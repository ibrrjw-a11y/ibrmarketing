# streamlit_app.py
# âœ… ì›ì¹™: ê¸°ì¡´ ì½”ë“œì—ì„œ 'ë…¼ì˜ ì—†ë˜ ê¸°ëŠ¥'ì€ ì‚­ì œ/ì¶•ì†Œí•˜ì§€ ì•ŠìŒ
# âœ… ì´ë²ˆ ìˆ˜ì •:
# 1) ëŒ€í–‰ ë‚´ë¶€: ì¸ê±´ë¹„ í¬í•¨í•œ ëŒ€í–‰ ì†ìµ(ìˆ˜ìˆ˜ë£Œ/í˜ì´ë°±/ë°”ì´ëŸ´ë§ˆì§„-ì¸ê±´ë¹„) ê³„ì‚° ì¶”ê°€
# 2) ì¶”ì²œì—”ì§„: ë‹¨ìˆœ ë£° fallback ìœ ì§€ + backdata ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì ìˆ˜í™” Top3 ì¶”ì²œ ì—”ì§„ ë³µì›/ê°•í™”
# 3) ì„±ì¥ë¥ /ê´‘ê³ ê¸°ì—¬ìœ¨/ì¬êµ¬ë§¤ìœ¨ backdata ë°˜ì˜ì€ ê¸°ì¡´ ê·¸ëŒ€ë¡œ ìœ ì§€

import streamlit as st
import pandas as pd
import numpy as np
import re
from io import StringIO
from typing import Optional, Dict, List, Tuple

# -------------------------
# Optional dependency: Plotly
# -------------------------
try:
    import plotly.express as px
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except Exception:
    HAS_PLOTLY = False

APP_PASSWORD = "ibrsecret"

# =========================
# Page / Theme
# =========================
st.set_page_config(page_title="ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°", layout="wide")

ACCENT = "#2F6FED"

st.markdown("""
<style>
html, body, [class*="css"]{
  font-size: 14px;
}
.card{
  border-radius: 14px;
  padding: 14px 14px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
}
.card h3{ margin:0; }
@media (prefers-color-scheme: light){
  .card{
    border: 1px solid rgba(0,0,0,0.08);
    background: #ffffff;
  }
}
div[data-testid="stDataFrame"] div, 
div[data-testid="stDataFrame"] span,
div[data-testid="stDataEditor"] div, 
div[data-testid="stDataEditor"] span,
div[data-baseweb="select"] * ,
input, textarea{
  opacity: 1 !important;
}
.smallcap{
  opacity: .75;
  font-size: 12px;
}
.badge{
  display:inline-block;
  padding: 6px 10px;
  border-radius: 999px;
  font-weight: 700;
  font-size: 12px;
  background: rgba(47,111,237,0.14);
  color: rgb(47,111,237);
}
hr.soft{
  border: 0;
  border-top: 1px solid rgba(255,255,255,0.10);
  margin: 12px 0;
}
@media (prefers-color-scheme: light){
  hr.soft{ border-top: 1px solid rgba(0,0,0,0.08); }
}

/* âœ… st.metric ê°’ì´ ...ìœ¼ë¡œ ì˜ë¦¬ëŠ” ë¬¸ì œ ë°©ì§€ */
div[data-testid="stMetricValue"]{
  white-space: normal !important;    /* ì¤„ë°”ê¿ˆ í—ˆìš© */
  overflow: visible !important;      /* ì˜ë¦¬ì§€ ì•Šê²Œ */
  text-overflow: clip !important;    /* ... ì œê±° */
  line-height: 1.15 !important;
}

/* ì¹´ë“œ ì•ˆì—ì„œëŠ” ì¡°ê¸ˆ ë” ì‘ê²Œ */
.card div[data-testid="stMetricValue"]{
  font-size: 1.35rem !important;     /* í•„ìš”ì‹œ 1.25~1.45 ì¡°ì • */
}

/* ëª¨ë°”ì¼/ì¢ì€ í™”ë©´ì—ì„œëŠ” ë” ì¤„ì´ê¸° */
@media (max-width: 1100px){
  .card div[data-testid="stMetricValue"]{
    font-size: 1.15rem !important;
  }
}
</style>
""", unsafe_allow_html=True)

if not HAS_PLOTLY:
    st.error(
        "âŒ plotlyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        "âœ… í•´ê²°:\n"
        "1) ë¡œì»¬/ì½”ë“œìŠ¤í˜ì´ìŠ¤: `pip install plotly`\n"
        "2) Streamlit Cloud: requirements.txtì— `plotly` ì¶”ê°€\n"
    )
    st.stop()

# =========================
# Auth (Password gate)
# =========================
def _norm01_rate(x):
    return normalize_ratio(x)

def auth_gate() -> bool:
    if st.session_state.get("auth_ok", False):
        return True

    st.sidebar.markdown("## ğŸ”’ ì ‘ê·¼ ì œí•œ")
    pw = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pw")
    col1, col2 = st.sidebar.columns([1, 1])
    with col1:
        if st.button("ì ê¸ˆ í•´ì œ", key="auth_unlock"):
            if pw == APP_PASSWORD:
                st.session_state["auth_ok"] = True
                st.rerun()
            else:
                st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤.")
    with col2:
        if st.button("ì´ˆê¸°í™”", key="auth_reset"):
            st.session_state.pop("auth_ok", None)
            st.session_state.pop("auth_pw", None)
            st.rerun()

    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    return False

if not auth_gate():
    st.stop()

# =========================
# Helpers
# =========================
def fmt_won(x) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):,.0f} ì›"
    except Exception:
        return "-"
def fmt_won_compact(x) -> str:
    """
    í° ìˆ«ì ì¹´ë“œì—ì„œ ê¸€ì”¨ê°€ ì§¤ë¦¬ëŠ” ë¬¸ì œ í•´ê²°ìš©(ì¶•ì•½ í‘œê¸°).
    - 1,234 -> 1,234ì›
    - 12,345,678 -> 1,235ë§Œì›
    - 1,234,567,890 -> 12.3ì–µì›
    """
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        v = float(x)

        av = abs(v)
        sign = "-" if v < 0 else ""

        if av < 10_000:
            return f"{v:,.0f} ì›"
        if av < 100_000_000:  # 1ì–µ ë¯¸ë§Œ: ë§Œì› ë‹¨ìœ„
            return f"{sign}{av/10_000:,.0f} ë§Œì›"
        # 1ì–µ ì´ìƒ: ì–µì› ë‹¨ìœ„ (ì†Œìˆ˜ 1ìë¦¬)
        return f"{sign}{av/100_000_000:,.1f} ì–µì›"
    except Exception:
        return "-"

def fmt_pct(x, digits=1) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):.{digits}f}%"
    except Exception:
        return "-"

def to_float(x, default=0.0) -> float:
    try:
        if pd.isna(x):
            return default
        s = str(x).strip().replace(",", "").replace("â‚©", "")
        s = s.replace("%", "")
        if s == "" or s.lower() == "nan":
            return default
        return float(s)
    except Exception:
        return default

def normalize_ratio(x) -> float:
    """supports 0.32, 32, '32%' -> returns 0~1"""
    v = to_float(x, default=np.nan)
    if np.isnan(v):
        return np.nan
    return (v / 100.0) if v > 1 else v

def clamp01(x: float, default: float = 0.0) -> float:
    try:
        v = float(x)
        if np.isnan(v):
            return default
        return max(0.0, min(1.0, v))
    except Exception:
        return default

def normalize_shares(d: Dict[str, float]) -> Dict[str, float]:
    d2 = {k: float(v or 0.0) for k, v in d.items()}
    s = sum(v for v in d2.values() if v > 0)
    if s <= 0:
        return {k: 0.0 for k in d2}
    return {k: (v / s if v > 0 else 0.0) for k, v in d2.items()}

def round_to_100(x) -> int:
    try:
        return int(np.round(float(x) / 100.0) * 100)
    except Exception:
        return 0

def safe_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in df.columns]
    for cand in candidates:
        if cand in cols:
            return cand
    for cand in candidates:
        for c in cols:
            if cand in c:
                return c
    return None

def drop_duplicate_dot_columns(df: pd.DataFrame) -> pd.DataFrame:
    cols = list(df.columns)
    base_seen = set()
    keep = []
    for c in cols:
        cstr = str(c)
        base = re.sub(r"\.\d+$", "", cstr)
        if base in base_seen and cstr != base:
            continue
        base_seen.add(base)
        keep.append(c)
    out = df[keep].copy()
    out.columns = [re.sub(r"\.\d+$", "", str(c)).strip() for c in out.columns]
    return out

def donut_chart(labels, values, title="", height=320):
    dd = pd.DataFrame({"name": labels, "value": values})
    fig = px.pie(dd, names="name", values="value", hole=0.55)
    fig.update_traces(textinfo="percent+label")
    fig.update_layout(height=height, margin=dict(t=40, b=10, l=10, r=10), title=title)
    return fig

# =========================
# Data loading (xlsx/csv)
# =========================
@st.cache_data(show_spinner=False)
def load_backdata_cached(file_bytes: bytes, filename: str) -> pd.DataFrame:
    name = (filename or "").lower()

    if name.endswith(".csv"):
        raw = file_bytes.decode("utf-8-sig", errors="replace")
        df = pd.read_csv(StringIO(raw))
        df = df.dropna(how="all")
        df = drop_duplicate_dot_columns(df)
        df.columns = [str(c).strip() for c in df.columns]
        return df

    try:
        xls = pd.ExcelFile(pd.io.common.BytesIO(file_bytes))
    except Exception as e:
        raise RuntimeError(
            "ì—‘ì…€(xlsx) ë¡œë“œ ì‹¤íŒ¨. Streamlit Cloudë¼ë©´ requirements.txtì— openpyxl ì¶”ê°€ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            f"ì›ì¸: {e}"
        )

    sheet = None
    for s in xls.sheet_names:
        s_norm = str(s).strip().lower()
        if s_norm in ("backdata", "back_data", "back data", "backdata "):
            sheet = s
            break
        if "backdata" in s_norm:
            sheet = s
            break
    if sheet is None:
        for s in xls.sheet_names:
            if str(s).strip().upper() == "BACKDATA":
                sheet = s
                break
    if sheet is None:
        sheet = xls.sheet_names[0]

    df = pd.read_excel(xls, sheet_name=sheet)
    df = df.dropna(how="all")
    df = drop_duplicate_dot_columns(df)
    df.columns = [str(c).strip() for c in df.columns]
    return df

def load_backdata(uploaded_file) -> pd.DataFrame:
    return load_backdata_cached(uploaded_file.getvalue(), uploaded_file.name)

# =========================
# Column detection (v4 with KPI + ì„±ì¥/ê¸°ì—¬/ì¬êµ¬ë§¤)
# =========================
def detect_columns(df: pd.DataFrame) -> Dict[str, object]:
    col_scn = safe_col(df, ["ì‹œë‚˜ë¦¬ì˜¤ëª…", "scenario", "Scenario"])
    col_disp = safe_col(df, ["ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…", "ë…¸ì¶œì‹œë‚˜ë¦¬ì˜¤ëª…", "display", "í‘œì‹œ ì‹œë‚˜ë¦¬ì˜¤ëª…"])
    if col_scn is None:
        col_scn = df.columns[0]
    if col_disp is None:
        col_disp = df.columns[1] if len(df.columns) > 1 else col_scn

    col_stage = safe_col(df, ["ë‹¨ê³„(ST)", "ë‹¨ê³„", "ST"])
    col_drv = safe_col(df, ["ë“œë¼ì´ë²„(DRV)", "ë“œë¼ì´ë²„", "DRV"])
    col_cat = safe_col(df, ["ì¹´í…Œê³ ë¦¬(ëŒ€)", "ì¹´í…Œê³ ë¦¬", "CAT"])
    col_pos = safe_col(df, ["ê°€ê²©í¬ì§€ì…˜(POS)", "ê°€ê²©í¬ì§€ì…˜", "POS"])

    rev_cols = [c for c in df.columns if str(c).endswith("ë§¤ì¶œë¹„ì¤‘") and c not in [col_scn, col_disp]]

    perf_cols = [
        c for c in df.columns
        if (str(c).startswith("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_") or str(c) == "í¼í¬ë¨¼ìŠ¤_ì™¸ë¶€ëª°PA")
        and not str(c).startswith("KPI_")
    ]
    viral_cols = [c for c in df.columns if str(c).startswith("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_") and not str(c).startswith("KPI_")]

    brand_cols = []
    for c in df.columns:
        s = str(c)
        if s.startswith("KPI_"):
            continue
        if s in ["ë¸Œëœë“œ ë§ˆì¼€íŒ…", "ê¸°íƒ€_ë¸Œëœë“œ", "ê¸°íƒ€ ë¸Œëœë“œ", "ê¸°íƒ€_ë¸Œëœë“œ%"]:
            brand_cols.append(c)
        elif ("ë¸Œëœë“œ" in s and "ë§ˆì¼€íŒ…" in s and not s.startswith("KPI_")):
            brand_cols.append(c)

    apply_internal = safe_col(df, ["apply_internal(ë‚´ë¶€)", "apply_internal", "ë‚´ë¶€ ì ìš©"])
    apply_client = safe_col(df, ["apply_client(ë¸Œëœë“œì‚¬)", "apply_client", "ë¸Œëœë“œì‚¬ ì ìš©"])
    apply_agency = safe_col(df, ["apply_agency(ëŒ€í–‰)", "apply_agency", "ëŒ€í–‰ ì ìš©"])

    # âœ… Backdata í™•ì¥ ì»¬ëŸ¼(ì›” ì„±ì¥ë¥ /ê´‘ê³ ê¸°ì—¬ìœ¨/ì¬êµ¬ë§¤ìœ¨/ê´‘ê³ ì˜ì¡´ë„)
    col_month_growth = safe_col(df, ["ì›” ì„±ì¥ë¥ ", "ì›”ì„±ì¥ë¥ ", "monthly_growth", "MoM Growth", "ì›”ì„±ì¥ë¥ (%)"])
    col_ad_contrib = safe_col(df, ["ê´‘ê³ ê¸°ì—¬ìœ¨", "ê´‘ê³  ê¸°ì—¬ìœ¨", "ad_contribution", "ê´‘ê³ ê¸°ì—¬ìœ¨(%)", "ê´‘ê³ ê¸°ì—¬"])
    col_repurchase = safe_col(df, ["ì¬êµ¬ë§¤ìœ¨", "ì¬êµ¬ë§¤ ë¹„ì¤‘", "repurchase", "ì¬êµ¬ë§¤ìœ¨(%)"])
    col_ad_dependency = safe_col(df, ["ê´‘ê³ ì˜ì¡´ë„", "ê´‘ê³  ì˜ì¡´ë„", "ad_dependency", "ê´‘ê³ ì˜ì¡´ë„(%)"])

    return {
        "scenario": col_scn,
        "display": col_disp,
        "stage": col_stage,
        "drv": col_drv,
        "cat": col_cat,
        "pos": col_pos,
        "rev_cols": rev_cols,
        "perf_cols": perf_cols,
        "viral_cols": viral_cols,
        "brand_cols": brand_cols,
        "kpi_cols": [c for c in df.columns if str(c).startswith("KPI_")],
        "apply_internal": apply_internal,
        "apply_client": apply_client,
        "apply_agency": apply_agency,
        "month_growth": col_month_growth,
        "ad_contrib": col_ad_contrib,
        "repurchase": col_repurchase,
        "ad_dependency": col_ad_dependency,
    }

def scenario_options(df: pd.DataFrame, col_scn: str, col_disp: str):
    tmp = df[[col_scn, col_disp]].copy()
    tmp[col_scn] = tmp[col_scn].astype(str).str.strip()
    tmp[col_disp] = tmp[col_disp].astype(str).str.strip()
    tmp = tmp.dropna()

    key_to_disp = dict(zip(tmp[col_scn], tmp[col_disp]))
    disp_to_key = {}
    for kk, dd in key_to_disp.items():
        if dd in disp_to_key and disp_to_key[dd] != kk:
            disp_to_key[f"{dd} ({kk})"] = kk
        else:
            disp_to_key[dd] = kk
    disp_list = sorted(list(disp_to_key.keys()))
    return key_to_disp, disp_to_key, disp_list

# =========================
# Media pretty & buckets
# =========================
def pretty_media_name(col: str) -> str:
    c = str(col).strip()
    c = c.replace("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_", "")
    c = c.replace("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_", "")
    c = c.replace("ì”¨ë”©", "ì‹œë”©")
    c = c.replace("ë„¤ì´ë²„ ", "ë„¤ì´ë²„")
    return c

def perf_category(media: str) -> str:
    m = str(media)
    if "SA" in m:
        return "ê²€ìƒ‰ ê´‘ê³ "
    if any(x in m for x in ["GDN", "GFA", "ë©”íƒ€", "í‹±í†¡", "í¬ë¦¬í…Œì˜¤", "í† ìŠ¤", "ìœ íŠœë¸Œ", "PMAX", "PMax", "pmax"]):
        return "ë””ìŠ¤í”Œë ˆì´/ì†Œì…œ"
    if "ì™¸ë¶€ëª°PA" in m or "ì¿ íŒ¡" in m:
        return "ë§ˆì¼“/PA"
    return "ê¸°íƒ€"

# =========================
# Viral price table (editable)
# =========================
DEFAULT_VIRAL_PRICE = pd.DataFrame([
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸í”Œë£¨ì–¸ì„œíƒ­", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìŠ¤ë§ˆíŠ¸ë¸”ë¡", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì§€ì‹ì¸", 100000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì‡¼í•‘ìƒìœ„", 2000000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸ê¸°ê¸€", 300000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìë™ê²€ìƒ‰ì™„ì„±", 400000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¹´í˜ì¹¨íˆ¬ë°”ì´ëŸ´", 30000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_êµ¬ë§¤ëŒ€í–‰", 120060, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_í•«ë”œ", 100000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_íŒŒì›Œí˜ì´ì§€", 400000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_í•´ì‹œíƒœê·¸ìƒìœ„ë…¸ì¶œ", 500000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_ê³„ì •ìƒìœ„ë…¸ì¶œ", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì§‘ë“¤ì´", 500000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì²´í—˜ë‹¨", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_êµ¬ë§¤ëŒ€í–‰", 200952, 1.0],
    ["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°", "ì»¤ë®¤ë‹ˆí‹°_í•«ë”œ", 200000, 1.0],
], columns=["ë§¤ì²´", "ì§€ë©´", "ê±´ë‹¹ë¹„ìš©", "ë¹„ìœ¨"])

# =========================
# Shares builder
# =========================
def build_rev_shares(row: pd.Series, rev_cols: List[str]) -> Dict[str, float]:
    d = {}
    for c in rev_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v):
            v = 0.0
        name = str(c).replace("ë§¤ì¶œë¹„ì¤‘", "").strip()
        d[name] = float(v)
    return normalize_shares(d)

def build_media_shares(row: pd.Series, perf_cols: List[str], viral_cols: List[str], brand_cols: List[str]):
    perf_raw, viral_raw, brand_raw = {}, {}, {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        perf_raw[pretty_media_name(c)] = float(v)
    for c in viral_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        viral_raw[pretty_media_name(c)] = float(v)
    for c in brand_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        brand_raw[pretty_media_name(c)] = float(v)

    perf_sum = sum(v for v in perf_raw.values() if v > 0)
    viral_sum = sum(v for v in viral_raw.values() if v > 0)
    brand_sum = sum(v for v in brand_raw.values() if v > 0)
    total = perf_sum + viral_sum + brand_sum

    group = {"í¼í¬ë¨¼ìŠ¤": 1.0, "ë°”ì´ëŸ´": 0.0, "ë¸Œëœë“œ": 0.0} if total <= 0 else {
        "í¼í¬ë¨¼ìŠ¤": perf_sum / total,
        "ë°”ì´ëŸ´": viral_sum / total,
        "ë¸Œëœë“œ": brand_sum / total
    }

    return {
        "group": group,
        "perf": normalize_shares(perf_raw),
        "viral": normalize_shares(viral_raw),
        "brand": normalize_shares(brand_raw),
        "raw_sums": {"perf": perf_sum, "viral": viral_sum, "brand": brand_sum},
    }

def viral_medium_shares(viral_share_dict: Dict[str, float]) -> Dict[str, float]:
    buckets = {"ë„¤ì´ë²„": 0.0, "ì¸ìŠ¤íƒ€ê·¸ë¨": 0.0, "ì˜¤ëŠ˜ì˜ì§‘": 0.0, "ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°": 0.0}
    for k, v in viral_share_dict.items():
        kk = str(k)
        if "ë„¤ì´ë²„" in kk:
            buckets["ë„¤ì´ë²„"] += v
        elif "ì¸ìŠ¤íƒ€" in kk:
            buckets["ì¸ìŠ¤íƒ€ê·¸ë¨"] += v
        elif "ì˜¤ëŠ˜ì˜ì§‘" in kk:
            buckets["ì˜¤ëŠ˜ì˜ì§‘"] += v
        else:
            buckets["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°"] += v
    return normalize_shares(buckets)

# =========================
# KPI blending (scenario-specific)
# =========================
def kpi_get(row: pd.Series, media_full: str, metric: str) -> Optional[float]:
    key = f"KPI_{metric}_{media_full}"
    if key in row.index:
        v = to_float(row.get(key), default=np.nan)
        if np.isnan(v):
            return None
        if metric in ("CTR", "CVR") and v > 1:
            v = v / 100.0
        return float(v)
    return None

def derive_cpc_from_cpm_ctr(cpm: Optional[float], ctr: Optional[float]) -> Optional[float]:
    if cpm is None or ctr is None:
        return None
    if cpm <= 0 or ctr <= 0:
        return None
    return float(cpm) / (1000.0 * float(ctr))

def blended_cpc_cvr(row: pd.Series, perf_cols: List[str]) -> Tuple[Optional[float], Optional[float]]:
    raw = {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        raw[str(c)] = float(v)
    shares = normalize_shares(raw)

    cpc_vals, cvr_vals = [], []
    weights_cpc, weights_cvr = [], []

    for media_full, w in shares.items():
        if w <= 0:
            continue

        cpc = kpi_get(row, media_full, "CPC")
        if cpc is None:
            cpm = kpi_get(row, media_full, "CPM")
            ctr = kpi_get(row, media_full, "CTR")
            cpc = derive_cpc_from_cpm_ctr(cpm, ctr)

        cvr = kpi_get(row, media_full, "CVR")

        if cpc is not None and cpc > 0:
            cpc_vals.append(cpc); weights_cpc.append(w)
        if cvr is not None and cvr > 0:
            cvr_vals.append(cvr); weights_cvr.append(w)

    def wavg(vals, ws):
        if not vals or not ws:
            return None
        s = sum(ws)
        if s <= 0:
            return None
        return float(sum(v * w for v, w in zip(vals, ws)) / s)

    return wavg(cpc_vals, weights_cpc), wavg(cvr_vals, weights_cvr)

# =========================
# Growth / Ad contribution / Repurchase (from backdata row)
# =========================
def get_row_rate(row: pd.Series, col: Optional[str], default: float) -> float:
    if col is None or col not in row.index:
        return float(default)
    v = normalize_ratio(row.get(col))
    if pd.isna(v):
        return float(default)
    return clamp01(float(v), default=float(default))

def get_row_growth(row: pd.Series, col: Optional[str], default: float) -> float:
    if col is None or col not in row.index:
        return float(default)
    v = to_float(row.get(col), default=np.nan)
    if np.isnan(v):
        return float(default)
    if abs(v) > 1.0:
        v = v / 100.0
    return float(v)

# =========================
# P&L / Simulation (sales-side)
# =========================
def simulate_pl(
    calc_mode: str,
    aov: float,
    cpc: float,
    cvr: float,
    cost_rate: float,
    logistics_per_order: float,
    fixed_cost: float,
    ad_spend: Optional[float],
    revenue: Optional[float],
    ad_contrib_rate: float = 1.0,
    repurchase_rate: float = 0.0,
):
    ad_contrib_rate = clamp01(ad_contrib_rate, 1.0)
    repurchase_rate = clamp01(repurchase_rate, 0.0)

    if calc_mode.startswith("ë§¤ì¶œ"):
        revenue = float(revenue or 0.0)
        total_orders = (revenue / aov) if aov > 0 else 0.0

        ad_revenue = revenue * ad_contrib_rate
        ad_orders = (ad_revenue / aov) if aov > 0 else 0.0

        clicks = (ad_orders / cvr) if cvr > 0 else 0.0
        ad_spend = clicks * cpc
    else:
        ad_spend = float(ad_spend or 0.0)
        clicks = (ad_spend / cpc) if cpc > 0 else 0.0
        ad_orders = clicks * cvr
        ad_revenue = ad_orders * aov

        denom = ad_contrib_rate if ad_contrib_rate > 0 else 1.0
        revenue = ad_revenue / denom
        total_orders = (revenue / aov) if aov > 0 else 0.0

    repeat_orders = total_orders * repurchase_rate
    first_orders = max(total_orders - repeat_orders, 0.0)
    repeat_revenue = repeat_orders * aov
    first_revenue = first_orders * aov

    cogs = revenue * cost_rate
    logistics = total_orders * logistics_per_order
    profit = revenue - (ad_spend + cogs + logistics + fixed_cost)
    contrib_margin = ((revenue - ad_spend - logistics - cogs) / revenue * 100) if revenue > 0 else 0.0
    roas = (revenue / ad_spend) if ad_spend and ad_spend > 0 else 0.0

    return {
        "revenue": float(revenue),
        "ad_spend": float(ad_spend),
        "orders": float(total_orders),
        "clicks": float(clicks),
        "cogs": float(cogs),
        "logistics": float(logistics),
        "fixed": float(fixed_cost),
        "profit": float(profit),
        "contrib_margin": float(contrib_margin),
        "roas": float(roas),
        "ad_contrib_rate": float(ad_contrib_rate),
        "repurchase_rate": float(repurchase_rate),
        "ad_revenue": float(ad_revenue),
        "ad_orders": float(ad_orders),
        "repeat_orders": float(repeat_orders),
        "first_orders": float(first_orders),
        "repeat_revenue": float(repeat_revenue),
        "first_revenue": float(first_revenue),
    }

# =========================
# Mix builders
# =========================
def build_performance_mix_table(perf_share: Dict[str, float], total_perf_budget: float) -> pd.DataFrame:
    rows = []
    for media, share in perf_share.items():
        if share <= 0:
            continue
        budget = round_to_100(total_perf_budget * share)
        rows.append({
            "êµ¬ë¶„": "í¼í¬ë¨¼ìŠ¤",
            "êµ¬ë¶„2": perf_category(media),
            "ë§¤ì²´": media,
            "ì§€ë©´/ìº í˜ì¸": "",
            "ì˜ˆì‚°(ê³„íš)": budget,
            "ëª©í‘œ ROAS(%)": 0.0,
        })
    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["êµ¬ë¶„2", "ë§¤ì²´"]).reset_index(drop=True)

def build_viral_mix_table(
    viral_price_df: pd.DataFrame,
    medium_share: Dict[str, float],
    total_viral_budget: float,
) -> pd.DataFrame:
    rows = []
    vp = viral_price_df.copy()

    for c in ["ë§¤ì²´", "ì§€ë©´"]:
        if c not in vp.columns:
            return pd.DataFrame()

    vp["ê±´ë‹¹ë¹„ìš©"] = vp["ê±´ë‹¹ë¹„ìš©"].apply(lambda x: to_float(x, 0.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].apply(lambda x: to_float(x, 1.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].replace(0, 1.0)

    for medium, mshare in medium_share.items():
        medium_budget = float(total_viral_budget) * float(mshare)
        sub = vp[vp["ë§¤ì²´"] == medium].copy()
        if sub.empty:
            continue

        sub_w = normalize_shares(dict(zip(sub["ì§€ë©´"], sub["ë¹„ìœ¨"])))

        for surface, w in sub_w.items():
            unit = float(sub.loc[sub["ì§€ë©´"] == surface, "ê±´ë‹¹ë¹„ìš©"].iloc[0])
            planned = medium_budget * float(w)
            cnt = int(np.round(planned / unit)) if unit > 0 else 0
            total_cost = cnt * unit
            rows.append({
                "êµ¬ë¶„": "ë°”ì´ëŸ´",
                "êµ¬ë¶„2": "",
                "ë§¤ì²´": medium,
                "ì§€ë©´/ìº í˜ì¸": surface,
                "ê±´ë‹¹ë¹„ìš©": unit,
                "ì§„í–‰ ê±´ìˆ˜": int(cnt),
                "ì˜ˆì‚°(ê³„íš)": round_to_100(total_cost),
            })

    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸"]).reset_index(drop=True)

def unify_mix_table(perf_df: pd.DataFrame, viral_df: pd.DataFrame) -> pd.DataFrame:
    base_cols = ["êµ¬ë¶„", "êµ¬ë¶„2", "ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ì˜ˆì‚°(ê³„íš)"]
    out = []
    if perf_df is not None and not perf_df.empty:
        tmp = perf_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if viral_df is not None and not viral_df.empty:
        tmp = viral_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if not out:
        return pd.DataFrame()
    return pd.concat(out, ignore_index=True)

# =========================
# Treemap builders
# =========================
def rev_bucket(channel_name: str) -> str:
    s = str(channel_name)
    if "ìì‚¬" in s:
        return "ìì‚¬ëª°"
    if "ìŠ¤ë§ˆíŠ¸" in s or "ìŠ¤í† ì–´" in s:
        return "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´"
    if "ì¿ íŒ¡" in s:
        return "ì¿ íŒ¡"
    if any(k in s for k in ["ì˜¤í”„ë¼ì¸", "ë©´ì„¸", "ë¦¬í…Œì¼", "ë°±í™”ì ", "ë§ˆíŠ¸", "ë“œëŸ­", "ì˜¬ë¦¬ë¸Œì˜"]):
        return "ì˜¤í”„ë¼ì¸"
    return "ì˜¨ë¼ì¸(ê¸°íƒ€)"

import colorsys

def _hls_to_hex(h, l, s):
    r, g, b = colorsys.hls_to_rgb(h, l, s)
    return "#{:02x}{:02x}{:02x}".format(int(r*255), int(g*255), int(b*255))

def treemap_revenue(rev_share: Dict[str, float], height=380, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)"):
    """
    âœ… ëª©í‘œ: ë§¤ì¶œ íŠ¸ë¦¬ë§µë„ ì˜ˆì‹œì²˜ëŸ¼
    - ê·¸ë£¹(ìì‚¬ëª°/ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¿ íŒ¡/ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ê¸°íƒ€)ë³„ Hue ê³ ì •
    - ê°™ì€ ê·¸ë£¹ ë‚´ì—ì„œëŠ” ë¹„ì¤‘(í¬ê¸°)ì— ë”°ë¼ ì§„í•˜ê¸°ë§Œ ë³€í™”
    """
    rows = []
    for ch, v in (rev_share or {}).items():
        if float(v or 0) <= 0:
            continue
        rows.append({"ê·¸ë£¹": rev_bucket(ch), "ì±„ë„": str(ch), "ë¹„ì¤‘": float(v)})

    if not rows:
        return None

    df = pd.DataFrame(rows)

    # âœ… ê·¸ë£¹ë³„ ê³ ì • Hue (ì›í•˜ëŠ” í†¤ ìˆìœ¼ë©´ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë¨)
    group_hue = {
        "ìì‚¬ëª°": 0.60,        # ë¸”ë£¨
        "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´": 0.55,  # ë¸”ë£¨-ì²­ë¡ ì‚¬ì´
        "ì¿ íŒ¡": 0.58,          # ë¸”ë£¨ ê³„ì—´ ìœ ì§€
        "ì˜¤í”„ë¼ì¸": 0.72,      # í¼í”Œ/ë°”ì´ì˜¬ë ›
        "ì˜¨ë¼ì¸(ê¸°íƒ€)": 0.60,  # ë¸”ë£¨(ì—°í†¤)
    }

    # ê·¸ë£¹ ë‚´ ì§„í•˜ê¸° ê¸°ì¤€: ì±„ë„ ë¹„ì¤‘(leaf) 0~1 ì •ê·œí™”
    g_minmax = df.groupby("ê·¸ë£¹")["ë¹„ì¤‘"].agg(["min", "max"]).reset_index()
    g_min = dict(zip(g_minmax["ê·¸ë£¹"], g_minmax["min"]))
    g_max = dict(zip(g_minmax["ê·¸ë£¹"], g_minmax["max"]))

    def within_norm(g, v):
        mn, mx = float(g_min.get(g, 0)), float(g_max.get(g, 0))
        if mx <= mn:
            return 1.0
        return (float(v) - mn) / (mx - mn)

    df["t"] = df.apply(lambda r: within_norm(r["ê·¸ë£¹"], r["ë¹„ì¤‘"]), axis=1)

    labels, parents, values, colors, ids = [], [], [], [], []

    # ê·¸ë£¹ ë…¸ë“œ
    grp_sum = df.groupby("ê·¸ë£¹")["ë¹„ì¤‘"].sum().to_dict()
    for g, v in grp_sum.items():
        labels.append(g)
        parents.append("")
        values.append(float(v))
        ids.append(f"grp::{g}")

        h = group_hue.get(g, 0.60)
        colors.append(_hls_to_hex(h, l=0.50, s=0.55))

    # ì±„ë„ ë…¸ë“œ
    for _, r in df.iterrows():
        g = r["ê·¸ë£¹"]
        name = r["ì±„ë„"]
        v = float(r["ë¹„ì¤‘"])
        t = float(r["t"])

        labels.append(name)
        parents.append(g)
        values.append(v)
        ids.append(f"leaf::{g}::{name}")

        h = group_hue.get(g, 0.60)
        # í° ì±„ë„ì¼ìˆ˜ë¡ ë” ì§„í•˜ê²Œ
        l = 0.88 - (0.50 * t)   # í•„ìš”í•˜ë©´ 0.65ë¡œ í‚¤ìš°ë©´ ë” ê·¹ì 
        s = 0.55
        colors.append(_hls_to_hex(h, l=l, s=s))

    fig = go.Figure(go.Treemap(
        labels=labels,
        parents=parents,
        values=values,
        ids=ids,
        branchvalues="total",
        marker=dict(
            colors=colors,
            line=dict(width=2, color="rgba(255,255,255,0.85)")
        ),
        textinfo="label+value",
        textfont=dict(color="white", size=14),
        hovertemplate="%{label}<br>%{value:.1%}<extra></extra>",
    ))

    fig.update_layout(
        height=height,
        title=title,
        margin=dict(t=50, b=10, l=10, r=10),
    )
    return fig



import colorsys

def _hls_to_hex(h, l, s):
    r, g, b = colorsys.hls_to_rgb(h, l, s)
    return "#{:02x}{:02x}{:02x}".format(int(r*255), int(g*255), int(b*255))

def treemap_ads(perf_df: pd.DataFrame, viral_df: pd.DataFrame, height=430, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)"):
    """
    âœ… ëª©í‘œ: ì˜ˆì‹œì²˜ëŸ¼
    - ê·¸ë£¹(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´/ë¸Œëœë“œ)ë³„ë¡œ ìƒ‰ ê³„ì—´(Hue) ê³ ì •
    - ê°™ì€ ê·¸ë£¹ ì•ˆì—ì„œëŠ” ì˜ˆì‚°(íƒ€ì¼ í¬ê¸°)ì— ë”°ë¼ ì§„í•˜ê¸°(Lightness)ë§Œ ë³€í™”
    - ì•Œë¡ë‹¬ë¡ color="ì§€ë©´" ë°©ì‹ ì œê±°
    """

    rows = []

    # í¼í¬ë¨¼ìŠ¤
    if perf_df is not None and not perf_df.empty:
        for _, r in perf_df.iterrows():
            bud = float(r.get("ì˜ˆì‚°(ê³„íš)", 0) or 0)
            if bud <= 0:
                continue
            rows.append({
                "ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤",
                "ë§¤ì²´": str(r.get("ë§¤ì²´", "")),
                "ì§€ë©´": str(r.get("ì§€ë©´/ìº í˜ì¸", "")) if str(r.get("ì§€ë©´/ìº í˜ì¸", "")).strip() else str(r.get("ë§¤ì²´", "")),
                "ì˜ˆì‚°": bud
            })

    # ë°”ì´ëŸ´
    if viral_df is not None and not viral_df.empty:
        for _, r in viral_df.iterrows():
            bud = float(r.get("ì˜ˆì‚°(ê³„íš)", 0) or 0)
            if bud <= 0:
                continue
            rows.append({
                "ê·¸ë£¹": "ë°”ì´ëŸ´",
                "ë§¤ì²´": str(r.get("ë§¤ì²´", "")),
                "ì§€ë©´": str(r.get("ì§€ë©´/ìº í˜ì¸", "")),
                "ì˜ˆì‚°": bud
            })

    if not rows:
        return None

    df = pd.DataFrame(rows)
    if df.empty:
        return None

    # âœ… ê·¸ë£¹ë³„ ê³ ì • Hue (ì›í•˜ë©´ ì—¬ê¸°ë§Œ í†¤ ë°”ê¿”)
    group_hue = {
        "í¼í¬ë¨¼ìŠ¤": 0.60,  # ë¸”ë£¨
        "ë°”ì´ëŸ´":   0.07,  # ì˜¤ë Œì§€
        "ë¸Œëœë“œ":   0.00,  # (ì•ˆ ì“°ë©´ ë¬´ì‹œë¨)
    }

    # ê·¸ë£¹ ë‚´ ì§„í•˜ê¸° ê¸°ì¤€: "ì§€ë©´ ì˜ˆì‚°"ì„ 0~1ë¡œ ì •ê·œí™” (í° íƒ€ì¼ì¼ìˆ˜ë¡ ì§„í•˜ê²Œ)
    g_minmax = df.groupby("ê·¸ë£¹")["ì˜ˆì‚°"].agg(["min", "max"]).reset_index()
    g_min = dict(zip(g_minmax["ê·¸ë£¹"], g_minmax["min"]))
    g_max = dict(zip(g_minmax["ê·¸ë£¹"], g_minmax["max"]))

    def within_norm(g, v):
        mn, mx = float(g_min.get(g, 0)), float(g_max.get(g, 0))
        if mx <= mn:
            return 1.0
        return (float(v) - mn) / (mx - mn)

    df["t"] = df.apply(lambda r: within_norm(r["ê·¸ë£¹"], r["ì˜ˆì‚°"]), axis=1)  # 0~1

    # Treemap ë…¸ë“œ êµ¬ì„±: ê·¸ë£¹(ë£¨íŠ¸) -> ì§€ë©´(leaf)
    labels, parents, values, colors, ids = [], [], [], [], []

    # ê·¸ë£¹ ë…¸ë“œ
    grp_sum = df.groupby("ê·¸ë£¹")["ì˜ˆì‚°"].sum().to_dict()
    for g, v in grp_sum.items():
        labels.append(g)
        parents.append("")
        values.append(float(v))
        ids.append(f"grp::{g}")

        h = group_hue.get(g, 0.6)
        colors.append(_hls_to_hex(h, l=0.50, s=0.55))  # ê·¸ë£¹ í—¤ë”ëŠ” ì¤‘ê°„í†¤

    # leaf ë…¸ë“œ (ì§€ë©´)
    for _, r in df.iterrows():
        g = r["ê·¸ë£¹"]
        name = r["ì§€ë©´"]
        v = float(r["ì˜ˆì‚°"])
        t = float(r["t"])  # 0~1

        labels.append(name)
        parents.append(g)
        values.append(v)
        ids.append(f"leaf::{g}::{name}")

        h = group_hue.get(g, 0.6)

        # âœ… ì˜ˆì‹œì²˜ëŸ¼ â€œí° íƒ€ì¼ = ë” ì§„í•˜ê²Œâ€
        # ë°ì€(ì‘ì€) 0.85 ~ ì§„í•œ(í°) 0.35
        l = 0.85 - (0.50 * t)
        s = 0.60
        colors.append(_hls_to_hex(h, l=l, s=s))

    fig = go.Figure(go.Treemap(
        labels=labels,
        parents=parents,
        values=values,
        ids=ids,
        branchvalues="total",
        marker=dict(
            colors=colors,
            line=dict(width=2, color="rgba(255,255,255,0.85)")
        ),
        # ì˜ˆì‹œì²˜ëŸ¼ ì¤‘ì•™ì— í° ê¸€ì”¨ ëŠë‚Œ
        textinfo="label+value",
        textfont=dict(color="white", size=14),
        hovertemplate="%{label}<br>%{value:,.0f}ì›<extra></extra>",
    ))

    fig.update_layout(
        height=height,
        title=title,
        margin=dict(t=50, b=10, l=10, r=10),
    )
    return fig



# =========================
# Compare chart
# =========================
def compare_chart(df_cmp: pd.DataFrame, x_col: str, rev_col: str, ad_col: str, roas_col: str, height=420, title=""):
    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=df_cmp[x_col], y=df_cmp[rev_col], name="ì˜ˆìƒë§¤ì¶œ", yaxis="y1",
        hovertemplate="%{y:,.0f}ì›<extra></extra>"
    ))
    fig.add_trace(go.Bar(
        x=df_cmp[x_col], y=df_cmp[ad_col], name="ì˜ˆìƒê´‘ê³ ë¹„", yaxis="y1",
        hovertemplate="%{y:,.0f}ì›<extra></extra>"
    ))

    roas = df_cmp[roas_col].astype(float).fillna(0.0).clip(lower=0)
    fig.add_trace(go.Scatter(
        x=df_cmp[x_col], y=roas, name="ROAS", yaxis="y2",
        mode="lines+markers",
        hovertemplate="ROAS %{y:.2f}x (%{customdata:.0f}%)<extra></extra>",
        customdata=(roas * 100.0)
    ))

    y2_min, y2_max = 1.0, 10.0
    if roas.max() > y2_max:
        y2_max = float(np.ceil(roas.max()))
    if roas.min() < y2_min and roas.min() > 0:
        y2_min = float(max(0.5, np.floor(roas.min()*2)/2))

    tickvals = list(np.linspace(y2_min, y2_max, 5))
    ticktext = [f"{v*100:.0f}%" for v in tickvals]

    fig.update_layout(
        height=height,
        barmode="group",
        title=title,
        margin=dict(t=50, b=10, l=10, r=10),
        yaxis=dict(title=None, tickformat=",.0f"),
        yaxis2=dict(
            title="ROAS(%)",
            overlaying="y",
            side="right",
            range=[y2_min, y2_max],
            tickmode="array",
            tickvals=tickvals,
            ticktext=ticktext,
        ),
        xaxis=dict(tickangle=0),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )
    return fig

# =========================
# Recommendation (fallback rule) - ìœ ì§€
# =========================
def top_key(d: Dict[str, float]) -> Tuple[Optional[str], float]:
    if not d:
        return None, 0.0
    items = sorted(d.items(), key=lambda x: x[1], reverse=True)
    return (items[0][0], float(items[0][1])) if items else (None, 0.0)

def strategy_recommendation_fallback(rev_share: Dict[str, float], sales_focus: str = "(ë¬´ê´€)") -> Dict[str, object]:
    def share_contains(keyword: str) -> float:
        s = 0.0
        for k, v in rev_share.items():
            if keyword in str(k):
                s += float(v)
        return s

    own = share_contains("ìì‚¬")
    smart = share_contains("ìŠ¤ë§ˆíŠ¸") + share_contains("ìŠ¤í† ì–´")
    coupang = share_contains("ì¿ íŒ¡")
    home = share_contains("í™ˆì‡¼í•‘")
    groupbuy = share_contains("ê³µêµ¬") + share_contains("ê³µë™")

    if home >= max(own, smart, coupang, groupbuy) and home > 0:
        title = "í™ˆì‡¼í•‘ ì—°ê³„í˜•"
        priority = [
            ("Naver SA", "í™ˆì‡¼í•‘ ìœ ì…/ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜ ì¤‘ì‹¬"),
            ("ë„¤ì´ë²„ ë¸”ë¡œê·¸Â·ì½˜í…ì¸ ", "ê²€ìƒ‰ ì‹ ë¢°/í›„ê¸°Â·ì •ë³´ì„± ë³´ê°•"),
            ("ì¿ íŒ¡ PA", "ë°©ì†¡ í›„ ìˆ˜ìš”ë¥¼ ë§ˆì¼“ì—ì„œ í¡ìˆ˜"),
        ]
        note = "ì´ ì¼€ì´ìŠ¤ëŠ” ë©”íƒ€/êµ¬ê¸€ ì§‘í–‰ì€ ì œì™¸(ë˜ëŠ” ìµœì†Œ) ê¶Œì¥"
    elif groupbuy >= max(own, smart, coupang, home) and groupbuy > 0:
        title = "ê³µêµ¬(ê·¸ë£¹ë°”ì‰) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì¸í”Œë£¨ì–¸ì„œ(ì¸ìŠ¤íƒ€ ë©”ê°€)", "ê³µêµ¬ëŠ” â€˜íŒë§¤ì íŒŒì›Œ/ì‹ ë¢°â€™ê°€ ë§¤ì¶œì„ ì¢Œìš°"),
            ("ë°”ì´ëŸ´(í•«ë”œ/ì»¤ë®¤ë‹ˆí‹°)", "êµ¬ë§¤ íŠ¸ë¦¬ê±°Â·í™•ì‚°"),
            ("ì™¸ë¶€ëª°/ì œíœ´ PA", "ê³µêµ¬ ì™¸ ì¶”ê°€ íŒë§¤ë¶„ í¡ìˆ˜"),
        ]
        note = "í¼í¬ë¨¼ìŠ¤ë³´ë‹¤ â€˜íŒë§¤ì/ì½˜í…ì¸  ë“œë¼ì´ë¸Œâ€™ê°€ ìš°ì„ "
    elif coupang >= max(own, smart, home, groupbuy) and coupang > 0:
        title = "ì¿ íŒ¡(ë§ˆì¼“) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì™¸ë¶€ëª° PA(ì¿ íŒ¡)", "ê°€ì¥ ì§ì ‘ì ì¸ ë§¤ì¶œ ê²¬ì¸ ë ˆë²„"),
            ("ë©”íƒ€", "ë¦¬íƒ€ê²Ÿ/í™•ì¥ ë° ìˆ˜ìš” ìƒì„±(ë³´ì¡°)"),
            ("ë„¤ì´ë²„ SA", "ë³´ì¡° ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
        ]
        note = "ì¿ íŒ¡ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ PA 1ìˆœìœ„, ê·¸ ë‹¤ìŒ ë©”íƒ€ê°€ ìì—°ìŠ¤ëŸ¬ì›€"
    elif smart >= max(own, coupang, home, groupbuy) and smart > 0:
        title = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(ë„¤ì´ë²„) ì¤‘ì‹¬í˜•"
        priority = [
            ("Naver SA", "ê²€ìƒ‰ ê¸°ë°˜ ì „í™˜ í™•ë³´"),
            ("ë„¤ì´ë²„ DA/GFA", "ë„¤ì´ë²„ ìƒíƒœê³„ ë‚´ í™•ì¥"),
            ("ë°”ì´ëŸ´(ë„¤ì´ë²„ ì§€ë©´)", "ìŠ¤ë§ˆíŠ¸ë¸”ë¡/ì½˜í…ì¸  ì—°ê³„"),
        ]
        note = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë„¤ì´ë²„ ë¹„ì¤‘ì„ ë†’ì´ëŠ” ê²Œ ì¼ê´€ë¨"
    elif own >= max(smart, coupang, home, groupbuy) and own > 0:
        title = "ìì‚¬ëª° ì¤‘ì‹¬í˜•"
        priority = [
            ("ë©”íƒ€", "ìì‚¬ëª°ì€ ëœë”©/ë¦¬íƒ€ê²Ÿ ì„¤ê³„ ê°•ì  â†’ íš¨ìœ¨ ê¸°ëŒ€"),
            ("Google(ì„ íƒ)", "ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜(ìƒí’ˆ/ë¸Œëœë“œ ê²€ìƒ‰ ì¤‘ì‹¬)"),
            ("ë„¤ì´ë²„ SA(ì„ íƒ)", "êµ­ë‚´ ê²€ìƒ‰ ìˆ˜ìš” ë³´ì¡°"),
        ]
        note = "ìì‚¬ëª° ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë©”íƒ€ ë¹„ì¤‘ì„ í‚¤ìš°ëŠ” ë£°ì´ ì˜ ë§ìŒ"
    else:
        title = "í˜¼í•©í˜•(ê· í˜• ìš´ì˜)"
        priority = [
            ("Naver SA", "ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
            ("ë©”íƒ€", "ìˆ˜ìš” ìƒì„±/ë¦¬íƒ€ê²Ÿ"),
            ("ë§ˆì¼“ PA", "ë³´ìœ  ì±„ë„ì—ì„œ ë§¤ì¶œ í¡ìˆ˜"),
        ]
        note = "ì±„ë„ì´ ì¹˜ìš°ì¹˜ì§€ ì•Šìœ¼ë©´ 3ì¶• ê· í˜• ìš´ì˜ ê¶Œì¥"

    top3 = sorted(rev_share.items(), key=lambda x: x[1], reverse=True)[:3]
    evidence = [f"{k}: {v*100:.1f}%" for k, v in top3 if v > 0]
    return {"title": title, "priority": priority, "note": note, "evidence": evidence}

# =========================
# âœ… Recommendation Engine (Checklist scoring) - ë³µì›/ê°•í™”
# =========================
def share_sum(rev_share: Dict[str, float], includes: List[str]) -> float:
    s = 0.0
    for k, v in rev_share.items():
        kk = str(k)
        if any(x in kk for x in includes):
            s += float(v)
    return float(s)

def build_checklist_features(
    row: pd.Series,
    rev_share: Dict[str, float],
    media_share: Dict[str, Dict[str, float]],
    cols: Dict[str, object],
    df_cols: Dict[str, object],
) -> Dict[str, object]:
    # channel dominance
    own = share_sum(rev_share, ["ìì‚¬"])
    smart = share_sum(rev_share, ["ìŠ¤ë§ˆíŠ¸", "ìŠ¤í† ì–´"])
    coupang = share_sum(rev_share, ["ì¿ íŒ¡"])
    offline = share_sum(rev_share, ["ì˜¤í”„ë¼ì¸", "ë©´ì„¸", "ë°±í™”ì ", "ì˜¬ë¦¬ë¸Œ", "ë§ˆíŠ¸", "ë“œëŸ­"])
    etc_online = max(1.0 - (own + smart + coupang + offline), 0.0)

    # scenario attributes
    stg = str(row.get(df_cols.get("stage")) if df_cols.get("stage") in row.index else "").strip()
    drv = str(row.get(df_cols.get("drv")) if df_cols.get("drv") in row.index else "").strip()
    cat = str(row.get(df_cols.get("cat")) if df_cols.get("cat") in row.index else "").strip()
    pos = str(row.get(df_cols.get("pos")) if df_cols.get("pos") in row.index else "").strip()

    month_growth = get_row_growth(row, cols.get("month_growth"), default=0.0)         # decimal
    ad_contrib = get_row_rate(row, cols.get("ad_contrib"), default=1.0)
    repurchase = get_row_rate(row, cols.get("repurchase"), default=0.0)
    ad_dep = get_row_rate(row, cols.get("ad_dependency"), default=ad_contrib)

    group = media_share.get("group", {"í¼í¬ë¨¼ìŠ¤": 1.0, "ë°”ì´ëŸ´": 0.0, "ë¸Œëœë“œ": 0.0})
    perf = group.get("í¼í¬ë¨¼ìŠ¤", 0.0)
    viral = group.get("ë°”ì´ëŸ´", 0.0)
    brand = group.get("ë¸Œëœë“œ", 0.0)

    return {
        "own": own,
        "smart": smart,
        "coupang": coupang,
        "offline": offline,
        "etc_online": etc_online,
        "stage": stg,
        "driver": drv,
        "category": cat,
        "position": pos,
        "month_growth": month_growth,
        "ad_contrib": ad_contrib,
        "repurchase": repurchase,
        "ad_dependency": ad_dep,
        "mix_perf": perf,
        "mix_viral": viral,
        "mix_brand": brand,
    }

STRATEGY_LIBRARY = [
    {
        "id": "S1_D2C_META_SCALE",
        "name": "ìì‚¬ëª° ìŠ¤ì¼€ì¼ì—…(ë©”íƒ€/êµ¬ê¸€ ì¤‘ì‹¬ + ë¦¬íƒ€ê²Ÿ)",
        "desc": "ìì‚¬ëª° ë¹„ì¤‘ì´ í° ê²½ìš°, í”½ì…€/CRM ê¸°ë°˜ ë¦¬íƒ€ê²Ÿê³¼ ë©”íƒ€ í™•ì¥ìœ¼ë¡œ CAC ì•ˆì •í™”.",
        "rules": [
            ("own", "ge", 0.35, 30),
            ("mix_perf", "ge", 0.55, 15),
            ("ad_dependency", "ge", 0.50, 10),
        ],
        "bonus": [
            ("repurchase", "ge", 0.25, 10),
            ("month_growth", "ge", 0.03, 10),
        ],
        "actions": [
            "ë©”íƒ€: ë¦¬íƒ€ê²Ÿ(7/14/30ì¼) + ìœ ì‚¬íƒ€ê²Ÿ í™•ì¥, í¬ë¦¬ì—ì´í‹°ë¸Œ AB",
            "êµ¬ê¸€: ë¸Œëœë“œ/ìƒí’ˆ ê²€ìƒ‰ ë°©ì–´ + PMAX(ê°€ëŠ¥ ì‹œ)ë¡œ í™•ì¥",
            "CRM: ì¬êµ¬ë§¤ìœ¨ ë†’ìœ¼ë©´ ì¹´ì¹´ì˜¤/ë©”ì¼ ìë™í™”ë¡œ ROAS ë³´ê°•",
        ],
    },
    {
        "id": "S2_NAVER_SMARTSTORE",
        "name": "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì„±ì¥(ë„¤ì´ë²„ SA/DA/GFA ì¤‘ì‹¬)",
        "desc": "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì¤‘ì‹¬ì´ë©´ ë„¤ì´ë²„ ìƒíƒœê³„ ë‚´ ê²€ìƒ‰/DAë¡œ ì „í™˜ì„ ë°€ì–´ì£¼ëŠ” ê²Œ ì •í•©.",
        "rules": [
            ("smart", "ge", 0.30, 30),
            ("mix_perf", "ge", 0.55, 10),
        ],
        "bonus": [
            ("month_growth", "ge", 0.02, 10),
            ("ad_dependency", "ge", 0.50, 5),
        ],
        "actions": [
            "ë„¤ì´ë²„ SA: í•µì‹¬ í‚¤ì›Œë“œ/ë¸Œëœë“œ í‚¤ì›Œë“œ êµ¬ì¡°í™” + ëœë”© ìµœì í™”",
            "GFA/DA: ì¥ë°”êµ¬ë‹ˆ/ì¬ë°©ë¬¸ ë¦¬íƒ€ê²Ÿ + ì‹ ê·œ í™•ì¥",
            "ì½˜í…ì¸ (ë¸”ë¡œê·¸/ìŠ¤ë§ˆíŠ¸ë¸”ë¡): ê²€ìƒ‰ ì‹ ë¢°/í›„ê¸° ê°•í™”",
        ],
    },
    {
        "id": "S3_COUPANG_PA",
        "name": "ì¿ íŒ¡ ë§¤ì¶œ ê°€ì†(ì¿ íŒ¡/ì™¸ë¶€ëª° PA ì¤‘ì‹¬)",
        "desc": "ì¿ íŒ¡ ë¹„ì¤‘ì´ í¬ë©´ ì™¸ë¶€ëª° PAê°€ ê°€ì¥ ì§ì ‘ì ì¸ ë ˆë²„.",
        "rules": [
            ("coupang", "ge", 0.25, 35),
            ("mix_perf", "ge", 0.55, 10),
        ],
        "bonus": [
            ("month_growth", "ge", 0.02, 10),
        ],
        "actions": [
            "ì¿ íŒ¡ PA: ROAS ê¸°ì¤€ ìë™ì…ì°°/í‚¤ì›Œë“œ í™•ì¥, ë² ìŠ¤íŠ¸SKU ì§‘ì¤‘",
            "ë©”íƒ€/ë„¤ì´ë²„: ì¿ íŒ¡ ëœë”© ë¦¬íƒ€ê²Ÿìœ¼ë¡œ ë³´ì¡° í¡ìˆ˜(í•„ìš” ì‹œ)",
            "ë¦¬ë·°/í‰ì : ì „í™˜ì˜ í•µì‹¬(ìš´ì˜ ê³¼ì œë¡œ ëª…ì‹œ)",
        ],
    },
    {
        "id": "S4_AD_DEP_DIVERSIFY",
        "name": "ê´‘ê³ ì˜ì¡´ë„ ì™„í™”(ë°”ì´ëŸ´/ë¸Œëœë“œ ë³´ê°• + ì„±ê³¼ ë°©ì–´)",
        "desc": "ê´‘ê³  ì˜ì¡´ë„ê°€ ë†’ì„ìˆ˜ë¡ ìœ ê¸°ì  ìˆ˜ìš”(ì½˜í…ì¸ /ë°”ì´ëŸ´)ë¡œ ë°©ì–´ ë ˆì´ì–´ í•„ìš”.",
        "rules": [
            ("ad_dependency", "ge", 0.70, 35),
        ],
        "bonus": [
            ("mix_viral", "ge", 0.15, 10),
            ("mix_brand", "ge", 0.10, 10),
        ],
        "actions": [
            "ë°”ì´ëŸ´: ë„¤ì´ë²„/ì»¤ë®¤ë‹ˆí‹° í•«ë”œ/ì²´í—˜ë‹¨ìœ¼ë¡œ ê²€ìƒ‰ëŸ‰/í›„ê¸° í™•ë³´",
            "ë¸Œëœë“œ: í•µì‹¬ ë©”ì‹œì§€/í¬ë¦¬ì—ì´í‹°ë¸Œ ì¼ê´€í™”ë¡œ ì „í™˜ìœ¨ ë³´ê°•",
            "í¼í¬ë¨¼ìŠ¤: ë¦¬íƒ€ê²Ÿ/ë¸Œëœë“œê²€ìƒ‰ ë°©ì–´ë¡œ íš¨ìœ¨ ìœ ì§€",
        ],
    },
    {
        "id": "S5_RETENTION_CRM",
        "name": "ë¦¬í…ì…˜/CRM ê°•í™”(ì¬êµ¬ë§¤ ì¤‘ì‹¬ LTV ì—…)",
        "desc": "ì¬êµ¬ë§¤ìœ¨ì´ ë†’ê±°ë‚˜ ë†’ì¼ ì—¬ì§€ê°€ í° ê²½ìš°, CRMì´ CACë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ë‚®ì¶¤.",
        "rules": [
            ("repurchase", "ge", 0.25, 35),
        ],
        "bonus": [
            ("own", "ge", 0.20, 10),
            ("month_growth", "le", 0.01, 10),
        ],
        "actions": [
            "CRM: ì²«êµ¬ë§¤â†’Nì¼ í›„ ë¦¬ë§ˆì¸ë“œ/ì„¸íŠ¸ì—…/ì •ê¸°êµ¬ë… ì‹œë‚˜ë¦¬ì˜¤",
            "ë¦¬íƒ€ê²Ÿ: ì¬êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬(êµ¬ë§¤ íšŸìˆ˜/ìµœê·¼ì„±)",
            "ì½˜í…ì¸ : ì‚¬ìš©ë²•/í›„ê¸° UGCë¡œ ì¬êµ¬ë§¤ íŠ¸ë¦¬ê±° ê°•í™”",
        ],
    },
    {
        "id": "S6_OFFLINE_SUPPORT",
        "name": "ì˜¤í”„ë¼ì¸/ë¦¬í…Œì¼ ì§€ì›(ì¸ì§€/ê²€ìƒ‰ ë°©ì–´)",
        "desc": "ì˜¤í”„ë¼ì¸ ë¹„ì¤‘ì´ ìˆëŠ” ê²½ìš°, ê²€ìƒ‰ ë°©ì–´ì™€ ë¸Œëœë“œ ë©”ì‹œì§€ë¡œ ë™ë°˜ ìƒìŠ¹ ìœ ë„.",
        "rules": [
            ("offline", "ge", 0.15, 30),
        ],
        "bonus": [
            ("mix_brand", "ge", 0.10, 10),
        ],
        "actions": [
            "ë„¤ì´ë²„/êµ¬ê¸€ ë¸Œëœë“œê²€ìƒ‰ ë°©ì–´: ë§¤ì¥ ë°©ë¬¸/êµ¬ë§¤ ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜",
            "ì½˜í…ì¸ : 'ì–´ë””ì„œ ì‚´ ìˆ˜ ìˆë‚˜' FAQ/ì§€ë„/ë¦¬ë·° ê°•í™”",
            "ë¸Œëœë”©: í•µì‹¬ USPë¥¼ ì˜¤í”„ë¼ì¸ íŒì´‰ê³¼ ì¼ê´€ë˜ê²Œ",
        ],
    },
]

def score_strategy(feat: Dict[str, object], strat: Dict[str, object]) -> Tuple[int, List[str]]:
    score = 0
    reasons = []

    def cmp(op: str, a: float, b: float) -> bool:
        if op == "ge": return a >= b
        if op == "gt": return a > b
        if op == "le": return a <= b
        if op == "lt": return a < b
        if op == "eq": return a == b
        return False

    for key, op, th, pts in strat.get("rules", []):
        a = float(feat.get(key, 0.0) or 0.0)
        if cmp(op, a, float(th)):
            score += int(pts)
            reasons.append(f"{key} {op} {th} (+{pts})")

    for key, op, th, pts in strat.get("bonus", []):
        a = float(feat.get(key, 0.0) or 0.0)
        if cmp(op, a, float(th)):
            score += int(pts)
            reasons.append(f"{key} {op} {th} (+{pts})")

    return score, reasons

def recommend_top3_strategies(feat: Dict[str, object]) -> pd.DataFrame:
    rows = []
    for s in STRATEGY_LIBRARY:
        sc, reasons = score_strategy(feat, s)
        rows.append({
            "ì „ëµID": s["id"],
            "ì „ëµëª…": s["name"],
            "ì ìˆ˜": sc,
            "ì„¤ëª…": s["desc"],
            "ê·¼ê±°(ë£°/ë³´ë„ˆìŠ¤)": " / ".join(reasons) if reasons else "",
            "ê¶Œì¥ ì•¡ì…˜": "\n- " + "\n- ".join(s["actions"]),
        })
    df_s = pd.DataFrame(rows).sort_values("ì ìˆ˜", ascending=False).reset_index(drop=True)
    return df_s

# =========================
# Sidebar - Upload
# =========================
st.sidebar.title("ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°")

uploaded = st.sidebar.file_uploader(
    "Backdata ì—…ë¡œë“œ (xlsx/csv)",
    type=["xlsx", "csv"],
    key="backdata_uploader"
)

if st.sidebar.button("ì—…ë¡œë“œ ì´ˆê¸°í™”", key="reset_uploader"):
    st.session_state.pop("backdata_uploader", None)
    st.cache_data.clear()
    st.rerun()

if uploaded is None:
    st.info("ì¢Œì¸¡ì—ì„œ backdata íŒŒì¼(xlsx/csv)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

try:
    df = load_backdata(uploaded)
except Exception as e:
    st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

cols = detect_columns(df)
col_scn = cols["scenario"]
col_disp = cols["display"]

if col_scn not in df.columns:
    st.error("âŒ 'ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

if col_disp not in df.columns:
    st.warning("âš ï¸ 'ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì´ ì—†ì–´, ì‹œë‚˜ë¦¬ì˜¤ëª…ì„ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤.")
    df[col_disp] = df[col_scn].astype(str)

key_to_disp, disp_to_key, disp_list = scenario_options(df, col_scn, col_disp)

stage_col, drv_col, cat_col, pos_col = cols["stage"], cols["drv"], cols["cat"], cols["pos"]

def uniq_vals(c):
    if c is None or c not in df.columns:
        return []
    return sorted([x for x in df[c].dropna().astype(str).unique().tolist() if str(x).strip() != ""])

st.sidebar.markdown("---")
st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ í•„í„°")
f_search = st.sidebar.text_input("ê²€ìƒ‰(ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…)", value="", key="f_search")
f_stage = st.sidebar.selectbox("ë‹¨ê³„(ST)", ["(ì „ì²´)"] + uniq_vals(stage_col), key="f_stage")
f_cat = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬", ["(ì „ì²´)"] + uniq_vals(cat_col), key="f_cat")
f_pos = st.sidebar.selectbox("ê°€ê²© í¬ì§€ì…˜(POS)", ["(ì „ì²´)"] + uniq_vals(pos_col), key="f_pos")
f_drv = st.sidebar.selectbox("ë“œë¼ì´ë²„(DRV)", ["(ì „ì²´)"] + uniq_vals(drv_col), key="f_drv")

apply_internal = cols.get("apply_internal")
apply_client = cols.get("apply_client")
apply_agency = cols.get("apply_agency")

st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ ë…¸ì¶œ í•„í„°(ì˜µì…˜)")
show_internal = st.sidebar.toggle("ë‚´ë¶€ìš© ì ìš©ë§Œ", value=False, key="show_internal")
show_client = st.sidebar.toggle("ë¸Œëœë“œì‚¬ìš© ì ìš©ë§Œ", value=False, key="show_client")
show_agency = st.sidebar.toggle("ëŒ€í–‰ìš© ì ìš©ë§Œ", value=False, key="show_agency")

df_f = df.copy()
if f_stage != "(ì „ì²´)" and stage_col in df_f.columns:
    df_f = df_f[df_f[stage_col].astype(str) == f_stage]
if f_cat != "(ì „ì²´)" and cat_col in df_f.columns:
    df_f = df_f[df_f[cat_col].astype(str) == f_cat]
if f_pos != "(ì „ì²´)" and pos_col in df_f.columns:
    df_f = df_f[df_f[pos_col].astype(str) == f_pos]
if f_drv != "(ì „ì²´)" and drv_col in df_f.columns:
    df_f = df_f[df_f[drv_col].astype(str) == f_drv]

def _apply_flag_filter(df_, flag_col):
    if flag_col and flag_col in df_.columns:
        return df_[df_[flag_col].astype(str).str.strip().isin(["1","True","TRUE","Y","y","O","o"])]
    return df_

if show_internal:
    df_f = _apply_flag_filter(df_f, apply_internal)
if show_client:
    df_f = _apply_flag_filter(df_f, apply_client)
if show_agency:
    df_f = _apply_flag_filter(df_f, apply_agency)

disp_candidates = sorted(list(set(df_f[col_disp].dropna().astype(str).str.strip().tolist())))
if f_search.strip():
    s = f_search.strip()
    disp_candidates = [x for x in disp_candidates if s in x]
if not disp_candidates:
    st.sidebar.warning("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•˜ì„¸ìš”.")
    disp_candidates = disp_list

sel_disp = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ", options=disp_candidates, key="sel_scn")

scenario_key = disp_to_key.get(sel_disp)
if scenario_key is None:
    scenario_key = next((k0 for k0, d0 in key_to_disp.items() if d0 == sel_disp), None)
if scenario_key is None:
    st.error("âŒ ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‚´ë¶€í‚¤ë¡œ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

row_df = df[df[col_scn].astype(str).str.strip() == str(scenario_key).strip()]
if row_df.empty:
    st.error("âŒ ì‹œë‚˜ë¦¬ì˜¤ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()
row = row_df.iloc[0]

rev_cols = cols["rev_cols"]
perf_cols = cols["perf_cols"]
viral_cols = cols["viral_cols"]
brand_cols = cols["brand_cols"]

rev_share = build_rev_shares(row, rev_cols)
media_share = build_media_shares(row, perf_cols, viral_cols, brand_cols)
group_share = media_share["group"]

# âœ… ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì„±ì¥/ê¸°ì—¬/ì¬êµ¬ë§¤ ê¸°ë³¸ê°’
scn_month_growth = get_row_growth(row, cols.get("month_growth"), default=0.0)
scn_ad_contrib = get_row_rate(row, cols.get("ad_contrib"), default=1.0)
scn_repurchase = get_row_rate(row, cols.get("repurchase"), default=0.0)
scn_ad_dependency = get_row_rate(row, cols.get("ad_dependency"), default=scn_ad_contrib)

def _rev_bucket_vec(rev_share: Dict[str, float]) -> Dict[str, float]:
    # ì±„ë„ëª…ì„ ë²„í‚·ìœ¼ë¡œ ë¬¶ì–´ì„œ ë²¡í„°í™”
    buckets = {"ìì‚¬ëª°": 0.0, "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´": 0.0, "ì¿ íŒ¡": 0.0, "ì˜¤í”„ë¼ì¸": 0.0, "ì˜¨ë¼ì¸(ê¸°íƒ€)": 0.0}
    for ch, v in (rev_share or {}).items():
        b = rev_bucket(ch)
        buckets[b] = buckets.get(b, 0.0) + float(v or 0.0)
    return normalize_shares(buckets)

def _cosine(a: Dict[str, float], b: Dict[str, float]) -> float:
    keys = set(a.keys()) | set(b.keys())
    va = np.array([float(a.get(k, 0.0) or 0.0) for k in keys], dtype=float)
    vb = np.array([float(b.get(k, 0.0) or 0.0) for k in keys], dtype=float)
    da = float(np.linalg.norm(va))
    db = float(np.linalg.norm(vb))
    if da <= 0 or db <= 0:
        return 0.0
    return float(np.dot(va, vb) / (da * db))

def _media_kw_share(perf_share: Dict[str, float], keywords: List[str]) -> float:
    s = 0.0
    for k, v in (perf_share or {}).items():
        kk = str(k)
        if any(kw in kk for kw in keywords):
            s += float(v or 0.0)
    return float(s)

def _ceiling_index(month_growth: float, repurchase: float, ad_dependency: float) -> float:
    """
    ê³ ì ì§€ìˆ˜: ì„±ì¥(+), ì¬êµ¬ë§¤(+), ê´‘ê³ ì˜ì¡´(-)
    0~2 ì •ë„ ë²”ìœ„ë¡œ ëŒ€ëµì ì¸ ë¹„êµì§€í‘œ (ìƒëŒ€ ë¹„êµìš©)
    """
    g = float(month_growth or 0.0)
    r = clamp01(repurchase, 0.0)
    d = clamp01(ad_dependency, 0.0)

    # ì„±ì¥ë¥ ì€ -ë„ ìˆìœ¼ë‹ˆ ì™„ë§Œí•˜ê²Œ
    g_score = np.clip(g * 6.0, -0.6, 0.9)      # -10%~-? ~ +15% ì •ë„ì—ì„œ ì™„ë§Œ
    r_score = r * 0.9                         # 0~0.9
    d_penalty = d * 0.7                       # 0~0.7

    return float(np.clip(1.0 + g_score + r_score - d_penalty, 0.2, 2.2))

# =========================================================
# Recommendation helpers (ADD THIS ABOVE ALL tabs)
# =========================================================

def _row_for_key(df_: pd.DataFrame, col_key: str, key: str) -> Optional[pd.Series]:
    if df_ is None or df_.empty:
        return None
    m = df_[col_key].astype(str).str.strip() == str(key).strip()
    sub = df_[m]
    if sub.empty:
        return None
    return sub.iloc[0]

def _estimate_now_and_roi(
    budget: float,
    aov: float,
    cpc: float,
    cvr: float,
    ad_contrib: float,
    month_growth: float = 0.0,
    repurchase: float = 0.0,
    ad_dependency: float = 0.0,
    months: int = 12,
    gross_margin_rate: float = 0.0,
    **kwargs,
):
    """
    ì¶”ì²œ ë¹„êµìš© ì¶”ì •ì¹˜(ë°©íƒ„):
    - budget/aov/cpc/cvrë¡œ ê´‘ê³ ë§¤ì¶œ(ad_rev) ê³„ì‚°
    - ê´‘ê³ ê¸°ì—¬ìœ¨(ad_contrib)ë¡œ ì´ë§¤ì¶œ(total_rev) í™˜ì‚°
    - ROIëŠ” ë§ˆì§„ê¸°ë°˜ ROI(= (ì´ë§¤ì¶œ*ë§ˆì§„ìœ¨ - ê´‘ê³ ë¹„)/ê´‘ê³ ë¹„)
    """
    budget = float(budget or 0.0)
    aov = float(aov or 0.0)
    cpc = float(cpc or 0.0)
    cvr = float(cvr or 0.0)

    ac = clamp01(normalize_ratio(ad_contrib), 0.6)
    rep = clamp01(normalize_ratio(repurchase), 0.0)

    # ì„±ì¥ë¥ ì€ ìŒìˆ˜ í¬í•¨ ê°€ëŠ¥
    g = to_float(month_growth, 0.0)
    if abs(g) > 1.0:
        g = g / 100.0

    addep = clamp01(normalize_ratio(ad_dependency), ac)

    # ê´‘ê³  -> ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ
    clicks = (budget / cpc) if cpc > 0 else 0.0
    orders = clicks * cvr
    ad_rev = orders * aov

    # ì´ë§¤ì¶œ í™˜ì‚°
    total_rev = ad_rev / max(ac, 1e-6)

    # ì¬êµ¬ë§¤ ì™„ë§Œ ë°˜ì˜(ëˆ„ì )
    rep_mult = 1.0 + rep * max(0, months - 1) * 0.15
    total_rev *= rep_mult

    roas = (total_rev / budget) if budget > 0 else np.nan
    gm = float(gross_margin_rate or 0.0)
    roi = ((total_rev * gm - budget) / budget) if budget > 0 else np.nan

    # ê³ ì (ì°¸ê³ ìš©) â€” ì¹´ë“œì—ëŠ” ì•ˆ ì¨ë„ ë¹„êµìš©ìœ¼ë¡œ ë‚¨ê¹€
    peak_total_rev = total_rev * ((1.0 + g) ** max(0, months - 1))
    peak_budget = budget * ((1.0 + g * addep) ** max(0, months - 1))

    return {
        "total_rev": float(total_rev),
        "ad_rev": float(ad_rev),
        "budget": float(budget),
        "roas": float(roas) if not pd.isna(roas) else np.nan,
        "roi": float(roi) if not pd.isna(roi) else np.nan,
        "peak_total_rev": float(peak_total_rev),
        "peak_budget": float(peak_budget),
    }

# =========================
# Tabs
# =========================
tab_guide, tab_agency, tab_brand, tab_rec, tab_custom, tab_plan = st.tabs(
    ["ì•ˆë‚´", "ëŒ€í–‰", "ë¸Œëœë“œì‚¬", "ì¶”ì²œì—”ì§„", "ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤", "ë§¤ì¶œ ê³„íš"]
)

# =========================
# Tab: Guide
# =========================
with tab_guide:
    st.markdown("## ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown(
    """
<div class="card">
  <h3>ì´ ì‹œë®¬ë ˆì´í„°ëŠ” ë¬´ì—‡ì„ í•˜ë‚˜ìš”?</h3>
  <hr class="soft"/>
  <ul>
    <li><b>ì‹œë‚˜ë¦¬ì˜¤(backdata)</b>ë¥¼ ì„ íƒí•˜ë©´, í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ <b>ë§¤ì¶œ ì±„ë„ ë¹„ì¤‘</b>ê³¼ <b>ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë¹„ì¤‘</b>ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.</li>
    <li><b>ëŒ€í–‰</b> íƒ­: ê´‘ê³ ë¹„â†”ë§¤ì¶œì„ ì–‘ë°©í–¥ìœ¼ë¡œ ì‚°ì¶œ(<b>ê´‘ê³ ê¸°ì—¬ìœ¨/ì¬êµ¬ë§¤ìœ¨</b> ë°˜ì˜). ë‚´ë¶€ìš©ì€ <b>ìˆ˜ìˆ˜ë£Œ/í˜ì´ë°±/ë°”ì´ëŸ´ë§ˆì§„/ì¸ê±´ë¹„</b>ê¹Œì§€ ì†ìµ ê³„ì‚°.</li>
    <li><b>ë¸Œëœë“œì‚¬</b> íƒ­: ì™¸ë¶€ìš©(ëŒ€ëµ ì „ë§ + íŠ¸ë¦¬ë§µ), ë‚´ë¶€ìš©(ì±„ë„ë³„ ì›”ë§¤ì¶œ + í•„ìš”ê´‘ê³ ë¹„ + ì›ê°€/ë¬¼ë¥˜/ë§ˆì§„/ì¸ê±´ë¹„).</li>
    <li><b>ì¶”ì²œì—”ì§„</b> íƒ­: ì‹œë‚˜ë¦¬ì˜¤ Top3 ì¶”ì²œ + <b>í˜„ì¬ íš¨ìœ¨(ROAS/ROI)</b> vs <b>ê³ ì (ì„±ì¥/ì¬êµ¬ë§¤/ê´‘ê³ ì˜ì¡´)</b> ë¹„êµë¡œ ìµœì¢… ì„ íƒ.</li>
  </ul>

  <hr class="soft"/>

  <h3>ì§€í‘œ/ì‚°ì‹ ì„¤ëª…</h3>
  <ul>
    <li><b>AOV</b> = ê°ë‹¨ê°€(í‰ê·  ì£¼ë¬¸ê¸ˆì•¡)</li>
    <li><b>CPC</b> = í´ë¦­ë‹¹ ë¹„ìš©(ì›)</li>
    <li><b>CVR</b> = ì „í™˜ìœ¨(ì£¼ë¬¸/í´ë¦­)</li>
    <li><b>ê´‘ê³ ê¸°ì—¬ìœ¨</b> = ì „ì²´ë§¤ì¶œ ì¤‘ ê´‘ê³ ê°€ ê¸°ì—¬í•œ ë¹„ì¤‘(0~1)</li>
    <li><b>ì¬êµ¬ë§¤ìœ¨</b> = ì „ì²´ì£¼ë¬¸ ì¤‘ ì¬êµ¬ë§¤ ì£¼ë¬¸ ë¹„ì¤‘(0~1, í‘œì‹œìš©/ì¶”ì •)</li>
    <li><b>ì›”ì„±ì¥ë¥ </b> = ì›” ê¸°ì¤€ ë§¤ì¶œ ì„±ì¥ë¥ (ìŒìˆ˜ ê°€ëŠ¥)</li>
    <li><b>ê´‘ê³ ì˜ì¡´ë„</b> = ì„±ì¥ ì‹œ ê´‘ê³ ë¹„ ì¦ê°€ ë¯¼ê°ë„(0~1, ë†’ì„ìˆ˜ë¡ ì„±ì¥ì— ê´‘ê³ ë¹„ê°€ ë” ë”°ë¼ë¶™ìŒ)</li>
  </ul>

  <hr class="soft"/>

  <h3>í•µì‹¬ ê³„ì‚° ë¡œì§(ìš”ì•½)</h3>
  <ul>
    <li><b>ì£¼ë¬¸ìˆ˜</b> = ë§¤ì¶œ Ã· AOV</li>
    <li><b>ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ</b><br/>
      í´ë¦­ìˆ˜ = ê´‘ê³ ë¹„ Ã· CPC<br/>
      ê´‘ê³ ì£¼ë¬¸ìˆ˜ = í´ë¦­ìˆ˜ Ã— CVR<br/>
      ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ = ê´‘ê³ ì£¼ë¬¸ìˆ˜ Ã— AOV<br/>
      ì „ì²´ë§¤ì¶œ = ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ Ã· ê´‘ê³ ê¸°ì—¬ìœ¨
    </li>
    <li><b>ë§¤ì¶œ â†’ í•„ìš” ê´‘ê³ ë¹„</b><br/>
      ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ = ì „ì²´ë§¤ì¶œ Ã— ê´‘ê³ ê¸°ì—¬ìœ¨<br/>
      ê´‘ê³ ì£¼ë¬¸ìˆ˜ = ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ Ã· AOV<br/>
      í´ë¦­ìˆ˜ = ê´‘ê³ ì£¼ë¬¸ìˆ˜ Ã· CVR<br/>
      í•„ìš” ê´‘ê³ ë¹„ = í´ë¦­ìˆ˜ Ã— CPC
    </li>
    <li><b>ROAS</b> = ì „ì²´ë§¤ì¶œ Ã· ê´‘ê³ ë¹„</li>
    <li class="smallcap">ë¸Œëœë“œ ë‚´ë¶€ íƒ­ì€ ì¶”ê°€ë¡œ ì›ê°€/ë¬¼ë¥˜/ê³ ì •ë¹„(ì¸ê±´ë¹„ í¬í•¨)ë¥¼ ë°˜ì˜í•´ ì˜ì—…ì´ìµì„ ê³„ì‚°í•©ë‹ˆë‹¤.</li>
  </ul>

  <hr class="soft"/>

  <h3>ê³ ì ì§€ìˆ˜ë€?</h3>
  <ul>
    <li>ì¶”ì²œì—”ì§„ì—ì„œ â€œ<b>í˜„ì¬ íš¨ìœ¨(ROAS/ROI)</b>â€ê³¼ â€œ<b>ì„±ì¥ ì ì¬ë ¥</b>â€ì„ í•¨ê»˜ ë¹„êµí•˜ê¸° ìœ„í•œ ë³´ì¡° ì§€í‘œì…ë‹ˆë‹¤.</li>
    <li>êµ¬ì„± ìš”ì†Œ: <b>ì›”ì„±ì¥ë¥ </b>, <b>ì¬êµ¬ë§¤ìœ¨</b>, <b>ê´‘ê³ ì˜ì¡´ë„</b></li>
    <li class="smallcap">ê³ ì ì§€ìˆ˜ ì‚°ì‹ì€ ì½”ë“œì˜ <code>_ceiling_index()</code>ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤(ì„¤ëª…ìš©).</li>
  </ul>

  <hr class="soft"/>

  <div class="smallcap">â€» ì…ë ¥ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì´ë©° ì‹¤ì œ ì„±ê³¼ëŠ” ìš´ì˜/ìƒí’ˆ/ì‹œì¦Œ ìš”ì¸ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>
</div>
    """,
    unsafe_allow_html=True
)


# =========================
# Editors
# =========================
def editable_perf_table(perf_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if perf_df.empty:
        return perf_df
    perf_df = perf_df.copy()

    if submode.startswith("ë‚´ë¶€"):
        if "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)" not in perf_df.columns:
            perf_df["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"] = 0.0
        if "í˜ì´ë°±ë¥ (%)" not in perf_df.columns:
            perf_df["í˜ì´ë°±ë¥ (%)"] = 0.0

        edited = st.data_editor(
            perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "í˜ì´ë°±ë¥ (%)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
            key=f"{key_prefix}_perf_editor_int",
        )
        outp = perf_df.copy()
        outp.update(edited)

        outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outp["ì²­êµ¬ì˜ˆìƒë¹„ìš©"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (1.0 + float(r["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"]) / 100.0)), axis=1
        )
        outp["ìˆ˜ìˆ˜ë£Œë§¤ì¶œ(ì›)"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (float(r["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"]) / 100.0)), axis=1
        )
        outp["í˜ì´ë°±ì˜ˆìƒì•¡"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (float(r["í˜ì´ë°±ë¥ (%)"]) / 100.0)), axis=1
        )
        outp["í¼í¬ë¨¼ìŠ¤ë§ˆì§„(ì›)"] = outp["ìˆ˜ìˆ˜ë£Œë§¤ì¶œ(ì›)"].astype(float) - outp["í˜ì´ë°±ì˜ˆìƒì•¡"].astype(float)

        st.dataframe(
            outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "ìˆ˜ìˆ˜ë£Œë§¤ì¶œ(ì›)", "í˜ì´ë°±ë¥ (%)", "í˜ì´ë°±ì˜ˆìƒì•¡", "í¼í¬ë¨¼ìŠ¤ë§ˆì§„(ì›)", "ì²­êµ¬ì˜ˆìƒë¹„ìš©"]],
            use_container_width=True,
            hide_index=True
        )
        return outp

    edited = st.data_editor(
        perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
        key=f"{key_prefix}_perf_editor_ext",
    )
    outp = perf_df.copy()
    outp.update(edited)
    outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    st.dataframe(outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]], use_container_width=True, hide_index=True)
    return outp

def editable_viral_table(viral_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if viral_df.empty:
        return viral_df

    viral_df = viral_df.copy()
    viral_df["ì˜ˆì‚°(ê³„íš)"] = viral_df["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    viral_df["ì§„í–‰ ê±´ìˆ˜"] = viral_df["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))

    if submode.startswith("ë‚´ë¶€"):
        if "ì‹¤ì§‘í–‰ë¹„(ì›)" not in viral_df.columns:
            viral_df["ì‹¤ì§‘í–‰ë¹„(ì›)"] = 0.0

        edited = st.data_editor(
            viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
            key=f"{key_prefix}_viral_editor_int",
        )
        outv = viral_df.copy()
        outv.update(edited)

        outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
        outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
        outv["ì‹¤ì§‘í–‰ë¹„(ì›)"] = outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outv["ë°”ì´ëŸ´ë§ˆì§„(ì›)"] = outv["ì˜ˆì‚°(ê³„íš)"].astype(float) - outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].astype(float)

        st.dataframe(
            outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)", "ë°”ì´ëŸ´ë§ˆì§„(ì›)"]],
            use_container_width=True,
            hide_index=True
        )
        return outv

    edited = st.data_editor(
        viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
        key=f"{key_prefix}_viral_editor_ext",
    )
    outv = viral_df.copy()
    outv.update(edited)
    outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
    outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
    st.dataframe(outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]], use_container_width=True, hide_index=True)
    return outv

# =========================
# âœ… Agency Internal P&L (ìˆ˜ìˆ˜ë£Œ/ë§ˆì§„/ì¸ê±´ë¹„) ê³„ì‚°
# =========================
def agency_internal_pl(perf_out: pd.DataFrame, viral_out: pd.DataFrame, labor_cost: float) -> Dict[str, float]:
    perf_budget = 0.0
    perf_fee_rev = 0.0
    perf_payback = 0.0
    perf_margin = 0.0

    if perf_out is not None and not perf_out.empty:
        perf_budget = float(perf_out["ì˜ˆì‚°(ê³„íš)"].astype(float).sum())
        if "ìˆ˜ìˆ˜ë£Œë§¤ì¶œ(ì›)" in perf_out.columns:
            perf_fee_rev = float(perf_out["ìˆ˜ìˆ˜ë£Œë§¤ì¶œ(ì›)"].astype(float).sum())
        else:
            # fallback: fee rate if exists
            if "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)" in perf_out.columns:
                perf_fee_rev = float((perf_out["ì˜ˆì‚°(ê³„íš)"].astype(float) * (perf_out["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"].astype(float)/100.0)).sum())
        if "í˜ì´ë°±ì˜ˆìƒì•¡" in perf_out.columns:
            perf_payback = float(perf_out["í˜ì´ë°±ì˜ˆìƒì•¡"].astype(float).sum())
        else:
            if "í˜ì´ë°±ë¥ (%)" in perf_out.columns:
                perf_payback = float((perf_out["ì˜ˆì‚°(ê³„íš)"].astype(float) * (perf_out["í˜ì´ë°±ë¥ (%)"].astype(float)/100.0)).sum())
        if "í¼í¬ë¨¼ìŠ¤ë§ˆì§„(ì›)" in perf_out.columns:
            perf_margin = float(perf_out["í¼í¬ë¨¼ìŠ¤ë§ˆì§„(ì›)"].astype(float).sum())
        else:
            perf_margin = perf_fee_rev - perf_payback

    viral_budget = 0.0
    viral_real = 0.0
    viral_margin = 0.0
    if viral_out is not None and not viral_out.empty:
        viral_budget = float(viral_out["ì˜ˆì‚°(ê³„íš)"].astype(float).sum())
        if "ì‹¤ì§‘í–‰ë¹„(ì›)" in viral_out.columns:
            viral_real = float(viral_out["ì‹¤ì§‘í–‰ë¹„(ì›)"].astype(float).sum())
        if "ë°”ì´ëŸ´ë§ˆì§„(ì›)" in viral_out.columns:
            viral_margin = float(viral_out["ë°”ì´ëŸ´ë§ˆì§„(ì›)"].astype(float).sum())
        else:
            viral_margin = viral_budget - viral_real

    gross_margin = perf_margin + viral_margin
    op_profit = gross_margin - float(labor_cost)

    # ëŒ€í–‰ "ì²­êµ¬ì•¡" ê´€ì (ì°¸ê³ )
    billed = 0.0
    if perf_out is not None and not perf_out.empty and "ì²­êµ¬ì˜ˆìƒë¹„ìš©" in perf_out.columns:
        billed += float(perf_out["ì²­êµ¬ì˜ˆìƒë¹„ìš©"].astype(float).sum())
    else:
        billed += perf_budget  # pass-throughë§Œì´ë¼ë„
    billed += viral_budget  # ë°”ì´ëŸ´ì€ ì˜ˆì‚°(ê³„íš) ê¸°ì¤€ ì²­êµ¬ë¡œ ê°€ì •

    return {
        "perf_budget": perf_budget,
        "perf_fee_rev": perf_fee_rev,
        "perf_payback": perf_payback,
        "perf_margin": perf_margin,
        "viral_budget": viral_budget,
        "viral_real": viral_real,
        "viral_margin": viral_margin,
        "gross_margin": gross_margin,
        "labor_cost": float(labor_cost),
        "op_profit": op_profit,
        "billed_total": billed,
    }

# =========================
# Tab: Agency
# =========================
with tab_agency:
    st.markdown("## ëŒ€í–‰ ëª¨ë“œ")
    submode = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(í´ë¼ì´ì–¸íŠ¸ ì œì•ˆìš©)", "ë‚´ë¶€(ìš´ì˜/ì •ì‚°ìš©)"], horizontal=True, key="agency_sub")

    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì…ë ¥ (ì‹œë®¬ë ˆì´ì…˜)")
    use_scn_kpi = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPI ìë™ ì‚¬ìš©(ê¶Œì¥)", value=True, key="use_scn_kpi_ag")

    cG1, cG2, cG3 = st.columns(3)
    with cG1:
        ad_contrib_in = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=float(scn_ad_contrib * 100.0), step=1.0, key="ag_ad_contrib") / 100.0
    with cG2:
        repurchase_in = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=float(scn_repurchase * 100.0), step=1.0, key="ag_repurchase") / 100.0
    with cG3:
        st.caption(f"ì°¸ê³ (ì‹œë‚˜ë¦¬ì˜¤): ì›”ì„±ì¥ë¥  {fmt_pct(scn_month_growth*100,1)} / ê´‘ê³ ì˜ì¡´ë„ {fmt_pct(scn_ad_dependency*100,1)}")

    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="calc_mode_ag")
    with cB:
        aov = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50000, step=1000, key="aov_ag")
    with cC:
        cpc_manual = st.number_input("CPC (ì›) [ìˆ˜ë™]", value=300.0, step=10.0, key="cpc_ag")
    with cD:
        cvr_manual = st.number_input("CVR (%) [ìˆ˜ë™]", value=2.0, step=0.1, key="cvr_ag") / 100.0

    scn_cpc, scn_cvr = blended_cpc_cvr(row, perf_cols)
    cpc = scn_cpc if (use_scn_kpi and scn_cpc is not None) else float(cpc_manual)
    cvr = scn_cvr if (use_scn_kpi and scn_cvr is not None) else float(cvr_manual)

    st.caption(
        f"í˜„ì¬ ì ìš© KPI: CPC {fmt_won(cpc)} / CVR {fmt_pct(cvr*100,1)} "
        + (f"(ì‹œë‚˜ë¦¬ì˜¤ KPI ê¸°ë°˜)" if use_scn_kpi and scn_cpc is not None else "(ìˆ˜ë™ ì…ë ¥)")
    )

    if calc_mode.startswith("ê´‘ê³ ë¹„"):
        ad_total = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="ad_total_ag")
        rev_target = None
    else:
        rev_target = st.number_input("ëª©í‘œ ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="rev_target_ag")
        ad_total = None

    sim = simulate_pl(
        calc_mode=calc_mode,
        aov=aov,
        cpc=cpc,
        cvr=cvr,
        cost_rate=0.0,
        logistics_per_order=0.0,
        fixed_cost=0.0,
        ad_spend=ad_total,
        revenue=rev_target,
        ad_contrib_rate=float(ad_contrib_in),
        repurchase_rate=float(repurchase_in),
    )

    st.divider()
    st.markdown("### ê²°ê³¼ ìš”ì•½(ëŒ€í–‰: ë§ˆì¼€íŒ… ì„±ê³¼ ê´€ì )")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ë§¤ì¶œ(ì´)", fmt_won(sim["revenue"]))
    m2.metric("í•„ìš”/ì…ë ¥ ê´‘ê³ ë¹„", fmt_won(sim["ad_spend"]))
    m3.metric("ROAS", f"{sim['roas']:.2f}x ({sim['roas']*100:,.0f}%)")
    m4.metric("ê´‘ê³ ê¸°ì—¬ìœ¨", fmt_pct(sim["ad_contrib_rate"]*100, 1))

    m5, m6, m7 = st.columns(3)
    m5.metric("ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ", fmt_won(sim["ad_revenue"]))
    m6.metric("ì¬êµ¬ë§¤ ë§¤ì¶œ(ì¶”ì •)", fmt_won(sim["repeat_revenue"]))
    m7.metric("ì¬êµ¬ë§¤ìœ¨", fmt_pct(sim["repurchase_rate"]*100, 1))

    st.divider()
    st.plotly_chart(
        donut_chart(
            ["í¼í¬ë¨¼ìŠ¤", "ë°”ì´ëŸ´", "ë¸Œëœë“œ"],
            [group_share.get("í¼í¬ë¨¼ìŠ¤", 0), group_share.get("ë°”ì´ëŸ´", 0), group_share.get("ë¸Œëœë“œ", 0)],
            title="ê´‘ê³ ë¹„ êµ¬ì¡°(100%)",
            height=380
        ),
        use_container_width=True,
        key=f"donut_group_ag_{scenario_key}"
    )

    st.divider()
    st.markdown("## ë¯¸ë””ì–´ ë¯¹ìŠ¤ (ì˜ˆì‚°/ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget = float(sim["ad_spend"]) * float(group_share.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget = float(sim["ad_spend"]) * float(group_share.get("ë°”ì´ëŸ´", 0.0))

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        st.caption("ì§€ë©´ ë‹¨ê°€/ë¹„ìœ¨ ìˆ˜ì • â†’ ê±´ìˆ˜/ì˜ˆì‚°ì— ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
        viral_price = st.data_editor(
            DEFAULT_VIRAL_PRICE.copy(),
            num_rows="dynamic",
            use_container_width=True,
            key=f"viral_price_editor_{scenario_key}"
        )

    perf_df = build_performance_mix_table(media_share["perf"], perf_budget)
    medium_share = viral_medium_shares(media_share["viral"])
    viral_df = build_viral_mix_table(viral_price, medium_share, viral_budget)

    st.markdown("### í¼í¬ë¨¼ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")
    if perf_df.empty:
        st.info("í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        perf_out = perf_df
    else:
        perf_out = editable_perf_table(perf_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.markdown("### ë°”ì´ëŸ´(ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")
    if viral_df.empty:
        st.info("ë°”ì´ëŸ´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        viral_out = viral_df
    else:
        viral_out = editable_viral_table(viral_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.divider()
    st.markdown("### í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ í‘œ(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´)")
    mix_df = unify_mix_table(perf_out, viral_out)
    if mix_df.empty:
        st.info("í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(mix_df, use_container_width=True, hide_index=True)

    fig_ads_tm = treemap_ads(perf_out, viral_out, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ: í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´ ìƒ‰ êµ¬ë¶„)")
    if fig_ads_tm:
        st.plotly_chart(fig_ads_tm, use_container_width=True, key=f"ads_tm_ag_{scenario_key}")

    # âœ… í•µì‹¬ ìˆ˜ì •: ëŒ€í–‰ ë‚´ë¶€ ì†ìµ(ì¸ê±´ë¹„ í¬í•¨)
    if submode.startswith("ë‚´ë¶€"):
        st.divider()
        st.markdown("## ëŒ€í–‰ ë‚´ë¶€ ì†ìµ(ìˆ˜ìˆ˜ë£Œ/ë§ˆì§„ - ì¸ê±´ë¹„)")

        cL1, cL2 = st.columns(2)
        with cL1:
            headcount = st.number_input("ëŒ€í–‰ ìš´ì˜ ì¸ë ¥(ëª…)", value=2, step=1, min_value=0, key="ag_hc_internal")
        with cL2:
            cost_per = st.number_input("ì¸ë‹¹ ì›” ì¸ê±´ë¹„(ì›)", value=3500000, step=100000, key="ag_cper_internal")

        labor_cost = float(headcount) * float(cost_per)

        pl = agency_internal_pl(perf_out, viral_out, labor_cost=labor_cost)

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("ì´ ì²­êµ¬ì•¡(ì¶”ì •)", fmt_won(pl["billed_total"]))
        k2.metric("í¼í¬ë¨¼ìŠ¤ ë§ˆì§„", fmt_won(pl["perf_margin"]))
        k3.metric("ë°”ì´ëŸ´ ë§ˆì§„", fmt_won(pl["viral_margin"]))
        k4.metric("ì´ ë§ˆì§„(=Gross)", fmt_won(pl["gross_margin"]))

        k5, k6, k7 = st.columns(3)
        k5.metric("ì¸ê±´ë¹„(ì›”)", fmt_won(pl["labor_cost"]))
        k6.metric("ëŒ€í–‰ ì˜ì—…ì´ìµ(ì›”)", fmt_won(pl["op_profit"]))
        gm_rate = (pl["gross_margin"] / pl["billed_total"] * 100.0) if pl["billed_total"] > 0 else 0.0
        k7.metric("ë§ˆì§„ìœ¨(ì²­êµ¬ ëŒ€ë¹„)", fmt_pct(gm_rate, 1))

        st.caption("â€» í¼í¬ë¨¼ìŠ¤ëŠ” ì˜ˆì‚°(pass-through) + ìˆ˜ìˆ˜ë£Œ ë§¤ì¶œ êµ¬ì¡°ë¡œ ê°€ì •. í˜ì´ë°±ì€ ë§ˆì§„ì—ì„œ ì°¨ê°. ë°”ì´ëŸ´ì€ ì˜ˆì‚°-ì‹¤ì§‘í–‰ë¹„ë¥¼ ë§ˆì§„ìœ¼ë¡œ ê³„ì‚°.")

# =========================
# Tab: Brand
# (ì´í•˜ ë™ì¼: ì´ì „ ë²„ì „ ê·¸ëŒ€ë¡œ ìœ ì§€ â€” ê¸¸ì´ìƒ ìƒëµ ì—†ì´ í¬í•¨í•´ì•¼ í•˜ì§€ë§Œ,
#  ì‚¬ìš©ì ìš”êµ¬ê°€ 'ëŒ€í–‰ ì¸ê±´ë¹„' + 'ì¶”ì²œì—”ì§„'ì´ë¼ ë¸Œëœë“œ íƒ­ì€ ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.)
# =========================
with tab_brand:
    st.markdown("## ë¸Œëœë“œì‚¬ ëª¨ë“œ")
    submode_b = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(ë¸Œëœë“œì‚¬ ê³µìœ ìš©)", "ë‚´ë¶€(ë¸Œëœë“œ ìš´ì˜/ê²€ì¦ìš©)"], horizontal=True, key="brand_sub")
    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë³¸ ë³€ìˆ˜(Backdata)")
    g1, g2, g3, g4 = st.columns(4)
    g1.metric("ì›” ì„±ì¥ë¥ (ê¸°ë³¸)", fmt_pct(scn_month_growth*100, 1))
    g2.metric("ê´‘ê³ ê¸°ì—¬ìœ¨(ê¸°ë³¸)", fmt_pct(scn_ad_contrib*100, 1))
    g3.metric("ì¬êµ¬ë§¤ìœ¨(ê¸°ë³¸)", fmt_pct(scn_repurchase*100, 1))
    g4.metric("ê´‘ê³ ì˜ì¡´ë„(ì°¸ê³ )", fmt_pct(scn_ad_dependency*100, 1))
    st.divider()

    if submode_b.startswith("ì™¸ë¶€"):
        st.markdown("### (ì™¸ë¶€) ëŒ€ëµ ì „ë§: ë§¤ì¶œ/ë¬¼ëŸ‰/ì¬ê³ ì†Œì§„")
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            months = st.selectbox("ê¸°ê°„(ê°œì›”)", options=[3, 6, 12], index=2, key="b_months")
        with c2:
            base_month_rev = st.number_input("ì›” ê¸°ì¤€ ì´ë§¤ì¶œ(ì›)", value=200000000, step=10000000, key="b_base_rev")
        with c3:
            growth = st.number_input("ì›” ì„±ì¥ë¥ (%)", value=float(scn_month_growth*100.0), step=0.5, key="b_growth") / 100.0
        with c4:
            selling_price = st.number_input("ì˜ˆìƒ íŒë§¤ê°€(AOV) (ì›)", value=50000, step=1000, key="b_sell_price_ext")

        s1, s2, s3 = st.columns(3)
        with s1:
            current_stock = st.number_input("í˜„ì¬ ì¬ê³ (ê°œ)", value=10000, step=100, key="b_stock_ext")
        with s2:
            safety_stock = st.number_input("ì•ˆì „ì¬ê³ (ê°œ)", value=0, step=100, key="b_safety_ext")
        with s3:
            start_day = st.date_input("ê¸°ì¤€ì¼(ì¬ê³  ì‹œì‘ì¼)", key="b_startday_ext")

        months_idx = list(range(1, int(months) + 1))
        rev_list, units_list, ym_list = [], [], []
        for i in months_idx:
            factor = (1.0 + growth) ** (i - 1)
            rev_i = base_month_rev * factor
            units_i = (rev_i / selling_price) if selling_price > 0 else 0.0
            rev_list.append(rev_i)
            units_list.append(units_i)
            ym_list.append(f"M{i}")

        df_m = pd.DataFrame({"ì›”": ym_list, "ì´ë§¤ì¶œ": rev_list, "ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)": units_list})
        df_m["ëˆ„ì íŒë§¤(ê°œ)"] = df_m["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].cumsum()

        burn_point = float(current_stock)
        burn_month = None
        burn_in_month_ratio = None
        prev = 0.0
        for _, r in df_m.iterrows():
            cumu = float(r["ëˆ„ì íŒë§¤(ê°œ)"])
            if cumu >= burn_point and burn_month is None:
                burn_month = r["ì›”"]
                month_units = float(r["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"])
                burn_in_month_ratio = (burn_point - prev) / month_units if month_units > 0 else 1.0
                break
            prev = cumu

        total_units = float(df_m["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].sum())
        po_units = max(int(np.ceil(total_units + float(safety_stock) - float(current_stock))), 0)

        k1, k2, k3 = st.columns(3)
        k1.metric("ê¸°ê°„ ì´ë§¤ì¶œ", fmt_won(df_m["ì´ë§¤ì¶œ"].sum()))
        k2.metric("ê¸°ê°„ ì˜ˆìƒ íŒë§¤ìˆ˜ëŸ‰", f"{df_m['ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)'].sum():,.0f} ê°œ")
        k3.metric("ê¶Œì¥ ë°œì£¼(ëŒ€ëµ)", f"{po_units:,.0f} ê°œ")

        if burn_month is None:
            st.info("ì¬ê³ ê°€ ê¸°ê°„ ë‚´ì— ì†Œì§„ë˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
        else:
            day_offset = int(np.clip((burn_in_month_ratio or 1.0) * 30.0, 1, 30))
            st.warning(f"ì˜ˆìƒ ì¬ê³  ì†Œì§„: **{burn_month}** ë‚´ **ì•½ {day_offset}ì¼ì°¨ ì „í›„**(ëŒ€ëµ)")

        st.divider()
        st.markdown("### ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        fig_rev_tm2 = treemap_revenue(rev_share, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        if fig_rev_tm2:
            st.plotly_chart(fig_rev_tm2, use_container_width=True, key=f"rev_tm_brand_ext_{scenario_key}")

        st.divider()
        st.markdown("### ì›”ë³„ ì´ë§¤ì¶œ/íŒë§¤ìˆ˜ëŸ‰(ì™¸ë¶€)")
        df_show = df_m.copy()
        df_show["ì´ë§¤ì¶œ"] = df_show["ì´ë§¤ì¶œ"].map(lambda x: f"{x:,.0f}")
        df_show["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"] = df_show["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].map(lambda x: f"{x:,.0f}")
        df_show["ëˆ„ì íŒë§¤(ê°œ)"] = df_show["ëˆ„ì íŒë§¤(ê°œ)"].map(lambda x: f"{x:,.0f}")
        st.dataframe(df_show, use_container_width=True, hide_index=True)

    else:
        st.markdown("### (ë‚´ë¶€) ìš´ì˜/ê²€ì¦: ë§¤ì¶œ + í•„ìš”ê´‘ê³ ë¹„ + ë§ˆì§„/ì¸ê±´ë¹„ + ì±„ë„ë³„ ë§¤ì¶œ")
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            months = st.selectbox("ê¸°ê°„(ê°œì›”)", options=[3, 6, 12], index=2, key="b_months_int")
        with c2:
            base_month_rev = st.number_input("ì›” ê¸°ì¤€ ì´ë§¤ì¶œ(ì›)", value=200000000, step=10000000, key="b_base_rev_int")
        with c3:
            growth = st.number_input("ì›” ì„±ì¥ë¥ (%)", value=float(scn_month_growth*100.0), step=0.5, key="b_growth_int") / 100.0
        with c4:
            selling_price = st.number_input("ì˜ˆìƒ íŒë§¤ê°€(AOV) (ì›)", value=50000, step=1000, key="b_sell_price_int")

        a1, a2, a3, a4 = st.columns(4)
        with a1:
            use_scn_kpi_b = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPI ìë™ ì‚¬ìš©(ê¶Œì¥)", value=True, key="use_scn_kpi_brand")
        with a2:
            ad_contrib_in = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=float(scn_ad_contrib*100.0), step=1.0, key="b_ad_contrib_int") / 100.0
        with a3:
            repurchase_in = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=float(scn_repurchase*100.0), step=1.0, key="b_repurchase_int") / 100.0
        with a4:
            st.caption("í•„ìš” ê´‘ê³ ë¹„ëŠ” 'ì´ë§¤ì¶œâ†’ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œâ†’ì£¼ë¬¸â†’í´ë¦­â†’CPC'ë¡œ ì—­ì‚°")

        b1, b2 = st.columns(2)
        with b1:
            cpc_manual_b = st.number_input("CPC (ì›) [ìˆ˜ë™]", value=300.0, step=10.0, key="b_cpc_manual")
        with b2:
            cvr_manual_b = st.number_input("CVR (%) [ìˆ˜ë™]", value=2.0, step=0.1, key="b_cvr_manual") / 100.0

        scn_cpc, scn_cvr = blended_cpc_cvr(row, perf_cols)
        cpc_b = scn_cpc if (use_scn_kpi_b and scn_cpc is not None) else float(cpc_manual_b)
        cvr_b = scn_cvr if (use_scn_kpi_b and scn_cvr is not None) else float(cvr_manual_b)

        st.caption(
            f"í˜„ì¬ ì ìš© KPI: CPC {fmt_won(cpc_b)} / CVR {fmt_pct(cvr_b*100,1)} "
            + (f"(ì‹œë‚˜ë¦¬ì˜¤ KPI ê¸°ë°˜)" if use_scn_kpi_b and scn_cpc is not None else "(ìˆ˜ë™ ì…ë ¥)")
        )

        cost1, cost2, cost3, cost4 = st.columns(4)
        with cost1:
            cost_rate = st.number_input("ì›ê°€ìœ¨(%)", value=30.0, step=1.0, key="b_cost_rate") / 100.0
        with cost2:
            logistics = st.number_input("ë¬¼ë¥˜ë¹„(ê±´ë‹¹) (ì›)", value=3000, step=500, key="b_logi")
        with cost3:
            headcount = st.number_input("ìš´ì˜ ì¸ë ¥(ëª…)", value=2, step=1, min_value=0, key="b_hc")
        with cost4:
            cost_per = st.number_input("ì¸ë‹¹ ê³ ì •ë¹„(ì›)", value=3000000, step=100000, key="b_cper")

        fixed_cost = float(headcount) * float(cost_per)

        s1, s2, s3 = st.columns(3)
        with s1:
            current_stock = st.number_input("í˜„ì¬ ì¬ê³ (ê°œ)", value=10000, step=100, key="b_stock_int")
        with s2:
            safety_stock = st.number_input("ì•ˆì „ì¬ê³ (ê°œ)", value=0, step=100, key="b_safety_int")
        with s3:
            start_day = st.date_input("ê¸°ì¤€ì¼(ì¬ê³  ì‹œì‘ì¼)", key="b_startday_int")

        months_idx = list(range(1, int(months) + 1))
        ym_list = [f"M{i}" for i in months_idx]
        rev_list = []
        for i in months_idx:
            factor = (1.0 + growth) ** (i - 1)
            rev_list.append(base_month_rev * factor)

        rows = []
        for ym, rev_i in zip(ym_list, rev_list):
            sim_i = simulate_pl(
                calc_mode="ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ",
                aov=float(selling_price),
                cpc=float(cpc_b),
                cvr=float(cvr_b),
                cost_rate=float(cost_rate),
                logistics_per_order=float(logistics),
                fixed_cost=float(fixed_cost)/max(int(months),1),
                ad_spend=None,
                revenue=float(rev_i),
                ad_contrib_rate=float(ad_contrib_in),
                repurchase_rate=float(repurchase_in),
            )
            units_i = (float(rev_i) / float(selling_price)) if selling_price > 0 else 0.0
            rows.append({
                "ì›”": ym,
                "ì´ë§¤ì¶œ": float(sim_i["revenue"]),
                "í•„ìš”ê´‘ê³ ë¹„": float(sim_i["ad_spend"]),
                "ROAS": float(sim_i["roas"]),
                "ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)": float(units_i),
                "ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ": float(sim_i["ad_revenue"]),
                "ì¬êµ¬ë§¤ë§¤ì¶œ": float(sim_i["repeat_revenue"]),
                "ì˜ì—…ì´ìµ(ì›”)": float(sim_i["profit"]),
            })

        df_fore = pd.DataFrame(rows)
        df_fore["ëˆ„ì íŒë§¤(ê°œ)"] = df_fore["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].cumsum()

        burn_point = float(current_stock)
        burn_month = None
        burn_in_month_ratio = None
        prev = 0.0
        for _, r in df_fore.iterrows():
            cumu = float(r["ëˆ„ì íŒë§¤(ê°œ)"])
            if cumu >= burn_point and burn_month is None:
                burn_month = r["ì›”"]
                month_units = float(r["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"])
                burn_in_month_ratio = ((burn_point - prev) / month_units) if month_units > 0 else 1.0
                break
            prev = cumu

        total_units = float(df_fore["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].sum())
        po_units = max(int(np.ceil(total_units + float(safety_stock) - float(current_stock))), 0)

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("ê¸°ê°„ ì´ë§¤ì¶œ", fmt_won(df_fore["ì´ë§¤ì¶œ"].sum()))
        k2.metric("ê¸°ê°„ í•„ìš” ê´‘ê³ ë¹„", fmt_won(df_fore["í•„ìš”ê´‘ê³ ë¹„"].sum()))
        k3.metric("ê¸°ê°„ ì˜ˆìƒ íŒë§¤ìˆ˜ëŸ‰", f"{total_units:,.0f} ê°œ")
        k4.metric("ê¶Œì¥ ë°œì£¼(í•„ìš”)", f"{po_units:,.0f} ê°œ")

        if burn_month is None:
            st.info("ì¬ê³ ê°€ ê¸°ê°„ ë‚´ì— ì†Œì§„ë˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
        else:
            day_offset = int(np.clip((burn_in_month_ratio or 1.0) * 30.0, 1, 30))
            st.warning(f"ì˜ˆìƒ ì¬ê³  ì†Œì§„: **{burn_month}** ë‚´ **ì•½ {day_offset}ì¼ì°¨ ì „í›„**(ëŒ€ëµ)")

        st.divider()
        df_chart = df_fore.copy()
        df_chart["ROAS"] = df_chart["ì´ë§¤ì¶œ"] / df_chart["í•„ìš”ê´‘ê³ ë¹„"].replace(0, np.nan)
        st.plotly_chart(
            compare_chart(df_chart, "ì›”", "ì´ë§¤ì¶œ", "í•„ìš”ê´‘ê³ ë¹„", "ROAS", title="ì›”ë³„ ì´ë§¤ì¶œ/í•„ìš”ê´‘ê³ ë¹„ + ROAS"),
            use_container_width=True,
            key=f"brand_int_month_chart_{scenario_key}"
        )

        st.divider()
        st.markdown("### ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        fig_rev_tm2 = treemap_revenue(rev_share, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        if fig_rev_tm2:
            st.plotly_chart(fig_rev_tm2, use_container_width=True, key=f"rev_tm_brand_int_{scenario_key}")

        st.divider()
        st.markdown("### (ë‚´ë¶€) íŒë§¤ì±„ë„ë³„ ë§¤ì¶œ ê³„íš(ì›”ë³„)")
        ch_rows = []
        for _, r in df_fore.iterrows():
            ym = r["ì›”"]
            total_rev = float(r["ì´ë§¤ì¶œ"])
            for ch, share in rev_share.items():
                if share <= 0:
                    continue
                ch_rows.append({
                    "ì›”": ym,
                    "ì±„ë„": ch,
                    "ë§¤ì¶œ(ì›)": round_to_100(total_rev * float(share)),
                    "ë¹„ì¤‘(%)": float(share) * 100.0,
                })
        df_ch = pd.DataFrame(ch_rows)
        if df_ch.empty:
            st.info("íŒë§¤ì±„ë„ ë¹„ì¤‘ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(
                df_ch.sort_values(["ì›”", "ë§¤ì¶œ(ì›)"], ascending=[True, False]),
                use_container_width=True,
                hide_index=True
            )

        st.divider()
        st.markdown("### (ë‚´ë¶€) ì›”ë³„ ìƒì„¸ í…Œì´ë¸”")
        disp = df_fore.copy()
        for c in ["ì´ë§¤ì¶œ","í•„ìš”ê´‘ê³ ë¹„","ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ","ì¬êµ¬ë§¤ë§¤ì¶œ","ì˜ì—…ì´ìµ(ì›”)"]:
            disp[c] = disp[c].map(lambda x: f"{x:,.0f}")
        disp["ROAS"] = (df_fore["ì´ë§¤ì¶œ"] / df_fore["í•„ìš”ê´‘ê³ ë¹„"].replace(0, np.nan)).map(lambda x: "-" if pd.isna(x) else f"{x:.2f}x")
        disp["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"] = df_fore["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(ê°œ)"].map(lambda x: f"{x:,.0f}")
        disp["ëˆ„ì íŒë§¤(ê°œ)"] = df_fore["ëˆ„ì íŒë§¤(ê°œ)"].map(lambda x: f"{x:,.0f}")
        st.dataframe(disp, use_container_width=True, hide_index=True)

# =========================
# Tab: Recommendation (Classic Top3 + Compare Panel)
# =========================
with tab_rec:
    st.markdown("## ì¶”ì²œ ì—”ì§„")
    st.markdown("<div class='smallcap'>ì˜ˆì „ ë°©ì‹ Top3 ì¶”ì²œ + ROI/ê³ ì (ì„±ì¥Â·ì¬êµ¬ë§¤Â·ê´‘ê³ ì˜ì¡´) ë¹„êµ</div>", unsafe_allow_html=True)
    st.divider()

    # ---- backdataì˜ ì„±ì¥/ì¬êµ¬ë§¤/ê´‘ê³  ê´€ë ¨ ì»¬ëŸ¼ ìë™ íƒì§€ ----
    col_m_growth = safe_col(df, ["ì›” ì„±ì¥ë¥ ", "ì›”ì„±ì¥ë¥ ", "monthly_growth", "MoM ì„±ì¥ë¥ ", "MoM"])
    col_ad_contrib = safe_col(df, ["ê´‘ê³ ê¸°ì—¬ìœ¨", "ê´‘ê³  ê¸°ì—¬ìœ¨", "ad_contrib", "ad_contribution", "ê´‘ê³ ê¸°ì—¬"])
    col_repurchase = safe_col(df, ["ì¬êµ¬ë§¤ìœ¨", "ì¬êµ¬ë§¤", "repurchase", "repeat_rate"])
    col_ad_dep = safe_col(df, ["ê´‘ê³ ì˜ì¡´ë„", "ê´‘ê³  ì˜ì¡´ë„", "ad_dependency", "ads_dependency", "ad_dep"])


    # ---- ì…ë ¥(ì˜ˆì „ ëŠë‚Œ ìœ ì§€í•˜ë˜, ë¹„êµì— í•„ìš”í•œ ìµœì†Œ ì…ë ¥ë§Œ ì¶”ê°€) ----
    with st.expander("ì…ë ¥ ì¡°ê±´", expanded=True):
        c1, c2, c3, c4 = st.columns(4)

        with c1:
            operator = st.selectbox(
                "ìš´ì˜ ì£¼ì²´",
                ["ë‚´ë¶€ë¸Œëœë“œ ìš´ì˜ì", "ë¸Œëœë“œì‚¬ ìš´ì˜ì(í´ë¼ì´ì–¸íŠ¸)", "ëŒ€í–‰ì‚¬(ë§ˆì¼€íŒ…ë§Œ)"],
                key="rec_operator",
            )
            stage_in = st.selectbox("ë‹¨ê³„(ST)", ["(ë¬´ê´€)"] + uniq_vals(stage_col), key="rec_stage_in") if stage_col in df.columns else "(ë¬´ê´€)"
            cat_in = st.selectbox("ì¹´í…Œê³ ë¦¬", ["(ë¬´ê´€)"] + uniq_vals(cat_col), key="rec_cat_in") if cat_col in df.columns else "(ë¬´ê´€)"

        with c2:
            pos_in = st.selectbox("ê°€ê²© í¬ì§€ì…˜(POS)", ["(ë¬´ê´€)"] + uniq_vals(pos_col), key="rec_pos_in") if pos_col in df.columns else "(ë¬´ê´€)"
            drv_in = st.selectbox("ë“œë¼ì´ë²„(DRV)", ["(ë¬´ê´€)"] + uniq_vals(drv_col), key="rec_drv_in") if drv_col in df.columns else "(ë¬´ê´€)"

        with c3:
            sales_focus = st.selectbox(
                "íŒë§¤ ì¤‘ì‹¬ ì±„ë„(ë¸Œëœë“œì‚¬ ì¤‘ìš” / ëŒ€í–‰ì‚¬ëŠ” ì°¸ê³ ë§Œ)",
                ["(ë¬´ê´€)", "ìì‚¬ëª°", "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", "ì¿ íŒ¡", "ì˜¤í”„ë¼ì¸", "ì˜¨ë¼ì¸(ê¸°íƒ€)"],
                key="rec_sales_focus",
            )
            total_budget = st.number_input("ì´ ê´‘ê³ ì˜ˆì‚°(ì›)", value=50_000_000, step=1_000_000, min_value=1, key="rec_budget2")

        with c4:
            # ë¹„êµ/ROIì— í•„ìš”í•œ ìµœì†Œ ì…ë ¥(ì‚­ì œ ì•„ë‹˜: ì¶”ì²œì—”ì§„ì—ë§Œ ì¶”ê°€)
            aov = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50_000, step=1_000, key="rec_aov")
            gross_margin_pct = st.number_input("ë§ˆì§„ìœ¨(%) (ROI ê³„ì‚°ìš©)", value=50.0, step=1.0, key="rec_gm") / 100.0
            use_scn_kpi = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPI ìë™ ì‚¬ìš©(ê¶Œì¥)", value=True, key="rec_use_kpi")
            run = st.button("Top3 ì¶”ì²œ ê³„ì‚°", use_container_width=True, key="rec_run2")

    if not run:
        st.info("ì…ë ¥ ì¡°ê±´ì„ ì„¤ì •í•˜ê³  **Top3 ì¶”ì²œ ê³„ì‚°**ì„ ëˆ„ë¥´ì„¸ìš”.")
        st.stop()

    # ---- í›„ë³´ ì‹œë‚˜ë¦¬ì˜¤ êµ¬ì„±(ì „ì²´ df ê¸°ì¤€, ì…ë ¥ì¡°ê±´ ë°˜ì˜) ----
    cand = df.copy()

    if stage_col in cand.columns and stage_in != "(ë¬´ê´€)":
        cand = cand[cand[stage_col].astype(str) == stage_in]
    if cat_col in cand.columns and cat_in != "(ë¬´ê´€)":
        cand = cand[cand[cat_col].astype(str) == cat_in]
    if pos_col in cand.columns and pos_in != "(ë¬´ê´€)":
        cand = cand[cand[pos_col].astype(str) == pos_in]
    if drv_col in cand.columns and drv_in != "(ë¬´ê´€)":
        cand = cand[cand[drv_col].astype(str) == drv_in]

    if cand.empty:
        st.warning("ì¡°ê±´ì— ë§ëŠ” í›„ë³´ê°€ ì—†ì–´ ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¶”ì²œí•©ë‹ˆë‹¤.")
        cand = df.copy()

    # ---- ìŠ¤ì½”ì–´ë§(ì˜ˆì „ ê°ì„± ìœ ì§€: ì±„ë„/ë¯¸ë””ì–´ ì •í•© + ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤) ----
    #   - ë¸Œëœë“œì‚¬ëŠ” íŒë§¤ì±„ë„ ê°€ì¤‘ì¹˜ â†‘
    #   - ëŒ€í–‰ì‚¬ëŠ” íŒë§¤ì±„ë„ ê°€ì¤‘ì¹˜ â†“ (ì°¸ê³ ë§Œ)
    W_META = 25.0
    W_SALES = 35.0 if operator != "ëŒ€í–‰ì‚¬(ë§ˆì¼€íŒ…ë§Œ)" else 15.0
    W_MEDIA = 25.0
    W_RISK = 15.0  # ê´‘ê³ ì˜ì¡´/ê´‘ê³ ê¸°ì—¬ìœ¨(íš¨ìœ¨) ê°€ë²¼ìš´ ë°˜ì˜(ë¹„êµíŒ¨ë„ì´ ë©”ì¸)

    target_vec = {"ìì‚¬ëª°":0, "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´":0, "ì¿ íŒ¡":0, "ì˜¤í”„ë¼ì¸":0, "ì˜¨ë¼ì¸(ê¸°íƒ€)":0}
    if sales_focus != "(ë¬´ê´€)":
        target_vec[sales_focus] = 1.0
    target_vec = normalize_shares(target_vec)

    rows = []
    for _, r in cand.iterrows():
        # shares
        rs = build_rev_shares(r, rev_cols)
        ms = build_media_shares(r, perf_cols, viral_cols, brand_cols)

        # 1) ë©”íƒ€ë°ì´í„° ë§¤ì¹­
        meta_score = 0.0
        if stage_col in df.columns and stage_in != "(ë¬´ê´€)" and str(r.get(stage_col)) == stage_in: meta_score += 1.0
        if cat_col in df.columns and cat_in != "(ë¬´ê´€)" and str(r.get(cat_col)) == cat_in: meta_score += 1.0
        if pos_col in df.columns and pos_in != "(ë¬´ê´€)" and str(r.get(pos_col)) == pos_in: meta_score += 1.0
        if drv_col in df.columns and drv_in != "(ë¬´ê´€)" and str(r.get(drv_col)) == drv_in: meta_score += 1.0
        meta_score = meta_score / 4.0  # 0~1

        # 2) íŒë§¤ì±„ë„ ì •í•©(ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        sales_sim = _cosine(_rev_bucket_vec(rs), target_vec) if sales_focus != "(ë¬´ê´€)" else 0.5

        # 3) ë¯¸ë””ì–´ ì •í•©(íŒë§¤í¬ì»¤ìŠ¤ë³„ â€œìˆì–´ì•¼ í•  ë§¤ì²´â€ ê°€ì‚°)
        perf = ms.get("perf", {})
        viral = ms.get("viral", {})
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ê°€ì‚°(ê¸°ì¡´ ì‚­ì œ ì•„ë‹˜: ë¹„êµíŒ¨ë„ì´ ìµœì¢… íŒë‹¨)
        media_score = 0.5
        if sales_focus == "ìì‚¬ëª°":
            media_score = np.clip(_media_kw_share(perf, ["ë©”íƒ€"]) * 2.0 + _media_kw_share(perf, ["êµ¬ê¸€", "Google"]) * 1.0, 0, 1)
        elif sales_focus == "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´":
            media_score = np.clip(_media_kw_share(perf, ["ë„¤ì´ë²„", "SA"]) * 2.0 + _media_kw_share(perf, ["GFA","GDN","DA"]) * 1.0, 0, 1)
        elif sales_focus == "ì¿ íŒ¡":
            media_score = np.clip(_media_kw_share(perf, ["ì™¸ë¶€ëª°PA","ì¿ íŒ¡","PA"]) * 2.2 + _media_kw_share(perf, ["ë©”íƒ€"]) * 1.0, 0, 1)
        else:
            media_score = 0.6 + np.clip(ms["group"].get("í¼í¬ë¨¼ìŠ¤",0)*0.4, 0, 0.4)

        # 4) ë¦¬ìŠ¤í¬/íš¨ìœ¨(ê°€ë³ê²Œë§Œ ì ìˆ˜ì— ë°˜ì˜í•˜ê³ , ë¹„êµíŒ¨ë„ì—ì„œ ìƒì„¸ í™•ì¸)
        ad_dep = _norm01_rate(r.get(col_ad_dep)) if col_ad_dep else np.nan
        ad_contrib = _norm01_rate(r.get(col_ad_contrib)) if col_ad_contrib else np.nan
        risk_score = 0.5
        if not np.isnan(ad_dep):
            risk_score = 1.0 - ad_dep  # ì˜ì¡´ë„ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        if not np.isnan(ad_contrib):
            # ê´‘ê³ ê¸°ì—¬ìœ¨ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ â€œê´‘ê³  ì—†ìœ¼ë©´ ë§¤ì¶œ ìœ ì§€ ì–´ë ¤ì›€â€ -> ê°€ì‚° ë‚®ì¶¤
            risk_score = (risk_score * 0.6) + ((1.0 - ad_contrib) * 0.4)

        score = (meta_score * W_META) + (sales_sim * W_SALES) + (float(media_score) * W_MEDIA) + (float(risk_score) * W_RISK)

        rows.append({
            "scenario_key": str(r[col_scn]).strip(),
            "scenario_disp": str(r[col_disp]).strip(),
            "score": float(score),
            "rev_share": rs,
            "media_share": ms,
            "row": r
        })

    rows = sorted(rows, key=lambda x: x["score"], reverse=True)
    top = rows[:3]
    top10 = rows[:10]

    # ---- Top3 ì¹´ë“œ(ì˜ˆì „ì²˜ëŸ¼ 3ì»¬ëŸ¼) ----
    st.markdown("### Top3 ì¶”ì²œ")
    cA, cB, cC = st.columns(3)

    def _render_card(col, idx, item):
        r = item["row"]
        rs = item["rev_share"]
        ms = item["media_share"]

        # KPI (ì‹œë‚˜ë¦¬ì˜¤ KPI ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤ blendedë¥¼ fallback)
        scn_cpc, scn_cvr = blended_cpc_cvr(r, perf_cols)
        if (not use_scn_kpi) or (scn_cpc is None) or (scn_cvr is None):
            # fallback: í˜„ì¬ ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤ KPI
            fb_cpc, fb_cvr = blended_cpc_cvr(row, perf_cols)
            scn_cpc = fb_cpc if fb_cpc is not None else 300.0
            scn_cvr = fb_cvr if fb_cvr is not None else 0.02

        # ê´‘ê³ ê¸°ì—¬/ì¬êµ¬ë§¤/ê´‘ê³ ì˜ì¡´
        mg = _norm01_rate(r.get(col_m_growth)) if col_m_growth else np.nan
        ac = _norm01_rate(r.get(col_ad_contrib)) if col_ad_contrib else np.nan
        rep = _norm01_rate(r.get(col_repurchase)) if col_repurchase else np.nan
        addep = _norm01_rate(r.get(col_ad_dep)) if col_ad_dep else np.nan

        est = _estimate_now_and_roi(
            budget=float(total_budget),
            aov=float(aov),
            cpc=float(scn_cpc),
            cvr=float(scn_cvr),
            ad_contrib=float(ac if not np.isnan(ac) else 0.6),
            month_growth=float(mg if not np.isnan(mg) else 0.0),
            repurchase=float(rep if not np.isnan(rep) else 0.0),
            ad_dependency=float(addep if not np.isnan(addep) else float(ac if not np.isnan(ac) else 0.6)),
            months=12,
            gross_margin_rate=float(gross_margin_pct),
            )
        ceil = _ceiling_index(
            month_growth=float(mg if not np.isnan(mg) else 0.0),
            repurchase=float(rep if not np.isnan(rep) else 0.0),
            ad_dependency=float(addep if not np.isnan(addep) else 0.0),
        )

        # ì¹´ë“œ
        with col:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            st.markdown(f"### #{idx} {item['scenario_disp']}")
            st.caption(item["scenario_key"])
            m1, m2, m3 = st.columns(3)
            m1.metric("Score", f"{item['score']:.1f}")
            m2.metric("ì˜ˆìƒ ROAS", f"{est['roas']:.2f}x")
            m3.metric("ê³ ì ì§€ìˆ˜", f"{ceil:.2f}")

            m4, m5, m6 = st.columns(3)
            m4.metric("ì˜ˆìƒ ë§¤ì¶œ", fmt_won_compact(est["total_rev"]))
            m5.metric("ê´‘ê³ ë§¤ì¶œ", fmt_won_compact(est["ad_rev"]))
            m6.metric("ROI(ë§ˆì§„)", "-" if np.isnan(est["roi"]) else f"{est['roi']*100:.0f}%")
            st.caption(f"í’€ê°’: ì˜ˆìƒë§¤ì¶œ {fmt_won(est['total_rev'])} / ê´‘ê³ ë§¤ì¶œ {fmt_won(est['ad_rev'])}")

            st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
            # ê·¼ê±° 3ì¤„(ì˜ˆì „ ìŠ¤íƒ€ì¼)
            top_rev = sorted(_rev_bucket_vec(rs).items(), key=lambda x: x[1], reverse=True)[:2]
            top_perf = sorted((ms.get("perf") or {}).items(), key=lambda x: x[1], reverse=True)[:2]
            st.write("**ìš”ì•½ ê·¼ê±°(3ì¤„)**")
            st.write(f"- íŒë§¤ì±„ë„: " + ", ".join([f"{k} {v:.0%}" for k, v in top_rev if v > 0]) if top_rev else "-")
            st.write(f"- í¼í¬ë¨¼ìŠ¤: " + ", ".join([f"{k} {v:.0%}" for k, v in top_perf if v > 0]) if top_perf else "-")
            st.write(f"- ì„±ì¥/ì¬êµ¬ë§¤/ì˜ì¡´: "
                     f"ì„±ì¥ {('-' if np.isnan(mg) else f'{mg*100:.1f}%')} / "
                     f"ì¬êµ¬ë§¤ {('-' if np.isnan(rep) else f'{rep*100:.0f}%')} / "
                     f"ê´‘ê³ ì˜ì¡´ {('-' if np.isnan(addep) else f'{addep*100:.0f}%')}"
                    )

            # ì„ íƒ ë²„íŠ¼(ë°”ë¡œ ì‚¬ì´ë“œë°” ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì´ë™)
            if st.button("ì´ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì„ íƒ", key=f"pick_{item['scenario_key']}"):
                # sel_scnëŠ” sidebar selectbox key
                st.session_state["sel_scn"] = item["scenario_disp"]
                st.rerun()

            st.markdown("</div>", unsafe_allow_html=True)

    if len(top) >= 1: _render_card(cA, 1, top[0])
    if len(top) >= 2: _render_card(cB, 2, top[1])
    if len(top) >= 3: _render_card(cC, 3, top[2])

    # ---- ë¹„êµ íŒ¨ë„(ì—¬ê¸°ì„œ â€œROI ë‚®ì§€ë§Œ ê³ ì  ë†’ì€ ê²ƒâ€ê¹Œì§€ í•œëˆˆì—) ----
    st.divider()
    st.markdown("### ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ(Top10)")
    st.caption("â€˜ì§€ê¸ˆ ROAS/ROIâ€™ vs â€˜ê³ ì (ì„±ì¥Â·ì¬êµ¬ë§¤Â·ê´‘ê³ ì˜ì¡´)â€™ì„ ë™ì‹œì— ë³´ê³  ìµœì¢… ì„ íƒí•˜ì„¸ìš”.")

    cmp_rows = []
    for item in top10:
        r = item["row"]
        scn_cpc, scn_cvr = blended_cpc_cvr(r, perf_cols)
        if (not use_scn_kpi) or (scn_cpc is None) or (scn_cvr is None):
            fb_cpc, fb_cvr = blended_cpc_cvr(row, perf_cols)
            scn_cpc = fb_cpc if fb_cpc is not None else 300.0
            scn_cvr = fb_cvr if fb_cvr is not None else 0.02

        mg = _norm01_rate(r.get(col_m_growth)) if col_m_growth else np.nan
        ac = _norm01_rate(r.get(col_ad_contrib)) if col_ad_contrib else np.nan
        rep = _norm01_rate(r.get(col_repurchase)) if col_repurchase else np.nan
        addep = _norm01_rate(r.get(col_ad_dep)) if col_ad_dep else np.nan

        est = _estimate_now_and_roi(
            budget=float(total_budget),
            aov=float(aov),
            cpc=float(scn_cpc),
            cvr=float(scn_cvr),
            ad_contrib=float(ac if not np.isnan(ac) else 0.6),
            month_growth=float(mg if not np.isnan(mg) else 0.0),
            repurchase=float(rep if not np.isnan(rep) else 0.0),
            ad_dependency=float(addep if not np.isnan(addep) else float(ac if not np.isnan(ac) else 0.6)),
            months=12,
            gross_margin_rate=float(gross_margin_pct),
            )

        ceil = _ceiling_index(
            month_growth=float(mg if not np.isnan(mg) else 0.0),
            repurchase=float(rep if not np.isnan(rep) else 0.0),
            ad_dependency=float(addep if not np.isnan(addep) else 0.0),
        )

        cmp_rows.append({
            "ì‹œë‚˜ë¦¬ì˜¤": item["scenario_disp"],
            "í‚¤": item["scenario_key"],
            "Score": item["score"],
            "ì˜ˆìƒë§¤ì¶œ(ì´)": est["total_rev"],
            "ROAS": est["roas"],
            "ROI(ë§ˆì§„)": est["roi"],
            "ê³ ì ì§€ìˆ˜": ceil,
            "ì›”ì„±ì¥ë¥ ": mg,
            "ì¬êµ¬ë§¤ìœ¨": rep,
            "ê´‘ê³ ê¸°ì—¬ìœ¨": ac,
            "ê´‘ê³ ì˜ì¡´ë„": addep,
        })

    df_cmp = pd.DataFrame(cmp_rows)
    if df_cmp.empty:
        st.info("ë¹„êµí•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë³´ê¸° ì¢‹ì€ í‘œì‹œìš©
        disp = df_cmp.copy()
        disp["ì˜ˆìƒë§¤ì¶œ(ì´)"] = disp["ì˜ˆìƒë§¤ì¶œ(ì´)"].map(lambda x: f"{x:,.0f}")
        disp["ROAS"] = disp["ROAS"].map(lambda x: f"{x:.2f}x")
        disp["ROI(ë§ˆì§„)"] = disp["ROI(ë§ˆì§„)"].map(lambda x: "-" if (pd.isna(x) or np.isnan(x)) else f"{x*100:.0f}%")
        disp["ê³ ì ì§€ìˆ˜"] = disp["ê³ ì ì§€ìˆ˜"].map(lambda x: f"{x:.2f}")
        for c in ["ì›”ì„±ì¥ë¥ ","ì¬êµ¬ë§¤ìœ¨","ê´‘ê³ ê¸°ì—¬ìœ¨","ê´‘ê³ ì˜ì¡´ë„"]:
            disp[c] = disp[c].map(lambda x: "-" if (pd.isna(x) or np.isnan(x)) else f"{x*100:.1f}%")

        st.dataframe(
            disp[["ì‹œë‚˜ë¦¬ì˜¤","Score","ì˜ˆìƒë§¤ì¶œ(ì´)","ROAS","ROI(ë§ˆì§„)","ê³ ì ì§€ìˆ˜","ì›”ì„±ì¥ë¥ ","ì¬êµ¬ë§¤ìœ¨","ê´‘ê³ ì˜ì¡´ë„","ê´‘ê³ ê¸°ì—¬ìœ¨"]],
            use_container_width=True,
            hide_index=True
        )

        # ì‚°ì ë„: x=ROAS, y=ê³ ì ì§€ìˆ˜, size=ì˜ˆìƒë§¤ì¶œ, ìƒ‰=ê´‘ê³ ì˜ì¡´ë„(ìˆìœ¼ë©´)
        plot_df = df_cmp.copy()
        plot_df["ê´‘ê³ ì˜ì¡´ë„"] = plot_df["ê´‘ê³ ì˜ì¡´ë„"].fillna(0.0)
        fig = px.scatter(
            plot_df,
            x="ROAS",
            y="ê³ ì ì§€ìˆ˜",
            size="ì˜ˆìƒë§¤ì¶œ(ì´)",
            color="ê´‘ê³ ì˜ì¡´ë„",
            hover_name="ì‹œë‚˜ë¦¬ì˜¤",
            hover_data=["í‚¤", "Score", "ì›”ì„±ì¥ë¥ ", "ì¬êµ¬ë§¤ìœ¨", "ê´‘ê³ ê¸°ì—¬ìœ¨"],
            title="ROAS(í˜„ì¬ íš¨ìœ¨) vs ê³ ì ì§€ìˆ˜(ì„±ì¥Â·ì¬êµ¬ë§¤Â·ì˜ì¡´ ë¦¬ìŠ¤í¬)"
        )
        fig.update_layout(height=420, margin=dict(t=50, b=10, l=10, r=10))
        st.plotly_chart(fig, use_container_width=True, key="rec_compare_scatter")

        # ìµœì¢… ì„ íƒ(í…Œì´ë¸”ì—ì„œ ë°”ë¡œ)
        pick = st.selectbox("ë¹„êµ í›„ ìµœì¢… ì„ íƒ", options=plot_df["ì‹œë‚˜ë¦¬ì˜¤"].tolist(), key="rec_final_pick")
        if st.button("ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì´ë™", key="rec_go_pick"):
            st.session_state["sel_scn"] = pick
            st.rerun()

# =========================
# Tab: Custom Scenario (ê¸°ì¡´ ìœ ì§€)
# =========================
with tab_custom:
    st.markdown("## ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤")
    st.markdown("<div class='smallcap'>ì‹œë‚˜ë¦¬ì˜¤ ìë™ ë¶„ë°°ê°’ ê¸°ë°˜ìœ¼ë¡œ, ë¹„ì¤‘/ì˜ˆì‚°ì„ ì§ì ‘ ìˆ˜ì •í•´ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    base = st.selectbox("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤(ì´ˆê¸°ê°’)", options=disp_list, index=disp_list.index(sel_disp) if sel_disp in disp_list else 0, key="custom_base")
    base_key = disp_to_key.get(base)
    base_row = df[df[col_scn].astype(str).str.strip() == str(base_key).strip()].iloc[0] if base_key is not None else row

    base_media = build_media_shares(base_row, perf_cols, viral_cols, brand_cols)
    base_group = base_media["group"]

    st.markdown("### 1) ê·¸ë£¹ ë¶„ë°°(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´/ë¸Œëœë“œ)")
    gdf = pd.DataFrame([
        {"ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤", "ë¹„ì¤‘(%)": base_group.get("í¼í¬ë¨¼ìŠ¤", 0) * 100},
        {"ê·¸ë£¹": "ë°”ì´ëŸ´", "ë¹„ì¤‘(%)": base_group.get("ë°”ì´ëŸ´", 0) * 100},
        {"ê·¸ë£¹": "ë¸Œëœë“œ", "ë¹„ì¤‘(%)": base_group.get("ë¸Œëœë“œ", 0) * 100},
    ])
    gdf_e = st.data_editor(gdf, use_container_width=True, hide_index=True, key="custom_group")
    group_custom = normalize_shares({r["ê·¸ë£¹"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in gdf_e.iterrows()})

    st.markdown("### 2) í¼í¬ë¨¼ìŠ¤ ì±„ë„ ë¹„ì¤‘")
    pdf = pd.DataFrame([{"ë§¤ì²´": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["perf"].items() if v > 0])
    if pdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— í¼í¬ë¨¼ìŠ¤ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        perf_custom = {}
    else:
        pdf_e = st.data_editor(pdf, use_container_width=True, hide_index=True, key="custom_perf_share")
        perf_custom = normalize_shares({r["ë§¤ì²´"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in pdf_e.iterrows()})

    st.markdown("### 3) ë°”ì´ëŸ´ ë¹„ì¤‘")
    vdf = pd.DataFrame([{"ë°”ì´ëŸ´ í•­ëª©": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["viral"].items() if v > 0])
    if vdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— ë°”ì´ëŸ´ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        viral_custom = {}
    else:
        vdf_e = st.data_editor(vdf, use_container_width=True, hide_index=True, key="custom_viral_share")
        viral_custom = normalize_shares({r["ë°”ì´ëŸ´ í•­ëª©"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in vdf_e.iterrows()})

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        viral_price_custom = st.data_editor(DEFAULT_VIRAL_PRICE.copy(), num_rows="dynamic", use_container_width=True, key="custom_viral_price")

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥")
    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode_c = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="custom_calc_mode")
    with cB:
        aov_c = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50000, step=1000, key="custom_aov")
    with cC:
        cpc_c = st.number_input("CPC (ì›)", value=300.0, step=10.0, key="custom_cpc")
    with cD:
        cvr_c = st.number_input("CVR (%)", value=2.0, step=0.1, key="custom_cvr") / 100.0

    cX1, cX2 = st.columns(2)
    with cX1:
        ad_contrib_c = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=float(scn_ad_contrib*100.0), step=1.0, key="custom_ad_contrib") / 100.0
    with cX2:
        repurchase_c = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=float(scn_repurchase*100.0), step=1.0, key="custom_repurchase") / 100.0

    if calc_mode_c.startswith("ê´‘ê³ ë¹„"):
        ad_total_c = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="custom_ad_total")
        rev_target_c = None
    else:
        rev_target_c = st.number_input("ëª©í‘œ ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="custom_rev_target")
        ad_total_c = None

    sim_c = simulate_pl(
        calc_mode=calc_mode_c,
        aov=aov_c,
        cpc=cpc_c,
        cvr=cvr_c,
        cost_rate=0.0,
        logistics_per_order=0.0,
        fixed_cost=0.0,
        ad_spend=ad_total_c,
        revenue=rev_target_c,
        ad_contrib_rate=float(ad_contrib_c),
        repurchase_rate=float(repurchase_c),
    )

    st.markdown("### ì»¤ìŠ¤í…€ ê²°ê³¼")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ë§¤ì¶œ(ì´)", fmt_won(sim_c["revenue"]))
    m2.metric("ì˜ˆìƒ ê´‘ê³ ë¹„", fmt_won(sim_c["ad_spend"]))
    m3.metric("ROAS", f"{sim_c['roas']:.2f}x ({sim_c['roas']*100:,.0f}%)")
    m4.metric("ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ", fmt_won(sim_c["ad_revenue"]))

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ë¯¸ë””ì–´ ë¯¹ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("ë°”ì´ëŸ´", 0.0))

    perf_df_c = build_performance_mix_table(perf_custom, perf_budget_c) if perf_custom else pd.DataFrame()
    viral_df_c = build_viral_mix_table(viral_price_custom, viral_medium_shares(viral_custom), viral_budget_c) if viral_custom else pd.DataFrame()

    st.markdown("#### í¼í¬ë¨¼ìŠ¤")
    if perf_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        perf_out_c = perf_df_c
    else:
        perf_out_c = editable_perf_table(perf_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    st.markdown("#### ë°”ì´ëŸ´")
    if viral_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ ë°”ì´ëŸ´ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        viral_out_c = viral_df_c
    else:
        viral_out_c = editable_viral_table(viral_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    fig_ads_tm_c = treemap_ads(perf_out_c, viral_out_c, title="ì»¤ìŠ¤í…€ ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)")
    if fig_ads_tm_c:
        st.plotly_chart(fig_ads_tm_c, use_container_width=True, key="custom_ads_tm")

# =========================
# Tab: Sales Plan (ê¸°ì¡´ ìœ ì§€)
# =========================
with tab_plan:
    st.markdown("## ë§¤ì¶œ ê³„íš (ë¸Œëœë“œë³„ 1~12ì›”)")
    st.markdown("<div class='smallcap'>ë¸Œëœë“œëª…/ì „ëµ ì…ë ¥ ë˜ëŠ” í…œí”Œë¦¿ CSV ì—…ë¡œë“œ â†’ ì›”ë³„ ê³„íšì„ í•œ ë²ˆì— ë³´ê³  í¸ì§‘í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    plan_mode = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥", "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ"], horizontal=True, key="plan_mode")

    if plan_mode == "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ":
        up = st.file_uploader("ë§¤ì¶œ ê³„íš í…œí”Œë¦¿ ì—…ë¡œë“œ(csv)", type=["csv"], key="plan_uploader")
        if up is None:
            st.info("í…œí”Œë¦¿ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ/ê´‘ê³ ë¹„ í”¼ë²— ë·°ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        else:
            plan_raw = pd.read_csv(StringIO(up.getvalue().decode("utf-8-sig", errors="replace")))
            brand_col = safe_col(plan_raw, ["Brand", "ë¸Œëœë“œ", "brand"])
            month_col = safe_col(plan_raw, ["Month", "ì›”", "month"])
            rev_col = safe_col(plan_raw, ["TotalRevenue", "ë§¤ì¶œ", "Revenue", "totalrevenue"])
            bud_col = safe_col(plan_raw, ["Budget", "ê´‘ê³ ë¹„", "AdSpend", "budget"])

            if brand_col is None or month_col is None or rev_col is None:
                st.error("í…œí”Œë¦¿ì—ì„œ Brand/Month/TotalRevenue(ë§¤ì¶œ) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                plan_raw[rev_col] = plan_raw[rev_col].apply(lambda x: to_float(x, 0.0))
                if bud_col and bud_col in plan_raw.columns:
                    plan_raw[bud_col] = plan_raw[bud_col].apply(lambda x: to_float(x, 0.0))

                p_rev = plan_raw.pivot_table(index=brand_col, columns=month_col, values=rev_col, aggfunc="sum").fillna(0.0)
                st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í¸ì§‘ ê°€ëŠ¥)")
                st.data_editor(p_rev.reset_index(), use_container_width=True, key="plan_pivot_rev")

                if bud_col and bud_col in plan_raw.columns:
                    st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ê´‘ê³ ë¹„(í¸ì§‘ ê°€ëŠ¥)")
                    p_bud = plan_raw.pivot_table(index=brand_col, columns=month_col, values=bud_col, aggfunc="sum").fillna(0.0)
                    st.data_editor(p_bud.reset_index(), use_container_width=True, key="plan_pivot_budget")

                totals = p_rev.sum(axis=1).reset_index()
                totals.columns = ["Brand", "TotalRevenue"]
                fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
                fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
                fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
                st.plotly_chart(fig, use_container_width=True, key="plan_bar_total")

    else:
        st.markdown("### ë¸Œëœë“œ ì…ë ¥(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)")
        seed = pd.DataFrame([
            {"Brand": "ë¸Œëœë“œA", "ì „ëµ": "Aggressive", "ì‹œì‘ì›”(YYYY-MM)": "2026-01", "ì›”ë§¤ì¶œ(ì›)": 200000000, "ì›”ê´‘ê³ ë¹„(ì›)": 50000000, "ì›”ì„±ì¥ë¥ (%)": 0.0},
        ])
        plan_in = st.data_editor(seed, num_rows="dynamic", use_container_width=True, key="plan_input")

        def month_add(ym: str, idx: int) -> str:
            y, m = ym.split("-")
            y, m = int(y), int(m)
            m2 = m + (idx - 1)
            y2 = y + (m2 - 1)//12
            m2 = (m2 - 1) % 12 + 1
            return f"{y2:04d}-{m2:02d}"

        rows = []
        for _, r in plan_in.iterrows():
            brand = str(r.get("Brand","")).strip()
            strat = str(r.get("ì „ëµ","")).strip()
            start = str(r.get("ì‹œì‘ì›”(YYYY-MM)","2026-01")).strip()
            base_rev = to_float(r.get("ì›”ë§¤ì¶œ(ì›)",0.0), 0.0)
            base_ad = to_float(r.get("ì›”ê´‘ê³ ë¹„(ì›)",0.0), 0.0)
            gr = to_float(r.get("ì›”ì„±ì¥ë¥ (%)",0.0), 0.0) / 100.0
            if not brand:
                continue
            for i in range(1, 13):
                factor = (1.0 + gr) ** (i - 1)
                rows.append({
                    "Brand": brand,
                    "ì „ëµ": strat,
                    "Month": month_add(start, i),
                    "ë§¤ì¶œ(ì›)": round_to_100(base_rev * factor),
                    "ê´‘ê³ ë¹„(ì›)": round_to_100(base_ad * factor),
                })

        plan_long = pd.DataFrame(rows)
        if plan_long.empty:
            st.info("ë¸Œëœë“œë¥¼ ìµœì†Œ 1ê°œ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.markdown("### ì›”ë³„ ê³„íš(í¸ì§‘ ê°€ëŠ¥)")
            plan_edit = st.data_editor(plan_long, use_container_width=True, key="plan_long_editor")

            st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í”¼ë²—)")
            p = plan_edit.pivot_table(index="Brand", columns="Month", values="ë§¤ì¶œ(ì›)", aggfunc="sum").fillna(0.0)
            st.data_editor(p.reset_index(), use_container_width=True, key="plan_pivot_from_manual")

            totals = p.sum(axis=1).reset_index()
            totals.columns = ["Brand", "TotalRevenue"]
            fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
            fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
            fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
            st.plotly_chart(fig, use_container_width=True, key="plan_bar_total_manual")
