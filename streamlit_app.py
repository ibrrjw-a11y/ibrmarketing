# streamlit_app.py

import streamlit as st
import pandas as pd
import numpy as np
import re
from io import StringIO
from typing import Optional, Dict, List, Tuple
from datetime import date, datetime, timedelta
import calendar

# -------------------------
# Optional dependency: Plotly
# -------------------------
try:
    import plotly.express as px
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except Exception:
    HAS_PLOTLY = False

APP_PASSWORD = "ibrsecret"

# =========================
# Page / Theme
# =========================
st.set_page_config(page_title="ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°", layout="wide")

ACCENT = "#2F6FED"

st.markdown("""
<style>
html, body, [class*="css"]{
  font-size: 14px;
}

/* -------- Card helper (works on both themes) -------- */
.card{
  border-radius: 14px;
  padding: 14px 14px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
}
.card h3{ margin:0; }

/* light theme overrides */
@media (prefers-color-scheme: light){
  .card{
    border: 1px solid rgba(0,0,0,0.08);
    background: #ffffff;
  }
}

/* avoid unreadable text in data editor / dataframes */
div[data-testid="stDataFrame"] div,
div[data-testid="stDataFrame"] span,
div[data-testid="stDataEditor"] div,
div[data-testid="stDataEditor"] span,
div[data-baseweb="select"] * ,
input, textarea{
  opacity: 1 !important;
}

/* small caption */
.smallcap{
  opacity: .75;
  font-size: 12px;
}

/* badge */
.badge{
  display:inline-block;
  padding: 6px 10px;
  border-radius: 999px;
  font-weight: 700;
  font-size: 12px;
  background: rgba(47,111,237,0.14);
  color: rgb(47,111,237);
}

/* section divider look */
hr.soft{
  border: 0;
  border-top: 1px solid rgba(255,255,255,0.10);
  margin: 12px 0;
}
@media (prefers-color-scheme: light){
  hr.soft{ border-top: 1px solid rgba(0,0,0,0.08); }
}
</style>
""", unsafe_allow_html=True)

# =========================
# Early guard: plotly required
# =========================
if not HAS_PLOTLY:
    st.error(
        "âŒ plotlyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        "âœ… í•´ê²°:\n"
        "1) ë¡œì»¬/ì½”ë“œìŠ¤í˜ì´ìŠ¤: `pip install plotly`\n"
        "2) Streamlit Cloud: requirements.txtì— `plotly` ì¶”ê°€\n"
    )
    st.stop()

# =========================
# Auth (Password gate)
# =========================
def auth_gate() -> bool:
    if st.session_state.get("auth_ok", False):
        return True

    st.sidebar.markdown("## ğŸ”’ ì ‘ê·¼ ì œí•œ")
    pw = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pw")
    col1, col2 = st.sidebar.columns([1, 1])
    with col1:
        if st.button("ì ê¸ˆ í•´ì œ", key="auth_unlock"):
            if pw == APP_PASSWORD:
                st.session_state["auth_ok"] = True
                st.rerun()
            else:
                st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤.")
    with col2:
        if st.button("ì´ˆê¸°í™”", key="auth_reset"):
            st.session_state.pop("auth_ok", None)
            st.session_state.pop("auth_pw", None)
            st.rerun()

    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    return False

if not auth_gate():
    st.stop()

# =========================
# Helpers
# =========================
def fmt_won(x) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):,.0f} ì›"
    except Exception:
        return "-"

def fmt_num(x, digits=0) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):,.{digits}f}"
    except Exception:
        return "-"

def fmt_pct(x, digits=1) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):.{digits}f}%"
    except Exception:
        return "-"

def to_float(x, default=0.0) -> float:
    try:
        if pd.isna(x):
            return default
        s = str(x).strip().replace(",", "").replace("â‚©", "")
        s = s.replace("%", "")
        if s == "" or s.lower() == "nan":
            return default
        return float(s)
    except Exception:
        return default

def normalize_ratio(x) -> float:
    """supports 0.32, 32, '32%' -> returns 0~1"""
    v = to_float(x, default=np.nan)
    if np.isnan(v):
        return np.nan
    return (v / 100.0) if v > 1 else v

def normalize_shares(d: Dict[str, float]) -> Dict[str, float]:
    d2 = {k: float(v or 0.0) for k, v in d.items()}
    s = sum(v for v in d2.values() if v > 0)
    if s <= 0:
        return {k: 0.0 for k in d2}
    return {k: (v / s if v > 0 else 0.0) for k, v in d2.items()}

def round_to_100(x) -> int:
    try:
        return int(np.round(float(x) / 100.0) * 100)
    except Exception:
        return 0

def safe_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in df.columns]
    for cand in candidates:
        if cand in cols:
            return cand
    for cand in candidates:
        for c in cols:
            if cand in c:
                return c
    return None

def drop_duplicate_dot_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Drop Excel-style duplicated columns ending with .1/.2 ..."""
    cols = list(df.columns)
    base_seen = set()
    keep = []
    for c in cols:
        cstr = str(c)
        base = re.sub(r"\.\d+$", "", cstr)
        if base in base_seen and cstr != base:
            continue
        base_seen.add(base)
        keep.append(c)
    out = df[keep].copy()
    out.columns = [re.sub(r"\.\d+$", "", str(c)).strip() for c in out.columns]
    return out

def donut_chart(labels, values, title="", height=320):
    dd = pd.DataFrame({"name": labels, "value": values})
    fig = px.pie(dd, names="name", values="value", hole=0.55)
    fig.update_traces(textinfo="percent+label")
    fig.update_layout(height=height, margin=dict(t=40, b=10, l=10, r=10), title=title)
    return fig

# =========================
# Data loading (xlsx/csv)
# =========================
@st.cache_data(show_spinner=False)
def load_backdata_cached(file_bytes: bytes, filename: str) -> pd.DataFrame:
    name = (filename or "").lower()

    if name.endswith(".csv"):
        raw = file_bytes.decode("utf-8-sig", errors="replace")
        df = pd.read_csv(StringIO(raw))
        df = df.dropna(how="all")
        df = drop_duplicate_dot_columns(df)
        df.columns = [str(c).strip() for c in df.columns]
        return df

    try:
        xls = pd.ExcelFile(pd.io.common.BytesIO(file_bytes))
    except Exception as e:
        raise RuntimeError(
            "ì—‘ì…€(xlsx) ë¡œë“œ ì‹¤íŒ¨. Streamlit Cloudë¼ë©´ requirements.txtì— openpyxl ì¶”ê°€ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            f"ì›ì¸: {e}"
        )

    sheet = None
    for s in xls.sheet_names:
        s_norm = str(s).strip().lower()
        if s_norm in ("backdata", "back_data", "back data", "backdata "):
            sheet = s
            break
        if "backdata" in s_norm:
            sheet = s
            break
    if sheet is None:
        for s in xls.sheet_names:
            if str(s).strip().upper() == "BACKDATA":
                sheet = s
                break
    if sheet is None:
        sheet = xls.sheet_names[0]

    df = pd.read_excel(xls, sheet_name=sheet)
    df = df.dropna(how="all")
    df = drop_duplicate_dot_columns(df)
    df.columns = [str(c).strip() for c in df.columns]
    return df

def load_backdata(uploaded_file) -> pd.DataFrame:
    return load_backdata_cached(uploaded_file.getvalue(), uploaded_file.name)

# =========================
# Column detection (v4 with KPI + growth/repurchase/ad_contrib)
# =========================
def detect_columns(df: pd.DataFrame) -> Dict[str, object]:
    col_scn = safe_col(df, ["ì‹œë‚˜ë¦¬ì˜¤ëª…", "scenario", "Scenario"])
    col_disp = safe_col(df, ["ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…", "ë…¸ì¶œì‹œë‚˜ë¦¬ì˜¤ëª…", "display", "í‘œì‹œ ì‹œë‚˜ë¦¬ì˜¤ëª…"])
    if col_scn is None:
        col_scn = df.columns[0]
    if col_disp is None:
        col_disp = df.columns[1] if len(df.columns) > 1 else col_scn

    col_stage = safe_col(df, ["ë‹¨ê³„(ST)", "ë‹¨ê³„", "ST"])
    col_drv = safe_col(df, ["ë“œë¼ì´ë²„(DRV)", "ë“œë¼ì´ë²„", "DRV"])
    col_cat = safe_col(df, ["ì¹´í…Œê³ ë¦¬(ëŒ€)", "ì¹´í…Œê³ ë¦¬", "CAT"])
    col_pos = safe_col(df, ["ê°€ê²©í¬ì§€ì…˜(POS)", "ê°€ê²©í¬ì§€ì…˜", "POS"])

    # âœ… backdata í•µì‹¬
    col_month_growth = safe_col(df, ["ì›”ì„±ì¥ë¥ (%)", "ì›” ì„±ì¥ë¥ ", "monthly growth"])
    col_repurchase = safe_col(df, ["ì¬êµ¬ë§¤ìœ¨(%)", "ì¬êµ¬ë§¤ìœ¨", "repurchase"])
    col_ad_contrib = safe_col(df, ["ê´‘ê³ ê¸°ì—¬ìœ¨(%)", "ê´‘ê³ ê¸°ì—¬ìœ¨", "ad contribution"])

    rev_cols = [c for c in df.columns if str(c).endswith("ë§¤ì¶œë¹„ì¤‘") and c not in [col_scn, col_disp]]

    perf_cols = [
        c for c in df.columns
        if (str(c).startswith("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_") or str(c) == "í¼í¬ë¨¼ìŠ¤_ì™¸ë¶€ëª°PA")
        and not str(c).startswith("KPI_")
    ]
    viral_cols = [c for c in df.columns if str(c).startswith("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_") and not str(c).startswith("KPI_")]

    brand_cols = []
    for c in df.columns:
        s = str(c)
        if s.startswith("KPI_"):
            continue
        if s in ["ë¸Œëœë“œ ë§ˆì¼€íŒ…", "ê¸°íƒ€_ë¸Œëœë“œ", "ê¸°íƒ€ ë¸Œëœë“œ", "ê¸°íƒ€_ë¸Œëœë“œ%"]:
            brand_cols.append(c)
        elif ("ë¸Œëœë“œ" in s and "ë§ˆì¼€íŒ…" in s and not s.startswith("KPI_")):
            brand_cols.append(c)

    apply_internal = safe_col(df, ["apply_internal(ë‚´ë¶€)", "apply_internal", "ë‚´ë¶€ ì ìš©"])
    apply_client = safe_col(df, ["apply_client(ë¸Œëœë“œì‚¬)", "apply_client", "ë¸Œëœë“œì‚¬ ì ìš©"])
    apply_agency = safe_col(df, ["apply_agency(ëŒ€í–‰)", "apply_agency", "ëŒ€í–‰ ì ìš©"])

    return {
        "scenario": col_scn,
        "display": col_disp,
        "stage": col_stage,
        "drv": col_drv,
        "cat": col_cat,
        "pos": col_pos,
        "month_growth": col_month_growth,
        "repurchase": col_repurchase,
        "ad_contrib": col_ad_contrib,
        "rev_cols": rev_cols,
        "perf_cols": perf_cols,
        "viral_cols": viral_cols,
        "brand_cols": brand_cols,
        "kpi_cols": [c for c in df.columns if str(c).startswith("KPI_")],
        "apply_internal": apply_internal,
        "apply_client": apply_client,
        "apply_agency": apply_agency,
    }

def scenario_options(df: pd.DataFrame, col_scn: str, col_disp: str):
    tmp = df[[col_scn, col_disp]].copy()
    tmp[col_scn] = tmp[col_scn].astype(str).str.strip()
    tmp[col_disp] = tmp[col_disp].astype(str).str.strip()
    tmp = tmp.dropna()

    key_to_disp = dict(zip(tmp[col_scn], tmp[col_disp]))
    disp_to_key = {}
    for kk, dd in key_to_disp.items():
        if dd in disp_to_key and disp_to_key[dd] != kk:
            disp_to_key[f"{dd} ({kk})"] = kk
        else:
            disp_to_key[dd] = kk
    disp_list = sorted(list(disp_to_key.keys()))
    return key_to_disp, disp_to_key, disp_list

# =========================
# Media pretty & buckets
# =========================
def pretty_media_name(col: str) -> str:
    c = str(col).strip()
    c = c.replace("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_", "")
    c = c.replace("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_", "")
    c = c.replace("ì”¨ë”©", "ì‹œë”©")
    c = c.replace("ë„¤ì´ë²„ ", "ë„¤ì´ë²„")
    return c

def perf_category(media: str) -> str:
    m = str(media)
    if "SA" in m:
        return "ê²€ìƒ‰ ê´‘ê³ "
    if any(x in m for x in ["GDN", "GFA", "ë©”íƒ€", "í‹±í†¡", "í¬ë¦¬í…Œì˜¤", "í† ìŠ¤"]):
        return "ë””ìŠ¤í”Œë ˆì´/ì†Œì…œ"
    if "ì™¸ë¶€ëª°PA" in m or "ì¿ íŒ¡" in m:
        return "ë§ˆì¼“/PA"
    return "ê¸°íƒ€"

# =========================
# Viral price table (editable)
# =========================
DEFAULT_VIRAL_PRICE = pd.DataFrame([
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸í”Œë£¨ì–¸ì„œíƒ­", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìŠ¤ë§ˆíŠ¸ë¸”ë¡", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì§€ì‹ì¸", 100000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì‡¼í•‘ìƒìœ„", 2000000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸ê¸°ê¸€", 300000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìë™ê²€ìƒ‰ì™„ì„±", 400000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¹´í˜ì¹¨íˆ¬ë°”ì´ëŸ´", 30000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_êµ¬ë§¤ëŒ€í–‰", 120060, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_í•«ë”œ", 100000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_íŒŒì›Œí˜ì´ì§€", 400000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_í•´ì‹œíƒœê·¸ìƒìœ„ë…¸ì¶œ", 500000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_ê³„ì •ìƒìœ„ë…¸ì¶œ", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì§‘ë“¤ì´", 500000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì²´í—˜ë‹¨", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_êµ¬ë§¤ëŒ€í–‰", 200952, 1.0],
    ["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°", "ì»¤ë®¤ë‹ˆí‹°_í•«ë”œ", 200000, 1.0],
], columns=["ë§¤ì²´", "ì§€ë©´", "ê±´ë‹¹ë¹„ìš©", "ë¹„ìœ¨"])

# =========================
# Shares builder
# =========================
def build_rev_shares(row: pd.Series, rev_cols: List[str]) -> Dict[str, float]:
    d = {}
    for c in rev_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v):
            v = 0.0
        name = str(c).replace("ë§¤ì¶œë¹„ì¤‘", "").strip()
        d[name] = float(v)
    return normalize_shares(d)

def build_media_shares(row: pd.Series, perf_cols: List[str], viral_cols: List[str], brand_cols: List[str]):
    perf_raw, viral_raw, brand_raw = {}, {}, {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        perf_raw[pretty_media_name(c)] = float(v)
    for c in viral_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        viral_raw[pretty_media_name(c)] = float(v)
    for c in brand_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        brand_raw[pretty_media_name(c)] = float(v)

    perf_sum = sum(v for v in perf_raw.values() if v > 0)
    viral_sum = sum(v for v in viral_raw.values() if v > 0)
    brand_sum = sum(v for v in brand_raw.values() if v > 0)
    total = perf_sum + viral_sum + brand_sum

    group = {"í¼í¬ë¨¼ìŠ¤": 1.0, "ë°”ì´ëŸ´": 0.0, "ë¸Œëœë“œ": 0.0} if total <= 0 else {
        "í¼í¬ë¨¼ìŠ¤": perf_sum / total,
        "ë°”ì´ëŸ´": viral_sum / total,
        "ë¸Œëœë“œ": brand_sum / total
    }

    return {
        "group": group,
        "perf": normalize_shares(perf_raw),
        "viral": normalize_shares(viral_raw),
        "brand": normalize_shares(brand_raw),
        "raw_sums": {"perf": perf_sum, "viral": viral_sum, "brand": brand_sum},
    }

def viral_medium_shares(viral_share_dict: Dict[str, float]) -> Dict[str, float]:
    buckets = {"ë„¤ì´ë²„": 0.0, "ì¸ìŠ¤íƒ€ê·¸ë¨": 0.0, "ì˜¤ëŠ˜ì˜ì§‘": 0.0, "ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°": 0.0}
    for k, v in viral_share_dict.items():
        kk = str(k)
        if "ë„¤ì´ë²„" in kk:
            buckets["ë„¤ì´ë²„"] += v
        elif "ì¸ìŠ¤íƒ€" in kk:
            buckets["ì¸ìŠ¤íƒ€ê·¸ë¨"] += v
        elif "ì˜¤ëŠ˜ì˜ì§‘" in kk:
            buckets["ì˜¤ëŠ˜ì˜ì§‘"] += v
        else:
            buckets["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°"] += v
    return normalize_shares(buckets)

# =========================
# KPI blending (scenario-specific)
# =========================
def kpi_get(row: pd.Series, media_full: str, metric: str) -> Optional[float]:
    key = f"KPI_{metric}_{media_full}"
    if key in row.index:
        v = to_float(row.get(key), default=np.nan)
        if np.isnan(v):
            return None
        if metric in ("CTR", "CVR") and v > 1:
            v = v / 100.0
        return float(v)
    return None

def derive_cpc_from_cpm_ctr(cpm: Optional[float], ctr: Optional[float]) -> Optional[float]:
    if cpm is None or ctr is None:
        return None
    if cpm <= 0 or ctr <= 0:
        return None
    return float(cpm) / (1000.0 * float(ctr))

def blended_cpc_cvr(row: pd.Series, perf_cols: List[str]) -> Tuple[Optional[float], Optional[float]]:
    raw = {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        raw[str(c)] = float(v)
    shares = normalize_shares(raw)

    cpc_vals, cvr_vals = [], []
    weights_cpc, weights_cvr = [], []

    for media_full, w in shares.items():
        if w <= 0:
            continue

        cpc = kpi_get(row, media_full, "CPC")
        if cpc is None:
            cpm = kpi_get(row, media_full, "CPM")
            ctr = kpi_get(row, media_full, "CTR")
            cpc = derive_cpc_from_cpm_ctr(cpm, ctr)

        cvr = kpi_get(row, media_full, "CVR")

        if cpc is not None and cpc > 0:
            cpc_vals.append(cpc); weights_cpc.append(w)
        if cvr is not None and cvr > 0:
            cvr_vals.append(cvr); weights_cvr.append(w)

    def wavg(vals, ws):
        if not vals or not ws:
            return None
        s = sum(ws)
        if s <= 0:
            return None
        return float(sum(v * w for v, w in zip(vals, ws)) / s)

    return wavg(cpc_vals, weights_cpc), wavg(cvr_vals, weights_cvr)

def roas_from_kpi(aov: float, cpc: float, cvr: float) -> float:
    # spend -> clicks = spend/cpc, orders=clicks*cvr, revenue=orders*aov
    # ROAS = revenue/spend = (aov*cvr)/cpc
    if cpc <= 0:
        return 0.0
    return float(aov) * float(cvr) / float(cpc)

# =========================
# Growth / Repurchase / Ad Contribution model
# =========================
def clamp01(x: float) -> float:
    return float(max(0.0, min(1.0, x)))

def split_revenue(total_rev: float, repurchase_rate: float) -> Dict[str, float]:
    rr = clamp01(repurchase_rate)
    repeat = total_rev * rr
    nonrepeat = total_rev - repeat
    return {"total": total_rev, "repeat": repeat, "nonrepeat": nonrepeat}

def ad_revenue_from_total(total_rev: float, repurchase_rate: float, ad_contrib: float) -> float:
    # ê´‘ê³ ê¸°ì—¬ìœ¨ì€ "ì‹ ê·œ/ë¹„ì¬êµ¬ë§¤ ë§¤ì¶œ(Non-repeat)"ì— ì ìš©
    rr = clamp01(repurchase_rate)
    acr = clamp01(ad_contrib)
    nonrepeat = total_rev * (1.0 - rr)
    return nonrepeat * acr

def total_from_ad_revenue(ad_rev: float, repurchase_rate: float, ad_contrib: float) -> float:
    # ad_rev = total*(1-rr)*acr  => total = ad_rev / ((1-rr)*acr)
    rr = clamp01(repurchase_rate)
    acr = clamp01(ad_contrib)
    denom = (1.0 - rr) * acr
    if denom <= 1e-9:
        return 0.0
    return float(ad_rev) / float(denom)

# =========================
# P&L / Simulation (two-way) with ad_contrib + repurchase
# =========================
def simulate_pl_with_mix(
    calc_mode: str,
    aov: float,
    cpc: float,
    cvr: float,
    cost_rate: float,
    logistics_per_order: float,
    fixed_cost: float,
    ad_spend: Optional[float],
    revenue: Optional[float],
    repurchase_rate: float,
    ad_contrib: float,
):
    rr = clamp01(repurchase_rate)
    acr = clamp01(ad_contrib)

    if calc_mode.startswith("ë§¤ì¶œ"):
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ revenueëŠ” "ì´ë§¤ì¶œ"
        total_rev = float(revenue or 0.0)

        # ì´ë§¤ì¶œ -> ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ(Non-repeatì— acr ì ìš©)
        ad_rev = ad_revenue_from_total(total_rev, rr, acr)

        # ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ -> í•„ìš”í•œ ê´‘ê³ ë¹„
        ad_orders = ad_rev / aov if aov > 0 else 0.0
        clicks = ad_orders / cvr if cvr > 0 else 0.0
        ad_spend = clicks * cpc

    else:
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ad_spendëŠ” ê´‘ê³  ì§‘í–‰ë¹„
        ad_spend = float(ad_spend or 0.0)
        clicks = ad_spend / cpc if cpc > 0 else 0.0
        ad_orders = clicks * cvr
        ad_rev = ad_orders * aov

        # ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ -> ì´ë§¤ì¶œ í™˜ì‚°
        total_rev = total_from_ad_revenue(ad_rev, rr, acr)

    # ì´ë§¤ì¶œ ê¸°ì¤€ ì£¼ë¬¸/ì›ê°€/ì´ìµ ê³„ì‚°
    orders_total = total_rev / aov if aov > 0 else 0.0

    cogs = total_rev * cost_rate
    logistics = orders_total * logistics_per_order
    profit = total_rev - (ad_spend + cogs + logistics + fixed_cost)
    contrib_margin = ((total_rev - ad_spend - logistics - cogs) / total_rev * 100) if total_rev > 0 else 0.0
    roas = (total_rev / ad_spend) if ad_spend and ad_spend > 0 else 0.0

    split = split_revenue(total_rev, rr)

    return {
        "total_revenue": float(total_rev),
        "ad_spend": float(ad_spend),
        "orders_total": float(orders_total),
        "clicks": float(clicks),
        "ad_revenue": float(ad_rev),
        "repeat_revenue": float(split["repeat"]),
        "nonrepeat_revenue": float(split["nonrepeat"]),
        "cogs": float(cogs),
        "logistics": float(logistics),
        "fixed": float(fixed_cost),
        "profit": float(profit),
        "contrib_margin": float(contrib_margin),
        "roas": float(roas),
        "repurchase_rate": rr,
        "ad_contrib": acr,
    }

# =========================
# Mix builders
# =========================
def build_performance_mix_table(perf_share: Dict[str, float], total_perf_budget: float) -> pd.DataFrame:
    rows = []
    for media, share in perf_share.items():
        if share <= 0:
            continue
        budget = round_to_100(total_perf_budget * share)
        rows.append({
            "êµ¬ë¶„": "í¼í¬ë¨¼ìŠ¤",
            "êµ¬ë¶„2": perf_category(media),
            "ë§¤ì²´": media,
            "ì§€ë©´/ìº í˜ì¸": "",
            "ì˜ˆì‚°(ê³„íš)": budget,
            "ëª©í‘œ ROAS(%)": 0.0,
        })
    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["êµ¬ë¶„2", "ë§¤ì²´"]).reset_index(drop=True)

def build_viral_mix_table(
    viral_price_df: pd.DataFrame,
    medium_share: Dict[str, float],
    total_viral_budget: float,
) -> pd.DataFrame:
    rows = []
    vp = viral_price_df.copy()

    for c in ["ë§¤ì²´", "ì§€ë©´"]:
        if c not in vp.columns:
            return pd.DataFrame()

    vp["ê±´ë‹¹ë¹„ìš©"] = vp["ê±´ë‹¹ë¹„ìš©"].apply(lambda x: to_float(x, 0.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].apply(lambda x: to_float(x, 1.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].replace(0, 1.0)

    for medium, mshare in medium_share.items():
        medium_budget = float(total_viral_budget) * float(mshare)
        sub = vp[vp["ë§¤ì²´"] == medium].copy()
        if sub.empty:
            continue

        sub_w = normalize_shares(dict(zip(sub["ì§€ë©´"], sub["ë¹„ìœ¨"])))

        for surface, w in sub_w.items():
            unit = float(sub.loc[sub["ì§€ë©´"] == surface, "ê±´ë‹¹ë¹„ìš©"].iloc[0])
            planned = medium_budget * float(w)
            cnt = int(np.round(planned / unit)) if unit > 0 else 0
            total_cost = cnt * unit
            rows.append({
                "êµ¬ë¶„": "ë°”ì´ëŸ´",
                "êµ¬ë¶„2": "",
                "ë§¤ì²´": medium,
                "ì§€ë©´/ìº í˜ì¸": surface,
                "ê±´ë‹¹ë¹„ìš©": unit,
                "ì§„í–‰ ê±´ìˆ˜": int(cnt),
                "ì˜ˆì‚°(ê³„íš)": round_to_100(total_cost),
            })

    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸"]).reset_index(drop=True)

def unify_mix_table(perf_df: pd.DataFrame, viral_df: pd.DataFrame) -> pd.DataFrame:
    base_cols = ["êµ¬ë¶„", "êµ¬ë¶„2", "ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ì˜ˆì‚°(ê³„íš)"]
    out = []
    if perf_df is not None and not perf_df.empty:
        tmp = perf_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if viral_df is not None and not viral_df.empty:
        tmp = viral_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if not out:
        return pd.DataFrame()
    return pd.concat(out, ignore_index=True)

# =========================
# Treemap builders
# =========================
def rev_bucket(channel_name: str) -> str:
    s = str(channel_name)
    if "ìì‚¬" in s:
        return "ìì‚¬ëª°"
    if "ìŠ¤ë§ˆíŠ¸" in s or "ìŠ¤í† ì–´" in s or "ì˜¨ë¼ì¸(ë§ˆì¼“)" in s:
        return "ì˜¨ë¼ì¸(ë§ˆì¼“)"
    if "ì¿ íŒ¡" in s:
        return "ì˜¨ë¼ì¸(ë§ˆì¼“)"
    if any(k in s for k in ["ì˜¤í”„ë¼ì¸", "ë©´ì„¸", "ë¦¬í…Œì¼", "ë°±í™”ì ", "ë§ˆíŠ¸", "ë“œëŸ­", "ì˜¬ë¦¬ë¸Œì˜"]):
        return "ì˜¤í”„ë¼ì¸"
    if "í™ˆì‡¼í•‘" in s:
        return "í™ˆì‡¼í•‘"
    if "ê³µêµ¬" in s or "ê³µë™" in s:
        return "ê³µêµ¬"
    if "B2B" in s or "ë„ë§¤" in s:
        return "B2B/ë„ë§¤"
    return "ì˜¨ë¼ì¸(ê¸°íƒ€)"

def treemap_revenue(rev_share: Dict[str, float], height=380, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)"):
    rows = []
    for ch, v in rev_share.items():
        if v <= 0:
            continue
        rows.append({"ê·¸ë£¹": rev_bucket(ch), "ì±„ë„": ch, "ë¹„ì¤‘": float(v)})
    if not rows:
        return None
    df = pd.DataFrame(rows)
    fig = px.treemap(df, path=["ê·¸ë£¹", "ì±„ë„"], values="ë¹„ì¤‘", color="ê·¸ë£¹")
    fig.update_layout(height=height, margin=dict(t=50, b=10, l=10, r=10), title=title)
    fig.update_traces(texttemplate="%{label}<br>%{value:.1%}")
    return fig

def treemap_ads(perf_df: pd.DataFrame, viral_df: pd.DataFrame, height=430, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)"):
    rows = []
    if perf_df is not None and not perf_df.empty:
        for _, r in perf_df.iterrows():
            rows.append({
                "ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤",
                "ë§¤ì²´": r.get("ë§¤ì²´",""),
                "ì§€ë©´": r.get("ì§€ë©´/ìº í˜ì¸","") or r.get("ë§¤ì²´",""),
                "ì˜ˆì‚°": float(r.get("ì˜ˆì‚°(ê³„íš)",0) or 0)
            })
    if viral_df is not None and not viral_df.empty:
        for _, r in viral_df.iterrows():
            rows.append({
                "ê·¸ë£¹": "ë°”ì´ëŸ´",
                "ë§¤ì²´": r.get("ë§¤ì²´",""),
                "ì§€ë©´": r.get("ì§€ë©´/ìº í˜ì¸",""),
                "ì˜ˆì‚°": float(r.get("ì˜ˆì‚°(ê³„íš)",0) or 0)
            })
    if not rows:
        return None
    df = pd.DataFrame(rows)
    df = df[df["ì˜ˆì‚°"] > 0]
    if df.empty:
        return None
    fig = px.treemap(df, path=["ê·¸ë£¹", "ë§¤ì²´", "ì§€ë©´"], values="ì˜ˆì‚°", color="ê·¸ë£¹")
    fig.update_layout(height=height, margin=dict(t=50, b=10, l=10, r=10), title=title)
    return fig

# =========================
# Editable tables (perf/viral)
# =========================
def editable_perf_table(perf_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if perf_df.empty:
        return perf_df
    perf_df = perf_df.copy()

    if submode.startswith("ë‚´ë¶€"):
        if "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)" not in perf_df.columns:
            perf_df["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"] = 0.0
        if "í˜ì´ë°±ë¥ (%)" not in perf_df.columns:
            perf_df["í˜ì´ë°±ë¥ (%)"] = 0.0

        edited = st.data_editor(
            perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "í˜ì´ë°±ë¥ (%)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
            key=f"{key_prefix}_perf_editor_int",
        )
        outp = perf_df.copy()
        outp.update(edited)

        outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outp["ì²­êµ¬ì˜ˆìƒë¹„ìš©"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (1.0 + float(r["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"]) / 100.0)), axis=1
        )
        outp["í˜ì´ë°±ì˜ˆìƒì•¡"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (float(r["í˜ì´ë°±ë¥ (%)"]) / 100.0)), axis=1
        )

        st.dataframe(
            outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "ì²­êµ¬ì˜ˆìƒë¹„ìš©", "í˜ì´ë°±ë¥ (%)", "í˜ì´ë°±ì˜ˆìƒì•¡"]],
            use_container_width=True,
            hide_index=True
        )
        return outp

    edited = st.data_editor(
        perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
        key=f"{key_prefix}_perf_editor_ext",
    )
    outp = perf_df.copy()
    outp.update(edited)
    outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    st.dataframe(outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]], use_container_width=True, hide_index=True)
    return outp

def editable_viral_table(viral_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if viral_df.empty:
        return viral_df

    viral_df = viral_df.copy()
    viral_df["ì˜ˆì‚°(ê³„íš)"] = viral_df["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    viral_df["ì§„í–‰ ê±´ìˆ˜"] = viral_df["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))

    if submode.startswith("ë‚´ë¶€"):
        if "ì‹¤ì§‘í–‰ë¹„(ì›)" not in viral_df.columns:
            viral_df["ì‹¤ì§‘í–‰ë¹„(ì›)"] = 0.0

        edited = st.data_editor(
            viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
            key=f"{key_prefix}_viral_editor_int",
        )
        outv = viral_df.copy()
        outv.update(edited)

        outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
        outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
        outv["ì‹¤ì§‘í–‰ë¹„(ì›)"] = outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outv["ë§ˆì§„(ì›)"] = outv["ì˜ˆì‚°(ê³„íš)"].astype(float) - outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].astype(float)

        st.dataframe(
            outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)", "ë§ˆì§„(ì›)"]],
            use_container_width=True,
            hide_index=True
        )
        return outv

    edited = st.data_editor(
        viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
        key=f"{key_prefix}_viral_editor_ext",
    )
    outv = viral_df.copy()
    outv.update(edited)
    outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
    outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
    st.dataframe(outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]], use_container_width=True, hide_index=True)
    return outv

# =========================
# Stock depletion schedule
# =========================
def month_days(yyyy: int, mm: int) -> int:
    return calendar.monthrange(yyyy, mm)[1]

def build_monthly_forecast(
    start_ym: str,
    months: int,
    base_month_rev: float,
    monthly_growth: float,
    aov: float,
    repurchase_rate: float,
    ad_contrib: float,
    roas_ad: float,  # ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ ê¸°ì¤€ ROAS(= ê´‘ê³ ë§¤ì¶œ/ê´‘ê³ ë¹„)
) -> pd.DataFrame:
    # start_ym: "YYYY-MM"
    y, m = start_ym.split("-")
    y0, m0 = int(y), int(m)

    rows = []
    for i in range(months):
        yy = y0 + (m0 - 1 + i) // 12
        mm = (m0 - 1 + i) % 12 + 1
        ym = f"{yy:04d}-{mm:02d}"

        factor = (1.0 + monthly_growth) ** i
        total_rev = float(base_month_rev) * factor

        ad_rev = ad_revenue_from_total(total_rev, repurchase_rate, ad_contrib)
        need_ad = (ad_rev / roas_ad) if roas_ad > 0 else 0.0

        units = (total_rev / aov) if aov > 0 else 0.0
        split = split_revenue(total_rev, repurchase_rate)

        rows.append({
            "ì›”": ym,
            "ì´ë§¤ì¶œ": total_rev,
            "ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ": ad_rev,
            "í•„ìš”ê´‘ê³ ë¹„": need_ad,
            "ì¬êµ¬ë§¤ë§¤ì¶œ": split["repeat"],
            "ë¹„ì¬êµ¬ë§¤ë§¤ì¶œ": split["nonrepeat"],
            "ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)": units,
        })

    dfm = pd.DataFrame(rows)
    return dfm

def calc_depletion_date(
    start_date: date,
    initial_stock: int,
    forecast_df: pd.DataFrame,
) -> Tuple[Optional[date], pd.DataFrame]:
    # ì¼ë³„ë¡œ ìª¼ê°œì„œ ì†Œì§„ì¼ ì¶”ì •
    stock = float(initial_stock)
    cur = start_date

    rows = []
    for _, r in forecast_df.iterrows():
        ym = str(r["ì›”"])
        yy, mm = int(ym.split("-")[0]), int(ym.split("-")[1])
        days = month_days(yy, mm)
        units_month = float(r.get("ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)", 0.0) or 0.0)
        daily = units_month / days if days > 0 else 0.0

        for _d in range(days):
            if stock <= 0:
                return cur, pd.DataFrame(rows)
            stock -= daily
            rows.append({
                "ì¼ì": cur.isoformat(),
                "ì¼íŒë§¤(ì¶”ì •)": daily,
                "ì”ì—¬ì¬ê³ (ì¶”ì •)": max(stock, 0.0),
            })
            cur += timedelta(days=1)

    # ê¸°ê°„ ë‚´ ì†Œì§„ ì•ˆë¨
    return None, pd.DataFrame(rows)

# =========================
# Recommendation (simple Top3 across scenarios)
# =========================
def focus_match_score(rev_share: Dict[str, float], focus: str) -> float:
    if focus == "ìì‚¬ëª°":
        kw = ["ìì‚¬"]
    elif focus == "ì˜¨ë¼ì¸(ë§ˆì¼“)":
        kw = ["ì˜¨ë¼ì¸", "ë§ˆì¼“", "ìŠ¤ë§ˆíŠ¸", "ìŠ¤í† ì–´", "ì¿ íŒ¡"]
    elif focus == "í™ˆì‡¼í•‘":
        kw = ["í™ˆì‡¼í•‘"]
    elif focus == "ê³µêµ¬":
        kw = ["ê³µêµ¬", "ê³µë™"]
    elif focus == "B2B/ë„ë§¤":
        kw = ["B2B", "ë„ë§¤"]
    else:
        kw = []
    if not kw:
        return 0.0
    s = 0.0
    for k, v in rev_share.items():
        if any(x in str(k) for x in kw):
            s += float(v)
    return float(s)

def strategy_recommendation_from_revshare(rev_share: Dict[str, float]) -> Dict[str, object]:
    # ê¸°ì¡´ ë£° ê¸°ë°˜(ë„ˆê°€ ì˜ˆì „ì— ë§í•œ ë£° ë°˜ì˜)
    def share_contains(keyword: str) -> float:
        return sum(float(v) for k, v in rev_share.items() if keyword in str(k))

    own = share_contains("ìì‚¬")
    smart = share_contains("ìŠ¤ë§ˆíŠ¸") + share_contains("ìŠ¤í† ì–´") + share_contains("ì˜¨ë¼ì¸")
    coupang = share_contains("ì¿ íŒ¡")
    home = share_contains("í™ˆì‡¼í•‘")
    groupbuy = share_contains("ê³µêµ¬") + share_contains("ê³µë™")

    if home >= max(own, smart, coupang, groupbuy) and home > 0:
        title = "í™ˆì‡¼í•‘ ì—°ê³„í˜•"
        priority = [
            ("Naver SA", "í™ˆì‡¼í•‘ ìœ ì…/ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜ ì¤‘ì‹¬"),
            ("ë„¤ì´ë²„ ë¸”ë¡œê·¸Â·ì½˜í…ì¸ ", "ê²€ìƒ‰ ì‹ ë¢°/í›„ê¸°Â·ì •ë³´ì„± ë³´ê°•"),
            ("ì¿ íŒ¡ PA", "ë°©ì†¡ í›„ ìˆ˜ìš”ë¥¼ ë§ˆì¼“ì—ì„œ í¡ìˆ˜"),
        ]
        note = "ì´ ì¼€ì´ìŠ¤ëŠ” ë©”íƒ€/êµ¬ê¸€ ì§‘í–‰ì€ ì œì™¸(ë˜ëŠ” ìµœì†Œ) ê¶Œì¥"
    elif groupbuy >= max(own, smart, coupang, home) and groupbuy > 0:
        title = "ê³µêµ¬(ê·¸ë£¹ë°”ì‰) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì¸í”Œë£¨ì–¸ì„œ(ì¸ìŠ¤íƒ€ ë©”ê°€)", "ê³µêµ¬ëŠ” â€˜íŒë§¤ì íŒŒì›Œ/ì‹ ë¢°â€™ê°€ ë§¤ì¶œì„ ì¢Œìš°"),
            ("ë°”ì´ëŸ´(í•«ë”œ/ì»¤ë®¤ë‹ˆí‹°)", "êµ¬ë§¤ íŠ¸ë¦¬ê±°Â·í™•ì‚°"),
            ("ì™¸ë¶€ëª°/ì œíœ´ PA", "ê³µêµ¬ ì™¸ ì¶”ê°€ íŒë§¤ë¶„ í¡ìˆ˜"),
        ]
        note = "í¼í¬ë¨¼ìŠ¤ë³´ë‹¤ â€˜íŒë§¤ì/ì½˜í…ì¸  ë“œë¼ì´ë¸Œâ€™ê°€ ìš°ì„ "
    elif coupang >= max(own, smart, home, groupbuy) and coupang > 0:
        title = "ì¿ íŒ¡(ë§ˆì¼“) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì™¸ë¶€ëª° PA(ì¿ íŒ¡)", "ê°€ì¥ ì§ì ‘ì ì¸ ë§¤ì¶œ ê²¬ì¸ ë ˆë²„"),
            ("ë©”íƒ€", "ë¦¬íƒ€ê²Ÿ/í™•ì¥ ë° ìˆ˜ìš” ìƒì„±(ë³´ì¡°)"),
            ("ë„¤ì´ë²„ SA", "ë³´ì¡° ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
        ]
        note = "ì¿ íŒ¡ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ PA 1ìˆœìœ„, ê·¸ ë‹¤ìŒ ë©”íƒ€ê°€ ìì—°ìŠ¤ëŸ¬ì›€"
    elif smart >= max(own, coupang, home, groupbuy) and smart > 0:
        title = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(ë„¤ì´ë²„) ì¤‘ì‹¬í˜•"
        priority = [
            ("Naver SA", "ê²€ìƒ‰ ê¸°ë°˜ ì „í™˜ í™•ë³´"),
            ("ë„¤ì´ë²„ DA/GFA", "ë„¤ì´ë²„ ìƒíƒœê³„ ë‚´ í™•ì¥"),
            ("ë°”ì´ëŸ´(ë„¤ì´ë²„ ì§€ë©´)", "ìŠ¤ë§ˆíŠ¸ë¸”ë¡/ì½˜í…ì¸  ì—°ê³„"),
        ]
        note = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë„¤ì´ë²„ ë¹„ì¤‘ì„ ë†’ì´ëŠ” ê²Œ ì¼ê´€ë¨"
    elif own >= max(smart, coupang, home, groupbuy) and own > 0:
        title = "ìì‚¬ëª° ì¤‘ì‹¬í˜•"
        priority = [
            ("ë©”íƒ€", "ìì‚¬ëª°ì€ ëœë”©/ë¦¬íƒ€ê²Ÿ ì„¤ê³„ ê°•ì  â†’ íš¨ìœ¨ ê¸°ëŒ€"),
            ("Google(ì„ íƒ)", "ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜(ìƒí’ˆ/ë¸Œëœë“œ ê²€ìƒ‰ ì¤‘ì‹¬)"),
            ("ë„¤ì´ë²„ SA(ì„ íƒ)", "êµ­ë‚´ ê²€ìƒ‰ ìˆ˜ìš” ë³´ì¡°"),
        ]
        note = "ìì‚¬ëª° ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë©”íƒ€ ë¹„ì¤‘ì„ í‚¤ìš°ëŠ” ë£°ì´ ì˜ ë§ìŒ"
    else:
        title = "í˜¼í•©í˜•(ê· í˜• ìš´ì˜)"
        priority = [
            ("Naver SA", "ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
            ("ë©”íƒ€", "ìˆ˜ìš” ìƒì„±/ë¦¬íƒ€ê²Ÿ"),
            ("ë§ˆì¼“ PA", "ë³´ìœ  ì±„ë„ì—ì„œ ë§¤ì¶œ í¡ìˆ˜"),
        ]
        note = "ì±„ë„ì´ ì¹˜ìš°ì¹˜ì§€ ì•Šìœ¼ë©´ 3ì¶• ê· í˜• ìš´ì˜ ê¶Œì¥"

    top3 = sorted(rev_share.items(), key=lambda x: x[1], reverse=True)[:3]
    evidence = [f"{k}: {v*100:.1f}%" for k, v in top3 if v > 0]
    return {"title": title, "priority": priority, "note": note, "evidence": evidence}

# =========================
# Sidebar - Upload
# =========================
st.sidebar.title("ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°")

uploaded = st.sidebar.file_uploader(
    "Backdata ì—…ë¡œë“œ (xlsx/csv)",
    type=["xlsx", "csv"],
    key="backdata_uploader"
)

if st.sidebar.button("ì—…ë¡œë“œ ì´ˆê¸°í™”", key="reset_uploader"):
    st.session_state.pop("backdata_uploader", None)
    st.cache_data.clear()
    st.rerun()

if uploaded is None:
    st.info("ì¢Œì¸¡ì—ì„œ backdata íŒŒì¼(xlsx/csv)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

try:
    df = load_backdata(uploaded)
except Exception as e:
    st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

cols = detect_columns(df)
col_scn = cols["scenario"]
col_disp = cols["display"]

if col_scn not in df.columns:
    st.error("âŒ 'ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

if col_disp not in df.columns:
    st.warning("âš ï¸ 'ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì´ ì—†ì–´, ì‹œë‚˜ë¦¬ì˜¤ëª…ì„ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤.")
    df[col_disp] = df[col_scn].astype(str)

key_to_disp, disp_to_key, disp_list = scenario_options(df, col_scn, col_disp)

stage_col, drv_col, cat_col, pos_col = cols["stage"], cols["drv"], cols["cat"], cols["pos"]

def uniq_vals(c):
    if c is None or c not in df.columns:
        return []
    return sorted([x for x in df[c].dropna().astype(str).unique().tolist() if str(x).strip() != ""])

st.sidebar.markdown("---")
st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ í•„í„°")
f_search = st.sidebar.text_input("ê²€ìƒ‰(ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…)", value="", key="f_search")
f_stage = st.sidebar.selectbox("ë‹¨ê³„(ST)", ["(ì „ì²´)"] + uniq_vals(stage_col), key="f_stage")
f_cat = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬", ["(ì „ì²´)"] + uniq_vals(cat_col), key="f_cat")
f_pos = st.sidebar.selectbox("ê°€ê²© í¬ì§€ì…˜(POS)", ["(ì „ì²´)"] + uniq_vals(pos_col), key="f_pos")
f_drv = st.sidebar.selectbox("ë“œë¼ì´ë²„(DRV)", ["(ì „ì²´)"] + uniq_vals(drv_col), key="f_drv")

apply_internal = cols.get("apply_internal")
apply_client = cols.get("apply_client")
apply_agency = cols.get("apply_agency")

st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ ë…¸ì¶œ í•„í„°(ì˜µì…˜)")
show_internal = st.sidebar.toggle("ë‚´ë¶€ìš© ì ìš©ë§Œ", value=False, key="show_internal")
show_client = st.sidebar.toggle("ë¸Œëœë“œì‚¬ìš© ì ìš©ë§Œ", value=False, key="show_client")
show_agency = st.sidebar.toggle("ëŒ€í–‰ìš© ì ìš©ë§Œ", value=False, key="show_agency")

df_f = df.copy()
if f_stage != "(ì „ì²´)" and stage_col in df_f.columns:
    df_f = df_f[df_f[stage_col].astype(str) == f_stage]
if f_cat != "(ì „ì²´)" and cat_col in df_f.columns:
    df_f = df_f[df_f[cat_col].astype(str) == f_cat]
if f_pos != "(ì „ì²´)" and pos_col in df_f.columns:
    df_f = df_f[df_f[pos_col].astype(str) == f_pos]
if f_drv != "(ì „ì²´)" and drv_col in df_f.columns:
    df_f = df_f[df_f[drv_col].astype(str) == f_drv]

def _apply_flag_filter(df_, flag_col):
    if flag_col and flag_col in df_.columns:
        return df_[df_[flag_col].astype(str).str.strip().isin(["1","True","TRUE","Y","y","O","o"])]
    return df_

if show_internal:
    df_f = _apply_flag_filter(df_f, apply_internal)
if show_client:
    df_f = _apply_flag_filter(df_f, apply_client)
if show_agency:
    df_f = _apply_flag_filter(df_f, apply_agency)

disp_candidates = sorted(list(set(df_f[col_disp].dropna().astype(str).str.strip().tolist())))
if f_search.strip():
    s = f_search.strip()
    disp_candidates = [x for x in disp_candidates if s in x]
if not disp_candidates:
    st.sidebar.warning("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•˜ì„¸ìš”.")
    disp_candidates = disp_list

sel_disp = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ", options=disp_candidates, key="sel_scn")

scenario_key = disp_to_key.get(sel_disp)
if scenario_key is None:
    scenario_key = next((k0 for k0, d0 in key_to_disp.items() if d0 == sel_disp), None)
if scenario_key is None:
    st.error("âŒ ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‚´ë¶€í‚¤ë¡œ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

row_df = df[df[col_scn].astype(str).str.strip() == str(scenario_key).strip()]
if row_df.empty:
    st.error("âŒ ì‹œë‚˜ë¦¬ì˜¤ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()
row = row_df.iloc[0]

rev_cols = cols["rev_cols"]
perf_cols = cols["perf_cols"]
viral_cols = cols["viral_cols"]
brand_cols = cols["brand_cols"]

rev_share = build_rev_shares(row, rev_cols)
media_share = build_media_shares(row, perf_cols, viral_cols, brand_cols)
group_share = media_share["group"]

# âœ… backdata í•µì‹¬ íŒŒë¼ë¯¸í„°(ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë³¸ê°’)
col_growth = cols.get("month_growth")
col_repurchase = cols.get("repurchase")
col_ad_contrib = cols.get("ad_contrib")

default_monthly_growth = to_float(row.get(col_growth), 0.0) / 100.0 if col_growth else 0.0
default_repurchase = to_float(row.get(col_repurchase), 0.0) / 100.0 if col_repurchase else 0.0
default_ad_contrib = to_float(row.get(col_ad_contrib), 0.0) / 100.0 if col_ad_contrib else 0.0

# =========================
# Main Tabs
# =========================
tab_guide, tab_agency, tab_brand, tab_rec, tab_custom, tab_plan = st.tabs(
    ["ì•ˆë‚´", "ëŒ€í–‰", "ë¸Œëœë“œì‚¬", "ì¶”ì²œì—”ì§„", "ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤", "ë§¤ì¶œ ê³„íš"]
)

# =========================
# Tab: Guide
# =========================
with tab_guide:
    st.markdown("## ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown(
        f"""
<div class="card">
<h3>ì´ ì‹œë®¬ë ˆì´í„°ëŠ” ë¬´ì—‡ì„ í•˜ë‚˜ìš”?</h3>
<hr class="soft"/>
<ul>
  <li><b>ì‹œë‚˜ë¦¬ì˜¤(backdata)</b>ë¥¼ ì„ íƒí•˜ë©´, í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ <b>ë§¤ì¶œ ì±„ë„ ë¹„ì¤‘</b>ê³¼ <b>ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë¹„ì¤‘</b>ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.</li>
  <li><b>ëŒ€í–‰</b> íƒ­: ê´‘ê³ ë¹„â†”ë§¤ì¶œ ì–‘ë°©í–¥ ì‚°ì¶œ + (ë‚´ë¶€) ì¸ê±´ë¹„/ê³ ì •ë¹„ í¬í•¨ ì†ìµ</li>
  <li><b>ë¸Œëœë“œì‚¬</b> íƒ­: ì›”ì„±ì¥ë¥ /ê´‘ê³ ê¸°ì—¬ìœ¨/ì¬êµ¬ë§¤ìœ¨ì„ ë°˜ì˜í•œ ì›”ë³„ ë§¤ì¶œ ì „ë§ + (ë‚´ë¶€) í•„ìš” ê´‘ê³ ë¹„/ë§ˆì§„/ì¬ê³  ì†Œì§„</li>
  <li><b>ì¶”ì²œì—”ì§„</b> íƒ­: ë§¤ì¶œì±„ë„ ë¹„ì¤‘ ê¸°ë°˜ìœ¼ë¡œ Top3 ì‹œë‚˜ë¦¬ì˜¤ ì¶”ì²œ(ê°„ë‹¨ ì ìˆ˜)</li>
</ul>
<hr class="soft"/>
<h3>Backdata ë°˜ì˜(ì¤‘ìš”)</h3>
<ul>
  <li><b>ì›”ì„±ì¥ë¥ </b>: ì›”ë³„ ì´ë§¤ì¶œì„ ì„±ì¥ì‹œí‚µë‹ˆë‹¤.</li>
  <li><b>ê´‘ê³ ê¸°ì—¬ìœ¨</b>: (ë¹„ì¬êµ¬ë§¤ ë§¤ì¶œ)ì— ëŒ€í•´ ê´‘ê³ ê°€ ë§Œë“  ë§¤ì¶œ ë¹„ì¤‘ìœ¼ë¡œ ê°€ì •í•˜ì—¬ í•„ìš” ê´‘ê³ ë¹„ë¥¼ ì—­ì‚°í•©ë‹ˆë‹¤.</li>
  <li><b>ì¬êµ¬ë§¤ìœ¨</b>: ì´ë§¤ì¶œ ì¤‘ ì¬êµ¬ë§¤ ë§¤ì¶œ ë¹„ì¤‘ì„ ë¶„ë¦¬í•´ (ë‚´ë¶€)ì—ì„œ ë§¤ì¶œ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>
</ul>
</div>
        """,
        unsafe_allow_html=True
    )

# =========================
# Tab: Agency
# =========================
with tab_agency:
    st.markdown("## ëŒ€í–‰ ëª¨ë“œ")
    submode = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(í´ë¼ì´ì–¸íŠ¸ ì œì•ˆìš©)", "ë‚´ë¶€(ìš´ì˜/ì •ì‚°ìš©)"], horizontal=True, key="agency_sub")

    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì…ë ¥ (ì‹œë®¬ë ˆì´ì…˜)")
    use_scn_kpi = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPI ìë™ ì‚¬ìš©(ê¶Œì¥)", value=True, key="use_scn_kpi_ag")

    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="calc_mode_ag")
    with cB:
        aov = st.number_input("ê°ë‹¨ê°€(AOV=í‰ê·  íŒë§¤ê°€) (ì›)", value=50000, step=1000, key="aov_ag")
    with cC:
        cpc_manual = st.number_input("CPC (ì›) [ìˆ˜ë™]", value=300.0, step=10.0, key="cpc_ag")
    with cD:
        cvr_manual = st.number_input("CVR (%) [ìˆ˜ë™]", value=2.0, step=0.1, key="cvr_ag") / 100.0

    scn_cpc, scn_cvr = blended_cpc_cvr(row, perf_cols)
    cpc = scn_cpc if (use_scn_kpi and scn_cpc is not None) else float(cpc_manual)
    cvr = scn_cvr if (use_scn_kpi and scn_cvr is not None) else float(cvr_manual)

    # âœ… backdata ë°˜ì˜ íŒŒë¼ë¯¸í„°(ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë³¸ê°’)
    c1, c2, c3 = st.columns(3)
    with c1:
        ad_contrib = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=float(default_ad_contrib*100), step=1.0, key="ag_ad_contrib") / 100.0
    with c2:
        repurchase = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=float(default_repurchase*100), step=1.0, key="ag_repurchase") / 100.0
    with c3:
        st.caption("â€» ê´‘ê³ ê¸°ì—¬ìœ¨ì€ â€˜ë¹„ì¬êµ¬ë§¤ ë§¤ì¶œâ€™ì— ì ìš©(ê°€ì •)")

    st.caption(
        f"í˜„ì¬ ì ìš© KPI: CPC {fmt_won(cpc)} / CVR {fmt_pct(cvr*100,1)} "
        + (f"(ì‹œë‚˜ë¦¬ì˜¤ KPI ê¸°ë°˜)" if use_scn_kpi and scn_cpc is not None else "(ìˆ˜ë™ ì…ë ¥)")
    )

    # ë¹„ìš© ì…ë ¥(ë‚´ë¶€ë§Œ)
    if submode.startswith("ë‚´ë¶€"):
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            cost_rate = st.number_input("ì›ê°€ìœ¨(%)", value=30.0, step=1.0, key="cr_ag") / 100.0
        with c2:
            logistics = st.number_input("ë¬¼ë¥˜ë¹„(ê±´ë‹¹) (ì›)", value=3000, step=500, key="logi_ag")
        with c3:
            headcount = st.number_input("ìš´ì˜ ì¸ë ¥(ëª…)", value=2, step=1, min_value=0, key="hc_ag")
        with c4:
            cost_per = st.number_input("ì¸ë‹¹ ê³ ì •ë¹„(ì›)", value=3000000, step=100000, key="cper_ag")
        fixed_cost = float(headcount) * float(cost_per)
    else:
        cost_rate = 0.0
        logistics = 0.0
        fixed_cost = 0.0

    if calc_mode.startswith("ê´‘ê³ ë¹„"):
        ad_total = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="ad_total_ag")
        rev_target = None
    else:
        rev_target = st.number_input("ëª©í‘œ ì´ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="rev_target_ag")
        ad_total = None

    sim = simulate_pl_with_mix(
        calc_mode=calc_mode,
        aov=aov,
        cpc=cpc,
        cvr=cvr,
        cost_rate=cost_rate,
        logistics_per_order=logistics,
        fixed_cost=fixed_cost,
        ad_spend=ad_total,
        revenue=rev_target,
        repurchase_rate=repurchase,
        ad_contrib=ad_contrib,
    )

    st.divider()
    st.markdown("### ê²°ê³¼ ìš”ì•½")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ì´ë§¤ì¶œ", fmt_won(sim["total_revenue"]))
    m2.metric("í•„ìš”/ì§‘í–‰ ê´‘ê³ ë¹„", fmt_won(sim["ad_spend"]))
    m3.metric("ì˜ˆìƒ ì£¼ë¬¸ìˆ˜(Units)", f"{sim['orders_total']:,.0f}")
    m4.metric("ì´ ROAS", f"{sim['roas']:.2f}x ({sim['roas']*100:,.0f}%)")

    # ë‚´ë¶€ëŠ” ì†ìµ ì¶”ê°€
    if submode.startswith("ë‚´ë¶€"):
        st.markdown("### (ë‚´ë¶€) ì†ìµ/ë§¤ì¶œ êµ¬ì¡°")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("ì˜ì—…ì´ìµ", fmt_won(sim["profit"]))
        k2.metric("ê³µí—Œì´ìµë¥ ", f"{sim['contrib_margin']:.1f}%")
        k3.metric("ì¬êµ¬ë§¤ ë§¤ì¶œ", fmt_won(sim["repeat_revenue"]))
        k4.metric("ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ", fmt_won(sim["ad_revenue"]))
    else:
        st.markdown("### ë§¤ì¶œ êµ¬ì¡°(ì°¸ê³ )")
        k1, k2, k3 = st.columns(3)
        k1.metric("ì¬êµ¬ë§¤ ë§¤ì¶œ(ì¶”ì •)", fmt_won(sim["repeat_revenue"]))
        k2.metric("ë¹„ì¬êµ¬ë§¤ ë§¤ì¶œ(ì¶”ì •)", fmt_won(sim["nonrepeat_revenue"]))
        k3.metric("ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ(ì¶”ì •)", fmt_won(sim["ad_revenue"]))

    st.divider()

    cL, cR = st.columns(2)
    with cL:
        fig_rev_tm = treemap_revenue(rev_share, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        if fig_rev_tm:
            st.plotly_chart(fig_rev_tm, use_container_width=True, key=f"rev_tm_ag_{scenario_key}")
        else:
            st.info("ë§¤ì¶œ ì±„ë„ ë¹„ì¤‘ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    with cR:
        st.plotly_chart(
            donut_chart(
                ["í¼í¬ë¨¼ìŠ¤", "ë°”ì´ëŸ´", "ë¸Œëœë“œ"],
                [group_share.get("í¼í¬ë¨¼ìŠ¤", 0), group_share.get("ë°”ì´ëŸ´", 0), group_share.get("ë¸Œëœë“œ", 0)],
                title="ê´‘ê³ ë¹„ êµ¬ì¡°(100%)",
                height=380
            ),
            use_container_width=True,
            key=f"donut_group_ag_{scenario_key}"
        )

    st.divider()
    st.markdown("## ë¯¸ë””ì–´ ë¯¹ìŠ¤ (ì˜ˆì‚°/ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget = float(sim["ad_spend"]) * float(group_share.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget = float(sim["ad_spend"]) * float(group_share.get("ë°”ì´ëŸ´", 0.0))

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        st.caption("ì§€ë©´ ë‹¨ê°€/ë¹„ìœ¨ ìˆ˜ì • â†’ ê±´ìˆ˜/ì˜ˆì‚°ì— ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
        viral_price = st.data_editor(
            DEFAULT_VIRAL_PRICE.copy(),
            num_rows="dynamic",
            use_container_width=True,
            key=f"viral_price_editor_{scenario_key}"
        )

    perf_df = build_performance_mix_table(media_share["perf"], perf_budget)
    medium_share = viral_medium_shares(media_share["viral"])
    viral_df = build_viral_mix_table(viral_price, medium_share, viral_budget)

    st.markdown("### í¼í¬ë¨¼ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")
    if perf_df.empty:
        st.info("í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        perf_out = perf_df
    else:
        perf_out = editable_perf_table(perf_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.markdown("### ë°”ì´ëŸ´(ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")
    if viral_df.empty:
        st.info("ë°”ì´ëŸ´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        viral_out = viral_df
    else:
        viral_out = editable_viral_table(viral_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.divider()
    st.markdown("### í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ í‘œ(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´)")
    mix_df = unify_mix_table(perf_out, viral_out)
    if mix_df.empty:
        st.info("í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(mix_df, use_container_width=True, hide_index=True)

    fig_ads_tm = treemap_ads(perf_out, viral_out, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ: í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´ ìƒ‰ êµ¬ë¶„)")
    if fig_ads_tm:
        st.plotly_chart(fig_ads_tm, use_container_width=True, key=f"ads_tm_ag_{scenario_key}")

# =========================
# Tab: Brand (ì™¸ë¶€/ë‚´ë¶€ ë¶„ë¦¬ + ì„±ì¥ë¥ /ê´‘ê³ ê¸°ì—¬ìœ¨/ì¬êµ¬ë§¤ìœ¨ ë°˜ì˜)
# =========================
with tab_brand:
    st.markdown("## ë¸Œëœë“œì‚¬ ëª¨ë“œ")
    submode_b = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(ë¸Œëœë“œì‚¬ ê³µìœ ìš©)", "ë‚´ë¶€(ë¸Œëœë“œ ìš´ì˜/ê²€ì¦ìš©)"], horizontal=True, key="brand_sub")
    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì „ë§ ì…ë ¥(ì›”ë³„)")

    c1, c2, c3, c4 = st.columns(4)
    with c1:
        months = st.selectbox("ê¸°ê°„(ê°œì›”)", options=[3, 6, 12], index=2, key="b_months")
    with c2:
        base_month_rev = st.number_input("ì›” ê¸°ì¤€ ì´ë§¤ì¶œ(ì›)", value=200000000, step=10000000, key="b_base_rev")
    with c3:
        aov_b = st.number_input("ì˜ˆìƒ íŒë§¤ê°€(AOV) (ì›)", value=50000, step=1000, key="b_aov")
    with c4:
        start_ym = st.text_input("ì‹œì‘ì›”(YYYY-MM)", value=f"{date.today().year:04d}-{date.today().month:02d}", key="b_start_ym")

    c5, c6, c7 = st.columns(3)
    with c5:
        monthly_growth = st.number_input("ì›” ì„±ì¥ë¥ (%)", value=float(default_monthly_growth*100), step=0.5, key="b_growth") / 100.0
    with c6:
        ad_contrib_b = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=float(default_ad_contrib*100), step=1.0, key="b_ad_contrib") / 100.0
    with c7:
        repurchase_b = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=float(default_repurchase*100), step=1.0, key="b_repurchase") / 100.0

    # KPI ê¸°ë°˜ ROAS(ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ ê¸°ì¤€) ê³„ì‚°: ë‚´ë¶€ì—ì„œ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œì— ì‚¬ìš©
    use_scn_kpi_b = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPIë¡œ ê´‘ê³  ROAS ì‚°ì¶œ(ê¶Œì¥)", value=True, key="b_use_scn_kpi")
    cpc_manual_b = st.number_input("CPC(ì›) [ìˆ˜ë™]", value=300.0, step=10.0, key="b_cpc")
    cvr_manual_b = st.number_input("CVR(%) [ìˆ˜ë™]", value=2.0, step=0.1, key="b_cvr") / 100.0

    scn_cpc_b, scn_cvr_b = blended_cpc_cvr(row, perf_cols)
    cpc_b = scn_cpc_b if (use_scn_kpi_b and scn_cpc_b is not None) else float(cpc_manual_b)
    cvr_b = scn_cvr_b if (use_scn_kpi_b and scn_cvr_b is not None) else float(cvr_manual_b)
    roas_ad = roas_from_kpi(aov_b, cpc_b, cvr_b)

    st.caption(f"ê´‘ê³  ROAS(ê°€ì •): {roas_ad:.2f}x  |  CPC {fmt_won(cpc_b)} / CVR {fmt_pct(cvr_b*100,1)}")

    # ì›”ë³„ forecast
    df_fore = build_monthly_forecast(
        start_ym=start_ym,
        months=int(months),
        base_month_rev=float(base_month_rev),
        monthly_growth=float(monthly_growth),
        aov=float(aov_b),
        repurchase_rate=float(repurchase_b),
        ad_contrib=float(ad_contrib_b),
        roas_ad=float(roas_ad),
    )

    # ì™¸ë¶€ìš©: ëŒ€ëµ ë§¤ì¶œ/ìˆ˜ëŸ‰/ì¬ê³  ì†Œì§„
    # ë‚´ë¶€ìš©: + í•„ìš”ê´‘ê³ ë¹„ + ë§ˆì§„/ì¸ê±´ë¹„/ì›ê°€
    st.divider()
    st.markdown("### ì˜ˆìƒ ë§¤ì¶œ/ìˆ˜ëŸ‰ ìš”ì•½")

    total_rev_sum = float(df_fore["ì´ë§¤ì¶œ"].sum())
    total_units_sum = float(df_fore["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"].sum())
    total_need_ad = float(df_fore["í•„ìš”ê´‘ê³ ë¹„"].sum())

    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ê¸°ê°„ ì´ë§¤ì¶œ", fmt_won(total_rev_sum))
    k2.metric("ê¸°ê°„ ì´íŒë§¤ìˆ˜ëŸ‰(ë°œì£¼ ê¸°ì¤€)", f"{total_units_sum:,.0f} ê°œ")
    if submode_b.startswith("ë‚´ë¶€"):
        k3.metric("ê¸°ê°„ í•„ìš” ê´‘ê³ ë¹„(ì¶”ì •)", fmt_won(total_need_ad))
        k4.metric("ê´‘ê³ ê¸°ì—¬ ë§¤ì¶œ(í•©)", fmt_won(float(df_fore["ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ"].sum())))
    else:
        k3.metric("ê´‘ê³ ê¸°ì—¬ìœ¨(ê°€ì •)", fmt_pct(ad_contrib_b*100,1))
        k4.metric("ì¬êµ¬ë§¤ìœ¨(ê°€ì •)", fmt_pct(repurchase_b*100,1))

    # ì¬ê³  ì†Œì§„
    st.markdown("### ì˜ˆìƒ ì¬ê³  ì†Œì§„ ì¼ì •")
    cA, cB, cC = st.columns(3)
    with cA:
        initial_stock = st.number_input("ì´ˆê¸° ì¬ê³ (ê°œ)", value=10000, step=100, key="b_stock")
    with cB:
        start_date_input = st.date_input("ì¬ê³  ì‹œì‘ì¼", value=date.today(), key="b_stock_start")
    with cC:
        st.caption("â€» ì›”ë³„ íŒë§¤ëŸ‰ì„ â€˜ì¼ í‰ê· â€™ìœ¼ë¡œ ìª¼ê°œ ì†Œì§„ì¼ì„ ì¶”ì •í•©ë‹ˆë‹¤.")

    dep_date, dep_trace = calc_depletion_date(start_date_input, int(initial_stock), df_fore)

    if dep_date is None:
        st.success("ê¸°ê°„ ë‚´ ì¬ê³ ê°€ ì†Œì§„ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        st.warning(f"ì˜ˆìƒ ì†Œì§„ì¼: **{dep_date.isoformat()}**")

    # ì™¸ë¶€ëŠ” ì›”ë³„ ë§¤ì¶œ/ìˆ˜ëŸ‰ë§Œ, ë‚´ë¶€ëŠ” ê´‘ê³ ë¹„/ë¶„í•´ê¹Œì§€
    if submode_b.startswith("ë‚´ë¶€"):
        st.markdown("### (ë‚´ë¶€) ì›”ë³„ ë§¤ì¶œ êµ¬ì¡°/í•„ìš” ê´‘ê³ ë¹„")
        disp = df_fore.copy()
        disp["ì´ë§¤ì¶œ"] = disp["ì´ë§¤ì¶œ"].map(lambda x: f"{x:,.0f}")
        disp["ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ"] = disp["ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ"].map(lambda x: f"{x:,.0f}")
        disp["í•„ìš”ê´‘ê³ ë¹„"] = disp["í•„ìš”ê´‘ê³ ë¹„"].map(lambda x: f"{x:,.0f}")
        disp["ì¬êµ¬ë§¤ë§¤ì¶œ"] = disp["ì¬êµ¬ë§¤ë§¤ì¶œ"].map(lambda x: f"{x:,.0f}")
        disp["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"] = disp["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"].map(lambda x: f"{x:,.0f}")
        st.dataframe(disp[["ì›”","ì´ë§¤ì¶œ","ê´‘ê³ ê¸°ì—¬ë§¤ì¶œ","í•„ìš”ê´‘ê³ ë¹„","ì¬êµ¬ë§¤ë§¤ì¶œ","ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"]], use_container_width=True, hide_index=True)

        st.markdown("### (ë‚´ë¶€) ë§ˆì§„/ì†ìµ(ê°„ë‹¨)")
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            landed_cost = st.number_input("ê°œë‹¹ ì›ê°€(ì›)", value=20000, step=500, key="b_landed")
        with c2:
            logistics_unit = st.number_input("ë¬¼ë¥˜ë¹„(ê±´ë‹¹) (ì›)", value=3000, step=500, key="b_logi")
        with c3:
            headcount_b = st.number_input("ì¸ì›(ëª…)", value=2, step=1, min_value=0, key="b_hc")
        with c4:
            cost_per_b = st.number_input("ì¸ë‹¹ ê³ ì •ë¹„(ì›)", value=3000000, step=100000, key="b_cper")

        labor = float(headcount_b) * float(cost_per_b)

        revenue_calc = total_units_sum * float(aov_b)
        cogs_calc = total_units_sum * float(landed_cost)
        logistics_calc = total_units_sum * float(logistics_unit)
        profit_calc = revenue_calc - (cogs_calc + logistics_calc + total_need_ad + labor)
        margin_amt = revenue_calc - cogs_calc

        s1, s2, s3, s4 = st.columns(4)
        s1.metric("ì˜ˆìƒ ë§¤ì¶œ(íŒë§¤ê°€Ã—ìˆ˜ëŸ‰)", fmt_won(revenue_calc))
        s2.metric("ë§¤ì¶œì´ì´ìµ(ë§¤ì¶œ-ì›ê°€)", fmt_won(margin_amt))
        s3.metric("í•„ìš” ê´‘ê³ ë¹„(í•©)", fmt_won(total_need_ad))
        s4.metric("ì˜ˆìƒ ìˆœì´ìµ(ê°„ë‹¨)", fmt_won(profit_calc))

    else:
        st.markdown("### (ì™¸ë¶€) ì›”ë³„ ì˜ˆìƒ ë§¤ì¶œ/íŒë§¤ìˆ˜ëŸ‰")
        disp = df_fore.copy()
        disp["ì´ë§¤ì¶œ"] = disp["ì´ë§¤ì¶œ"].map(lambda x: f"{x:,.0f}")
        disp["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"] = disp["ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"].map(lambda x: f"{x:,.0f}")
        st.dataframe(disp[["ì›”","ì´ë§¤ì¶œ","ì˜ˆìƒíŒë§¤ìˆ˜ëŸ‰(Units)"]], use_container_width=True, hide_index=True)

    # ê°„ë‹¨ ì°¨íŠ¸
    st.divider()
    st.markdown("### ì›”ë³„ ì¶”ì´(ì°¨íŠ¸)")
    fig = go.Figure()
    fig.add_trace(go.Bar(x=df_fore["ì›”"], y=df_fore["ì´ë§¤ì¶œ"], name="ì´ë§¤ì¶œ"))
    if submode_b.startswith("ë‚´ë¶€"):
        fig.add_trace(go.Bar(x=df_fore["ì›”"], y=df_fore["í•„ìš”ê´‘ê³ ë¹„"], name="í•„ìš”ê´‘ê³ ë¹„"))
    fig.update_layout(height=420, barmode="group", margin=dict(t=30, b=10, l=10, r=10))
    st.plotly_chart(fig, use_container_width=True, key=f"brand_fore_chart_{scenario_key}_{submode_b}")

# =========================================================
# TAB: Recommendation Engine (stable, no df_all)
# =========================================================
with tab_rec:
    st.markdown("## ì¶”ì²œ ì—”ì§„")
    st.markdown("<div class='smallcap'>ë§¤ì¶œì±„ë„ ë¹„ì¤‘ ê¸°ë°˜ Top3 ì‹œë‚˜ë¦¬ì˜¤ ì¶”ì²œ(ê°„ë‹¨ ì ìˆ˜) + ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì§‘í–‰ ìš°ì„ ìˆœìœ„</div>", unsafe_allow_html=True)
    st.divider()

    focus = st.selectbox("íŒë§¤ ì¤‘ì‹¬ ì±„ë„(ì¶”ì²œ ê¸°ì¤€)", ["ìì‚¬ëª°","ì˜¨ë¼ì¸(ë§ˆì¼“)","í™ˆì‡¼í•‘","ê³µêµ¬","B2B/ë„ë§¤"], key="rec_focus_simple")

    # top3 scenario by score
    rows = []
    for _, rr in df_f.iterrows():
        rev = build_rev_shares(rr, rev_cols)
        score = focus_match_score(rev, focus)
        rows.append({
            "ì‹œë‚˜ë¦¬ì˜¤": str(rr.get(col_disp, rr.get(col_scn,""))),
            "í‚¤": str(rr.get(col_scn,"")),
            "ì ìˆ˜": score,
        })
    dfr = pd.DataFrame(rows).sort_values("ì ìˆ˜", ascending=False)
    top3 = dfr.head(3).copy()

    c1, c2, c3 = st.columns(3)
    for i, colx in enumerate([c1,c2,c3]):
        if i >= len(top3):
            continue
        r = top3.iloc[i]
        with colx:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            st.markdown(f"### #{i+1} {r['ì‹œë‚˜ë¦¬ì˜¤']}")
            st.caption(r["í‚¤"])
            st.metric("ì±„ë„ ì í•© ì ìˆ˜", f"{r['ì ìˆ˜']:.2f}")
            st.markdown("</div>", unsafe_allow_html=True)

    st.divider()
    st.markdown("### (ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤) ì§‘í–‰ ìš°ì„ ìˆœìœ„ Top3")
    rec = strategy_recommendation_from_revshare(rev_share)
    st.markdown(f"**ì „ëµ íƒ€ì…:** {rec['title']}")
    st.caption("ê·¼ê±°(ë§¤ì¶œì±„ë„ ìƒìœ„): " + (" / ".join(rec["evidence"]) if rec["evidence"] else "-"))
    for i, (ch, why) in enumerate(rec["priority"], 1):
        st.write(f"{i}. **{ch}** â€” {why}")
    st.info(rec["note"])

# =========================
# Tab: Custom Scenario (ê·¸ëŒ€ë¡œ)
# =========================
with tab_custom:
    st.markdown("## ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤")
    st.markdown("<div class='smallcap'>ì‹œë‚˜ë¦¬ì˜¤ ìë™ ë¶„ë°°ê°’ ê¸°ë°˜ìœ¼ë¡œ, ë¹„ì¤‘/ì˜ˆì‚°ì„ ì§ì ‘ ìˆ˜ì •í•´ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    base = st.selectbox("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤(ì´ˆê¸°ê°’)", options=disp_list, index=disp_list.index(sel_disp) if sel_disp in disp_list else 0, key="custom_base")
    base_key = disp_to_key.get(base)
    base_row = df[df[col_scn].astype(str).str.strip() == str(base_key).strip()].iloc[0] if base_key is not None else row

    base_media = build_media_shares(base_row, perf_cols, viral_cols, brand_cols)
    base_group = base_media["group"]

    st.markdown("### 1) ê·¸ë£¹ ë¶„ë°°(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´/ë¸Œëœë“œ)")
    gdf = pd.DataFrame([
        {"ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤", "ë¹„ì¤‘(%)": base_group.get("í¼í¬ë¨¼ìŠ¤", 0) * 100},
        {"ê·¸ë£¹": "ë°”ì´ëŸ´", "ë¹„ì¤‘(%)": base_group.get("ë°”ì´ëŸ´", 0) * 100},
        {"ê·¸ë£¹": "ë¸Œëœë“œ", "ë¹„ì¤‘(%)": base_group.get("ë¸Œëœë“œ", 0) * 100},
    ])
    gdf_e = st.data_editor(gdf, use_container_width=True, hide_index=True, key="custom_group")
    group_custom = normalize_shares({r["ê·¸ë£¹"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in gdf_e.iterrows()})

    st.markdown("### 2) í¼í¬ë¨¼ìŠ¤ ì±„ë„ ë¹„ì¤‘")
    pdf = pd.DataFrame([{"ë§¤ì²´": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["perf"].items() if v > 0])
    if pdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— í¼í¬ë¨¼ìŠ¤ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        perf_custom = {}
    else:
        pdf_e = st.data_editor(pdf, use_container_width=True, hide_index=True, key="custom_perf_share")
        perf_custom = normalize_shares({r["ë§¤ì²´"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in pdf_e.iterrows()})

    st.markdown("### 3) ë°”ì´ëŸ´ ë¹„ì¤‘")
    vdf = pd.DataFrame([{"ë°”ì´ëŸ´ í•­ëª©": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["viral"].items() if v > 0])
    if vdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— ë°”ì´ëŸ´ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        viral_custom = {}
    else:
        vdf_e = st.data_editor(vdf, use_container_width=True, hide_index=True, key="custom_viral_share")
        viral_custom = normalize_shares({r["ë°”ì´ëŸ´ í•­ëª©"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in vdf_e.iterrows()})

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        viral_price_custom = st.data_editor(DEFAULT_VIRAL_PRICE.copy(), num_rows="dynamic", use_container_width=True, key="custom_viral_price")

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥")
    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode_c = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="custom_calc_mode")
    with cB:
        aov_c = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50000, step=1000, key="custom_aov")
    with cC:
        cpc_c = st.number_input("CPC (ì›)", value=300.0, step=10.0, key="custom_cpc")
    with cD:
        cvr_c = st.number_input("CVR (%)", value=2.0, step=0.1, key="custom_cvr") / 100.0

    # ì»¤ìŠ¤í…€ë„ backdata íŒŒë¼ë¯¸í„° ì…ë ¥ ê°€ëŠ¥
    cE, cF = st.columns(2)
    with cE:
        ad_contrib_c = st.number_input("ê´‘ê³ ê¸°ì—¬ìœ¨(%)", value=50.0, step=1.0, key="custom_ad_contrib") / 100.0
    with cF:
        repurchase_c = st.number_input("ì¬êµ¬ë§¤ìœ¨(%)", value=10.0, step=1.0, key="custom_repurchase") / 100.0

    if calc_mode_c.startswith("ê´‘ê³ ë¹„"):
        ad_total_c = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="custom_ad_total")
        rev_target_c = None
    else:
        rev_target_c = st.number_input("ëª©í‘œ ì´ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="custom_rev_target")
        ad_total_c = None

    sim_c = simulate_pl_with_mix(
        calc_mode=calc_mode_c,
        aov=aov_c,
        cpc=cpc_c,
        cvr=cvr_c,
        cost_rate=0.0,
        logistics_per_order=0.0,
        fixed_cost=0.0,
        ad_spend=ad_total_c,
        revenue=rev_target_c,
        repurchase_rate=repurchase_c,
        ad_contrib=ad_contrib_c,
    )

    st.markdown("### ì»¤ìŠ¤í…€ ê²°ê³¼")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ì´ë§¤ì¶œ", fmt_won(sim_c["total_revenue"]))
    m2.metric("ê´‘ê³ ë¹„", fmt_won(sim_c["ad_spend"]))
    m3.metric("ROAS", f"{sim_c['roas']:.2f}x ({sim_c['roas']*100:,.0f}%)")
    m4.metric("ì˜ˆìƒ ìˆ˜ëŸ‰(Units)", f"{sim_c['orders_total']:,.0f}")

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ë¯¸ë””ì–´ ë¯¹ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("ë°”ì´ëŸ´", 0.0))

    perf_df_c = build_performance_mix_table(perf_custom, perf_budget_c) if perf_custom else pd.DataFrame()
    viral_df_c = build_viral_mix_table(viral_price_custom, viral_medium_shares(viral_custom), viral_budget_c) if viral_custom else pd.DataFrame()

    st.markdown("#### í¼í¬ë¨¼ìŠ¤")
    if perf_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        perf_out_c = perf_df_c
    else:
        perf_out_c = editable_perf_table(perf_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    st.markdown("#### ë°”ì´ëŸ´")
    if viral_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ ë°”ì´ëŸ´ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        viral_out_c = viral_df_c
    else:
        viral_out_c = editable_viral_table(viral_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    fig_ads_tm_c = treemap_ads(perf_out_c, viral_out_c, title="ì»¤ìŠ¤í…€ ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)")
    if fig_ads_tm_c:
        st.plotly_chart(fig_ads_tm_c, use_container_width=True, key="custom_ads_tm")

# =========================
# Tab: Sales Plan (ê·¸ëŒ€ë¡œ)
# =========================
with tab_plan:
    st.markdown("## ë§¤ì¶œ ê³„íš (ë¸Œëœë“œë³„ 1~12ì›”)")
    st.markdown("<div class='smallcap'>ë¸Œëœë“œëª…/ì „ëµ ì…ë ¥ ë˜ëŠ” í…œí”Œë¦¿ CSV ì—…ë¡œë“œ â†’ ì›”ë³„ ê³„íšì„ í•œ ë²ˆì— ë³´ê³  í¸ì§‘í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    plan_mode = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥", "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ"], horizontal=True, key="plan_mode")

    if plan_mode == "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ":
        up = st.file_uploader("ë§¤ì¶œ ê³„íš í…œí”Œë¦¿ ì—…ë¡œë“œ(csv)", type=["csv"], key="plan_uploader")
        if up is None:
            st.info("í…œí”Œë¦¿ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ/ê´‘ê³ ë¹„ í”¼ë²— ë·°ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        else:
            plan_raw = pd.read_csv(StringIO(up.getvalue().decode("utf-8-sig", errors="replace")))
            brand_col = safe_col(plan_raw, ["Brand", "ë¸Œëœë“œ", "brand"])
            month_col = safe_col(plan_raw, ["Month", "ì›”", "month"])
            rev_col = safe_col(plan_raw, ["TotalRevenue", "ë§¤ì¶œ", "Revenue", "totalrevenue"])
            bud_col = safe_col(plan_raw, ["Budget", "ê´‘ê³ ë¹„", "AdSpend", "budget"])

            if brand_col is None or month_col is None or rev_col is None:
                st.error("í…œí”Œë¦¿ì—ì„œ Brand/Month/TotalRevenue(ë§¤ì¶œ) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                plan_raw[rev_col] = plan_raw[rev_col].apply(lambda x: to_float(x, 0.0))
                if bud_col and bud_col in plan_raw.columns:
                    plan_raw[bud_col] = plan_raw[bud_col].apply(lambda x: to_float(x, 0.0))

                p_rev = plan_raw.pivot_table(index=brand_col, columns=month_col, values=rev_col, aggfunc="sum").fillna(0.0)
                st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í¸ì§‘ ê°€ëŠ¥)")
                st.data_editor(p_rev.reset_index(), use_container_width=True, key="plan_pivot_rev")

                if bud_col and bud_col in plan_raw.columns:
                    st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ê´‘ê³ ë¹„(í¸ì§‘ ê°€ëŠ¥)")
                    p_bud = plan_raw.pivot_table(index=brand_col, columns=month_col, values=bud_col, aggfunc="sum").fillna(0.0)
                    st.data_editor(p_bud.reset_index(), use_container_width=True, key="plan_pivot_budget")

                totals = p_rev.sum(axis=1).reset_index()
                totals.columns = ["Brand", "TotalRevenue"]
                fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
                fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
                fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
                st.plotly_chart(fig, use_container_width=True, key="plan_bar_total")

    else:
        st.markdown("### ë¸Œëœë“œ ì…ë ¥(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)")
        seed = pd.DataFrame([
            {"Brand": "ë¸Œëœë“œA", "ì „ëµ": "Aggressive", "ì‹œì‘ì›”(YYYY-MM)": "2026-01", "ì›”ë§¤ì¶œ(ì›)": 200000000, "ì›”ê´‘ê³ ë¹„(ì›)": 50000000, "ì›”ì„±ì¥ë¥ (%)": 0.0},
        ])
        plan_in = st.data_editor(seed, num_rows="dynamic", use_container_width=True, key="plan_input")

        def month_add(ym: str, idx: int) -> str:
            y, m = ym.split("-")
            y, m = int(y), int(m)
            m2 = m + (idx - 1)
            y2 = y + (m2 - 1)//12
            m2 = (m2 - 1) % 12 + 1
            return f"{y2:04d}-{m2:02d}"

        rows = []
        for _, r in plan_in.iterrows():
            brand = str(r.get("Brand","")).strip()
            strat = str(r.get("ì „ëµ","")).strip()
            start = str(r.get("ì‹œì‘ì›”(YYYY-MM)","2026-01")).strip()
            base_rev = to_float(r.get("ì›”ë§¤ì¶œ(ì›)",0.0), 0.0)
            base_ad = to_float(r.get("ì›”ê´‘ê³ ë¹„(ì›)",0.0), 0.0)
            gr = to_float(r.get("ì›”ì„±ì¥ë¥ (%)",0.0), 0.0) / 100.0
            if not brand:
                continue
            for i in range(1, 13):
                factor = (1.0 + gr) ** (i - 1)
                rows.append({
                    "Brand": brand,
                    "ì „ëµ": strat,
                    "Month": month_add(start, i),
                    "ë§¤ì¶œ(ì›)": round_to_100(base_rev * factor),
                    "ê´‘ê³ ë¹„(ì›)": round_to_100(base_ad * factor),
                })

        plan_long = pd.DataFrame(rows)
        if plan_long.empty:
            st.info("ë¸Œëœë“œë¥¼ ìµœì†Œ 1ê°œ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.markdown("### ì›”ë³„ ê³„íš(í¸ì§‘ ê°€ëŠ¥)")
            plan_edit = st.data_editor(plan_long, use_container_width=True, key="plan_long_editor")

            st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í”¼ë²—)")
            p = plan_edit.pivot_table(index="Brand", columns="Month", values="ë§¤ì¶œ(ì›)", aggfunc="sum").fillna(0.0)
            st.data_editor(p.reset_index(), use_container_width=True, key="plan_pivot_from_manual")

            totals = p.sum(axis=1).reset_index()
            totals.columns = ["Brand", "TotalRevenue"]
            fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
            fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
            fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
            st.plotly_chart(fig, use_container_width=True, key="plan_bar_total_manual")
