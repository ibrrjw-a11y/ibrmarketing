# streamlit_app.py

import streamlit as st
import pandas as pd
import numpy as np
import re
from io import StringIO
from typing import Optional, Dict, List, Tuple

# -------------------------
# Optional dependency: Plotly
# -------------------------
try:
    import plotly.express as px
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except Exception:
    HAS_PLOTLY = False

APP_PASSWORD = "ibrsecret"

# =========================
# Page / Theme
# =========================
st.set_page_config(page_title="ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°", layout="wide")

ACCENT = "#2F6FED"

# âœ… CSS: f-string braces ë¬¸ì œ ì—†ë„ë¡(í¬ë§·ë³€ìˆ˜ ë¯¸ì‚¬ìš©) + ë‹¤í¬/ë¼ì´íŠ¸ ëŒ€ì‘
st.markdown("""
<style>
html, body, [class*="css"]{
  font-size: 14px;
}

/* -------- Card helper (works on both themes) -------- */
.card{
  border-radius: 14px;
  padding: 14px 14px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
}
.card h3{ margin:0; }

/* light theme overrides */
@media (prefers-color-scheme: light){
  .card{
    border: 1px solid rgba(0,0,0,0.08);
    background: #ffffff;
  }
}

/* avoid unreadable text in data editor / dataframes */
div[data-testid="stDataFrame"] div, 
div[data-testid="stDataFrame"] span,
div[data-testid="stDataEditor"] div, 
div[data-testid="stDataEditor"] span,
div[data-baseweb="select"] * ,
input, textarea{
  opacity: 1 !important;
}

/* small caption */
.smallcap{
  opacity: .75;
  font-size: 12px;
}

/* badge */
.badge{
  display:inline-block;
  padding: 6px 10px;
  border-radius: 999px;
  font-weight: 700;
  font-size: 12px;
  background: rgba(47,111,237,0.14);
  color: rgb(47,111,237);
}

/* section divider look */
hr.soft{
  border: 0;
  border-top: 1px solid rgba(255,255,255,0.10);
  margin: 12px 0;
}
@media (prefers-color-scheme: light){
  hr.soft{ border-top: 1px solid rgba(0,0,0,0.08); }
}
</style>
""", unsafe_allow_html=True)

# =========================
# Early guard: plotly required
# =========================
if not HAS_PLOTLY:
    st.error(
        "âŒ plotlyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        "âœ… í•´ê²°:\n"
        "1) ë¡œì»¬/ì½”ë“œìŠ¤í˜ì´ìŠ¤: `pip install plotly`\n"
        "2) Streamlit Cloud: requirements.txtì— `plotly` ì¶”ê°€\n"
    )
    st.stop()

# =========================
# Auth (Password gate)
# =========================
def auth_gate() -> bool:
    if st.session_state.get("auth_ok", False):
        return True

    st.sidebar.markdown("## ğŸ”’ ì ‘ê·¼ ì œí•œ")
    pw = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pw")
    col1, col2 = st.sidebar.columns([1, 1])
    with col1:
        if st.button("ì ê¸ˆ í•´ì œ", key="auth_unlock"):
            if pw == APP_PASSWORD:
                st.session_state["auth_ok"] = True
                st.rerun()
            else:
                st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤.")
    with col2:
        if st.button("ì´ˆê¸°í™”", key="auth_reset"):
            st.session_state.pop("auth_ok", None)
            st.session_state.pop("auth_pw", None)
            st.rerun()

    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    return False

if not auth_gate():
    st.stop()

# =========================
# Helpers
# =========================
def fmt_won(x) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):,.0f} ì›"
    except Exception:
        return "-"

def fmt_pct(x, digits=1) -> str:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return "-"
        return f"{float(x):.{digits}f}%"
    except Exception:
        return "-"

def to_float(x, default=0.0) -> float:
    try:
        if pd.isna(x):
            return default
        s = str(x).strip().replace(",", "").replace("â‚©", "")
        s = s.replace("%", "")
        if s == "" or s.lower() == "nan":
            return default
        return float(s)
    except Exception:
        return default

def normalize_ratio(x) -> float:
    """supports 0.32, 32, '32%' -> returns 0~1"""
    v = to_float(x, default=np.nan)
    if np.isnan(v):
        return np.nan
    return (v / 100.0) if v > 1 else v

def normalize_shares(d: Dict[str, float]) -> Dict[str, float]:
    d2 = {k: float(v or 0.0) for k, v in d.items()}
    s = sum(v for v in d2.values() if v > 0)
    if s <= 0:
        return {k: 0.0 for k in d2}
    return {k: (v / s if v > 0 else 0.0) for k, v in d2.items()}

def round_to_100(x) -> int:
    try:
        return int(np.round(float(x) / 100.0) * 100)
    except Exception:
        return 0

def safe_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in df.columns]
    for cand in candidates:
        if cand in cols:
            return cand
    for cand in candidates:
        for c in cols:
            if cand in c:
                return c
    return None

def drop_duplicate_dot_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Drop Excel-style duplicated columns ending with .1/.2 ..."""
    cols = list(df.columns)
    base_seen = set()
    keep = []
    for c in cols:
        cstr = str(c)
        base = re.sub(r"\.\d+$", "", cstr)
        if base in base_seen and cstr != base:
            continue
        base_seen.add(base)
        keep.append(c)
    out = df[keep].copy()
    out.columns = [re.sub(r"\.\d+$", "", str(c)).strip() for c in out.columns]
    return out

def donut_chart(labels, values, title="", height=320):
    dd = pd.DataFrame({"name": labels, "value": values})
    fig = px.pie(dd, names="name", values="value", hole=0.55)
    fig.update_traces(textinfo="percent+label")
    fig.update_layout(height=height, margin=dict(t=40, b=10, l=10, r=10), title=title)
    return fig

# =========================
# Data loading (xlsx/csv)
# =========================
@st.cache_data(show_spinner=False)
def load_backdata_cached(file_bytes: bytes, filename: str) -> pd.DataFrame:
    name = (filename or "").lower()

    if name.endswith(".csv"):
        raw = file_bytes.decode("utf-8-sig", errors="replace")
        df = pd.read_csv(StringIO(raw))
        df = df.dropna(how="all")
        df = drop_duplicate_dot_columns(df)
        df.columns = [str(c).strip() for c in df.columns]
        return df

    try:
        xls = pd.ExcelFile(pd.io.common.BytesIO(file_bytes))
    except Exception as e:
        raise RuntimeError(
            "ì—‘ì…€(xlsx) ë¡œë“œ ì‹¤íŒ¨. Streamlit Cloudë¼ë©´ requirements.txtì— openpyxl ì¶”ê°€ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            f"ì›ì¸: {e}"
        )

    sheet = None
    for s in xls.sheet_names:
        s_norm = str(s).strip().lower()
        if s_norm in ("backdata", "back_data", "back data", "backdata "):
            sheet = s
            break
        if "backdata" in s_norm:
            sheet = s
            break
    if sheet is None:
        for s in xls.sheet_names:
            if str(s).strip().upper() == "BACKDATA":
                sheet = s
                break
    if sheet is None:
        sheet = xls.sheet_names[0]

    df = pd.read_excel(xls, sheet_name=sheet)
    df = df.dropna(how="all")
    df = drop_duplicate_dot_columns(df)
    df.columns = [str(c).strip() for c in df.columns]
    return df

def load_backdata(uploaded_file) -> pd.DataFrame:
    return load_backdata_cached(uploaded_file.getvalue(), uploaded_file.name)

# =========================
# Column detection (v4 with KPI)
# =========================
def detect_columns(df: pd.DataFrame) -> Dict[str, object]:
    col_scn = safe_col(df, ["ì‹œë‚˜ë¦¬ì˜¤ëª…", "scenario", "Scenario"])
    col_disp = safe_col(df, ["ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…", "ë…¸ì¶œì‹œë‚˜ë¦¬ì˜¤ëª…", "display", "í‘œì‹œ ì‹œë‚˜ë¦¬ì˜¤ëª…"])
    if col_scn is None:
        col_scn = df.columns[0]
    if col_disp is None:
        col_disp = df.columns[1] if len(df.columns) > 1 else col_scn

    col_stage = safe_col(df, ["ë‹¨ê³„(ST)", "ë‹¨ê³„", "ST"])
    col_drv = safe_col(df, ["ë“œë¼ì´ë²„(DRV)", "ë“œë¼ì´ë²„", "DRV"])
    col_cat = safe_col(df, ["ì¹´í…Œê³ ë¦¬(ëŒ€)", "ì¹´í…Œê³ ë¦¬", "CAT"])
    col_pos = safe_col(df, ["ê°€ê²©í¬ì§€ì…˜(POS)", "ê°€ê²©í¬ì§€ì…˜", "POS"])

    rev_cols = [c for c in df.columns if str(c).endswith("ë§¤ì¶œë¹„ì¤‘") and c not in [col_scn, col_disp]]

    perf_cols = [
        c for c in df.columns
        if (str(c).startswith("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_") or str(c) == "í¼í¬ë¨¼ìŠ¤_ì™¸ë¶€ëª°PA")
        and not str(c).startswith("KPI_")
    ]
    viral_cols = [c for c in df.columns if str(c).startswith("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_") and not str(c).startswith("KPI_")]

    brand_cols = []
    for c in df.columns:
        s = str(c)
        if s.startswith("KPI_"):
            continue
        if s in ["ë¸Œëœë“œ ë§ˆì¼€íŒ…", "ê¸°íƒ€_ë¸Œëœë“œ", "ê¸°íƒ€ ë¸Œëœë“œ", "ê¸°íƒ€_ë¸Œëœë“œ%"]:
            brand_cols.append(c)
        elif ("ë¸Œëœë“œ" in s and "ë§ˆì¼€íŒ…" in s and not s.startswith("KPI_")):
            brand_cols.append(c)

    apply_internal = safe_col(df, ["apply_internal(ë‚´ë¶€)", "apply_internal", "ë‚´ë¶€ ì ìš©"])
    apply_client = safe_col(df, ["apply_client(ë¸Œëœë“œì‚¬)", "apply_client", "ë¸Œëœë“œì‚¬ ì ìš©"])
    apply_agency = safe_col(df, ["apply_agency(ëŒ€í–‰)", "apply_agency", "ëŒ€í–‰ ì ìš©"])

    return {
        "scenario": col_scn,
        "display": col_disp,
        "stage": col_stage,
        "drv": col_drv,
        "cat": col_cat,
        "pos": col_pos,
        "rev_cols": rev_cols,
        "perf_cols": perf_cols,
        "viral_cols": viral_cols,
        "brand_cols": brand_cols,
        "kpi_cols": [c for c in df.columns if str(c).startswith("KPI_")],
        "apply_internal": apply_internal,
        "apply_client": apply_client,
        "apply_agency": apply_agency,
    }

def scenario_options(df: pd.DataFrame, col_scn: str, col_disp: str):
    tmp = df[[col_scn, col_disp]].copy()
    tmp[col_scn] = tmp[col_scn].astype(str).str.strip()
    tmp[col_disp] = tmp[col_disp].astype(str).str.strip()
    tmp = tmp.dropna()

    key_to_disp = dict(zip(tmp[col_scn], tmp[col_disp]))
    disp_to_key = {}
    for kk, dd in key_to_disp.items():
        if dd in disp_to_key and disp_to_key[dd] != kk:
            disp_to_key[f"{dd} ({kk})"] = kk
        else:
            disp_to_key[dd] = kk
    disp_list = sorted(list(disp_to_key.keys()))
    return key_to_disp, disp_to_key, disp_list

# =========================
# Media pretty & buckets
# =========================
def pretty_media_name(col: str) -> str:
    c = str(col).strip()
    c = c.replace("í¼í¬ë¨¼ìŠ¤ë§ˆì¼€íŒ…_", "")
    c = c.replace("ë°”ì´ëŸ´ë§ˆì¼€íŒ…_", "")
    c = c.replace("ì”¨ë”©", "ì‹œë”©")
    c = c.replace("ë„¤ì´ë²„ ", "ë„¤ì´ë²„")
    return c

def perf_category(media: str) -> str:
    m = str(media)
    if "SA" in m:
        return "ê²€ìƒ‰ ê´‘ê³ "
    if any(x in m for x in ["GDN", "GFA", "ë©”íƒ€", "í‹±í†¡", "í¬ë¦¬í…Œì˜¤", "í† ìŠ¤"]):
        return "ë””ìŠ¤í”Œë ˆì´/ì†Œì…œ"
    if "ì™¸ë¶€ëª°PA" in m or "ì¿ íŒ¡" in m:
        return "ë§ˆì¼“/PA"
    return "ê¸°íƒ€"

# =========================
# Viral price table (editable)
# =========================
DEFAULT_VIRAL_PRICE = pd.DataFrame([
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸í”Œë£¨ì–¸ì„œíƒ­", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìŠ¤ë§ˆíŠ¸ë¸”ë¡", 250000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì§€ì‹ì¸", 100000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì‡¼í•‘ìƒìœ„", 2000000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¸ê¸°ê¸€", 300000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ìë™ê²€ìƒ‰ì™„ì„±", 400000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_ì¹´í˜ì¹¨íˆ¬ë°”ì´ëŸ´", 30000, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_êµ¬ë§¤ëŒ€í–‰", 120060, 1.0],
    ["ë„¤ì´ë²„", "ë„¤ì´ë²„_í•«ë”œ", 100000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_íŒŒì›Œí˜ì´ì§€", 400000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_í•´ì‹œíƒœê·¸ìƒìœ„ë…¸ì¶œ", 500000, 1.0],
    ["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì¸ìŠ¤íƒ€ê·¸ë¨_ê³„ì •ìƒìœ„ë…¸ì¶œ", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì§‘ë“¤ì´", 500000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_ì²´í—˜ë‹¨", 400000, 1.0],
    ["ì˜¤ëŠ˜ì˜ì§‘", "ì˜¤ëŠ˜ì˜ì§‘_êµ¬ë§¤ëŒ€í–‰", 200952, 1.0],
    ["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°", "ì»¤ë®¤ë‹ˆí‹°_í•«ë”œ", 200000, 1.0],
], columns=["ë§¤ì²´", "ì§€ë©´", "ê±´ë‹¹ë¹„ìš©", "ë¹„ìœ¨"])

# =========================
# Shares builder
# =========================
def build_rev_shares(row: pd.Series, rev_cols: List[str]) -> Dict[str, float]:
    d = {}
    for c in rev_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v):
            v = 0.0
        name = str(c).replace("ë§¤ì¶œë¹„ì¤‘", "").strip()
        d[name] = float(v)
    return normalize_shares(d)

def build_media_shares(row: pd.Series, perf_cols: List[str], viral_cols: List[str], brand_cols: List[str]):
    perf_raw, viral_raw, brand_raw = {}, {}, {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        perf_raw[pretty_media_name(c)] = float(v)
    for c in viral_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        viral_raw[pretty_media_name(c)] = float(v)
    for c in brand_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        brand_raw[pretty_media_name(c)] = float(v)

    perf_sum = sum(v for v in perf_raw.values() if v > 0)
    viral_sum = sum(v for v in viral_raw.values() if v > 0)
    brand_sum = sum(v for v in brand_raw.values() if v > 0)
    total = perf_sum + viral_sum + brand_sum

    group = {"í¼í¬ë¨¼ìŠ¤": 1.0, "ë°”ì´ëŸ´": 0.0, "ë¸Œëœë“œ": 0.0} if total <= 0 else {
        "í¼í¬ë¨¼ìŠ¤": perf_sum / total,
        "ë°”ì´ëŸ´": viral_sum / total,
        "ë¸Œëœë“œ": brand_sum / total
    }

    return {
        "group": group,
        "perf": normalize_shares(perf_raw),
        "viral": normalize_shares(viral_raw),
        "brand": normalize_shares(brand_raw),
        "raw_sums": {"perf": perf_sum, "viral": viral_sum, "brand": brand_sum},
    }

def viral_medium_shares(viral_share_dict: Dict[str, float]) -> Dict[str, float]:
    buckets = {"ë„¤ì´ë²„": 0.0, "ì¸ìŠ¤íƒ€ê·¸ë¨": 0.0, "ì˜¤ëŠ˜ì˜ì§‘": 0.0, "ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°": 0.0}
    for k, v in viral_share_dict.items():
        kk = str(k)
        if "ë„¤ì´ë²„" in kk:
            buckets["ë„¤ì´ë²„"] += v
        elif "ì¸ìŠ¤íƒ€" in kk:
            buckets["ì¸ìŠ¤íƒ€ê·¸ë¨"] += v
        elif "ì˜¤ëŠ˜ì˜ì§‘" in kk:
            buckets["ì˜¤ëŠ˜ì˜ì§‘"] += v
        else:
            buckets["ê¸°íƒ€ ì»¤ë®¤ë‹ˆí‹°"] += v
    return normalize_shares(buckets)

# =========================
# KPI blending (scenario-specific)
# =========================
def kpi_get(row: pd.Series, media_full: str, metric: str) -> Optional[float]:
    key = f"KPI_{metric}_{media_full}"
    if key in row.index:
        v = to_float(row.get(key), default=np.nan)
        if np.isnan(v):
            return None
        if metric in ("CTR", "CVR") and v > 1:
            v = v / 100.0
        return float(v)
    return None

def derive_cpc_from_cpm_ctr(cpm: Optional[float], ctr: Optional[float]) -> Optional[float]:
    if cpm is None or ctr is None:
        return None
    if cpm <= 0 or ctr <= 0:
        return None
    return float(cpm) / (1000.0 * float(ctr))

def blended_cpc_cvr(row: pd.Series, perf_cols: List[str]) -> Tuple[Optional[float], Optional[float]]:
    raw = {}
    for c in perf_cols:
        v = normalize_ratio(row.get(c))
        if pd.isna(v): v = 0.0
        raw[str(c)] = float(v)
    shares = normalize_shares(raw)

    cpc_vals, cvr_vals = [], []
    weights_cpc, weights_cvr = [], []

    for media_full, w in shares.items():
        if w <= 0:
            continue

        cpc = kpi_get(row, media_full, "CPC")
        if cpc is None:
            cpm = kpi_get(row, media_full, "CPM")
            ctr = kpi_get(row, media_full, "CTR")
            cpc = derive_cpc_from_cpm_ctr(cpm, ctr)

        cvr = kpi_get(row, media_full, "CVR")

        if cpc is not None and cpc > 0:
            cpc_vals.append(cpc); weights_cpc.append(w)
        if cvr is not None and cvr > 0:
            cvr_vals.append(cvr); weights_cvr.append(w)

    def wavg(vals, ws):
        if not vals or not ws:
            return None
        s = sum(ws)
        if s <= 0:
            return None
        return float(sum(v * w for v, w in zip(vals, ws)) / s)

    return wavg(cpc_vals, weights_cpc), wavg(cvr_vals, weights_cvr)

# =========================
# P&L / Simulation (two-way)
# =========================
def simulate_pl(
    calc_mode: str,
    aov: float,
    cpc: float,
    cvr: float,
    cost_rate: float,
    logistics_per_order: float,
    fixed_cost: float,
    ad_spend: Optional[float],
    revenue: Optional[float],
):
    if calc_mode.startswith("ë§¤ì¶œ"):
        revenue = float(revenue or 0.0)
        orders = revenue / aov if aov > 0 else 0.0
        clicks = orders / cvr if cvr > 0 else 0.0
        ad_spend = clicks * cpc
    else:
        ad_spend = float(ad_spend or 0.0)
        clicks = ad_spend / cpc if cpc > 0 else 0.0
        orders = clicks * cvr
        revenue = orders * aov

    cogs = revenue * cost_rate
    logistics = orders * logistics_per_order
    profit = revenue - (ad_spend + cogs + logistics + fixed_cost)
    contrib_margin = ((revenue - ad_spend - logistics - cogs) / revenue * 100) if revenue > 0 else 0.0
    roas = (revenue / ad_spend) if ad_spend and ad_spend > 0 else 0.0

    return {
        "revenue": float(revenue),
        "ad_spend": float(ad_spend),
        "orders": float(orders),
        "clicks": float(clicks),
        "cogs": float(cogs),
        "logistics": float(logistics),
        "fixed": float(fixed_cost),
        "profit": float(profit),
        "contrib_margin": float(contrib_margin),
        "roas": float(roas),
    }

# =========================
# Mix builders
# =========================
def build_performance_mix_table(perf_share: Dict[str, float], total_perf_budget: float) -> pd.DataFrame:
    rows = []
    for media, share in perf_share.items():
        if share <= 0:
            continue
        budget = round_to_100(total_perf_budget * share)
        rows.append({
            "êµ¬ë¶„": "í¼í¬ë¨¼ìŠ¤",
            "êµ¬ë¶„2": perf_category(media),
            "ë§¤ì²´": media,
            "ì§€ë©´/ìº í˜ì¸": "",
            "ì˜ˆì‚°(ê³„íš)": budget,
            "ëª©í‘œ ROAS(%)": 0.0,
        })
    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["êµ¬ë¶„2", "ë§¤ì²´"]).reset_index(drop=True)

def build_viral_mix_table(
    viral_price_df: pd.DataFrame,
    medium_share: Dict[str, float],
    total_viral_budget: float,
) -> pd.DataFrame:
    rows = []
    vp = viral_price_df.copy()

    for c in ["ë§¤ì²´", "ì§€ë©´"]:
        if c not in vp.columns:
            return pd.DataFrame()

    vp["ê±´ë‹¹ë¹„ìš©"] = vp["ê±´ë‹¹ë¹„ìš©"].apply(lambda x: to_float(x, 0.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].apply(lambda x: to_float(x, 1.0))
    vp["ë¹„ìœ¨"] = vp["ë¹„ìœ¨"].replace(0, 1.0)

    for medium, mshare in medium_share.items():
        medium_budget = float(total_viral_budget) * float(mshare)
        sub = vp[vp["ë§¤ì²´"] == medium].copy()
        if sub.empty:
            continue

        sub_w = normalize_shares(dict(zip(sub["ì§€ë©´"], sub["ë¹„ìœ¨"])))

        for surface, w in sub_w.items():
            unit = float(sub.loc[sub["ì§€ë©´"] == surface, "ê±´ë‹¹ë¹„ìš©"].iloc[0])
            planned = medium_budget * float(w)
            cnt = int(np.round(planned / unit)) if unit > 0 else 0
            total_cost = cnt * unit
            rows.append({
                "êµ¬ë¶„": "ë°”ì´ëŸ´",
                "êµ¬ë¶„2": "",
                "ë§¤ì²´": medium,
                "ì§€ë©´/ìº í˜ì¸": surface,
                "ê±´ë‹¹ë¹„ìš©": unit,
                "ì§„í–‰ ê±´ìˆ˜": int(cnt),
                "ì˜ˆì‚°(ê³„íš)": round_to_100(total_cost),
            })

    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.sort_values(["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸"]).reset_index(drop=True)

def unify_mix_table(perf_df: pd.DataFrame, viral_df: pd.DataFrame) -> pd.DataFrame:
    base_cols = ["êµ¬ë¶„", "êµ¬ë¶„2", "ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ì˜ˆì‚°(ê³„íš)"]
    out = []
    if perf_df is not None and not perf_df.empty:
        tmp = perf_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if viral_df is not None and not viral_df.empty:
        tmp = viral_df.copy()
        for c in base_cols:
            if c not in tmp.columns:
                tmp[c] = ""
        out.append(tmp[base_cols + [c for c in tmp.columns if c not in base_cols]])
    if not out:
        return pd.DataFrame()
    return pd.concat(out, ignore_index=True)

# =========================
# Treemap builders
# =========================
def rev_bucket(channel_name: str) -> str:
    s = str(channel_name)
    if "ìì‚¬" in s:
        return "ìì‚¬ëª°"
    if "ìŠ¤ë§ˆíŠ¸" in s or "ìŠ¤í† ì–´" in s:
        return "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´"
    if "ì¿ íŒ¡" in s:
        return "ì¿ íŒ¡"
    if any(k in s for k in ["ì˜¤í”„ë¼ì¸", "ë©´ì„¸", "ë¦¬í…Œì¼", "ë°±í™”ì ", "ë§ˆíŠ¸", "ë“œëŸ­", "ì˜¬ë¦¬ë¸Œì˜"]):
        return "ì˜¤í”„ë¼ì¸"
    return "ì˜¨ë¼ì¸(ê¸°íƒ€)"

def treemap_revenue(rev_share: Dict[str, float], height=380, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)"):
    rows = []
    for ch, v in rev_share.items():
        if v <= 0:
            continue
        rows.append({"ê·¸ë£¹": rev_bucket(ch), "ì±„ë„": ch, "ë¹„ì¤‘": float(v)})
    if not rows:
        return None
    df = pd.DataFrame(rows)
    fig = px.treemap(df, path=["ê·¸ë£¹", "ì±„ë„"], values="ë¹„ì¤‘", color="ê·¸ë£¹")
    fig.update_layout(height=height, margin=dict(t=50, b=10, l=10, r=10), title=title)
    fig.update_traces(texttemplate="%{label}<br>%{value:.1%}")
    return fig

def treemap_ads(perf_df: pd.DataFrame, viral_df: pd.DataFrame, height=430, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)"):
    rows = []
    if perf_df is not None and not perf_df.empty:
        for _, r in perf_df.iterrows():
            rows.append({
                "ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤",
                "ë§¤ì²´": r.get("ë§¤ì²´",""),
                "ì§€ë©´": r.get("ì§€ë©´/ìº í˜ì¸","") or r.get("ë§¤ì²´",""),
                "ì˜ˆì‚°": float(r.get("ì˜ˆì‚°(ê³„íš)",0) or 0)
            })
    if viral_df is not None and not viral_df.empty:
        for _, r in viral_df.iterrows():
            rows.append({
                "ê·¸ë£¹": "ë°”ì´ëŸ´",
                "ë§¤ì²´": r.get("ë§¤ì²´",""),
                "ì§€ë©´": r.get("ì§€ë©´/ìº í˜ì¸",""),
                "ì˜ˆì‚°": float(r.get("ì˜ˆì‚°(ê³„íš)",0) or 0)
            })
    if not rows:
        return None
    df = pd.DataFrame(rows)
    df = df[df["ì˜ˆì‚°"] > 0]
    if df.empty:
        return None
    fig = px.treemap(df, path=["ê·¸ë£¹", "ë§¤ì²´", "ì§€ë©´"], values="ì˜ˆì‚°", color="ê·¸ë£¹")
    fig.update_layout(height=height, margin=dict(t=50, b=10, l=10, r=10), title=title)
    return fig

# =========================
# Compare chart (bars + ROAS line / secondary axis)
# =========================
def compare_chart(df_cmp: pd.DataFrame, x_col: str, rev_col: str, ad_col: str, roas_col: str, height=420, title=""):
    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=df_cmp[x_col], y=df_cmp[rev_col], name="ì˜ˆìƒë§¤ì¶œ", yaxis="y1",
        hovertemplate="%{y:,.0f}ì›<extra></extra>"
    ))
    fig.add_trace(go.Bar(
        x=df_cmp[x_col], y=df_cmp[ad_col], name="ì˜ˆìƒê´‘ê³ ë¹„", yaxis="y1",
        hovertemplate="%{y:,.0f}ì›<extra></extra>"
    ))

    roas = df_cmp[roas_col].astype(float).fillna(0.0).clip(lower=0)
    fig.add_trace(go.Scatter(
        x=df_cmp[x_col], y=roas, name="ROAS", yaxis="y2",
        mode="lines+markers",
        hovertemplate="ROAS %{y:.2f}x (%{customdata:.0f}%)<extra></extra>",
        customdata=(roas * 100.0)
    ))

    y2_min, y2_max = 1.0, 10.0
    if roas.max() > y2_max:
        y2_max = float(np.ceil(roas.max()))
    if roas.min() < y2_min and roas.min() > 0:
        y2_min = float(max(0.5, np.floor(roas.min()*2)/2))

    tickvals = list(np.linspace(y2_min, y2_max, 5))
    ticktext = [f"{v*100:.0f}%" for v in tickvals]

    fig.update_layout(
        height=height,
        barmode="group",
        title=title,
        margin=dict(t=50, b=10, l=10, r=10),
        yaxis=dict(title=None, tickformat=",.0f"),
        yaxis2=dict(
            title="ROAS(%)",
            overlaying="y",
            side="right",
            range=[y2_min, y2_max],
            tickmode="array",
            tickvals=tickvals,
            ticktext=ticktext,
        ),
        xaxis=dict(tickangle=0),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )
    return fig

# =========================
# Recommendation (rule-based)
# =========================
def top_key(d: Dict[str, float]) -> Tuple[Optional[str], float]:
    if not d:
        return None, 0.0
    items = sorted(d.items(), key=lambda x: x[1], reverse=True)
    return (items[0][0], float(items[0][1])) if items else (None, 0.0)

def detect_sales_archetype(rev_share: Dict[str, float], sales_focus: str = "(ë¬´ê´€)") -> str:
    if sales_focus and sales_focus != "(ë¬´ê´€)":
        if sales_focus in ["ìì‚¬ëª°", "ì˜¨ë¼ì¸(ë§ˆì¼“)", "í™ˆì‡¼í•‘", "ê³µêµ¬", "B2B/ë„ë§¤"]:
            return sales_focus

    k, _ = top_key(rev_share)
    if not k:
        return "ê¸°íƒ€"

    k = str(k)
    if "ìì‚¬" in k:
        return "ìì‚¬ëª°"
    if "ìŠ¤ë§ˆíŠ¸" in k or "ìŠ¤í† ì–´" in k:
        return "ì˜¨ë¼ì¸(ë§ˆì¼“)"
    if "ì¿ íŒ¡" in k:
        return "ì˜¨ë¼ì¸(ë§ˆì¼“)"
    if "í™ˆì‡¼í•‘" in k:
        return "í™ˆì‡¼í•‘"
    if "ê³µêµ¬" in k or "ê³µë™" in k:
        return "ê³µêµ¬"
    if "B2B" in k or "ë„ë§¤" in k:
        return "B2B/ë„ë§¤"
    return "ê¸°íƒ€"

def strategy_recommendation(rev_share: Dict[str, float], sales_focus: str = "(ë¬´ê´€)") -> Dict[str, object]:
    def share_contains(keyword: str) -> float:
        s = 0.0
        for k, v in rev_share.items():
            if keyword in str(k):
                s += float(v)
        return s

    own = share_contains("ìì‚¬")
    smart = share_contains("ìŠ¤ë§ˆíŠ¸") + share_contains("ìŠ¤í† ì–´")
    coupang = share_contains("ì¿ íŒ¡")
    home = share_contains("í™ˆì‡¼í•‘")
    groupbuy = share_contains("ê³µêµ¬") + share_contains("ê³µë™")

    if home >= max(own, smart, coupang, groupbuy) and home > 0:
        title = "í™ˆì‡¼í•‘ ì—°ê³„í˜•"
        priority = [
            ("Naver SA", "í™ˆì‡¼í•‘ ìœ ì…/ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜ ì¤‘ì‹¬"),
            ("ë„¤ì´ë²„ ë¸”ë¡œê·¸Â·ì½˜í…ì¸ ", "ê²€ìƒ‰ ì‹ ë¢°/í›„ê¸°Â·ì •ë³´ì„± ë³´ê°•"),
            ("ì¿ íŒ¡ PA", "ë°©ì†¡ í›„ ìˆ˜ìš”ë¥¼ ë§ˆì¼“ì—ì„œ í¡ìˆ˜"),
        ]
        note = "ì´ ì¼€ì´ìŠ¤ëŠ” ë©”íƒ€/êµ¬ê¸€ ì§‘í–‰ì€ ì œì™¸(ë˜ëŠ” ìµœì†Œ) ê¶Œì¥"
    elif groupbuy >= max(own, smart, coupang, home) and groupbuy > 0:
        title = "ê³µêµ¬(ê·¸ë£¹ë°”ì‰) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì¸í”Œë£¨ì–¸ì„œ(ì¸ìŠ¤íƒ€ ë©”ê°€)", "ê³µêµ¬ëŠ” â€˜íŒë§¤ì íŒŒì›Œ/ì‹ ë¢°â€™ê°€ ë§¤ì¶œì„ ì¢Œìš°"),
            ("ë°”ì´ëŸ´(í•«ë”œ/ì»¤ë®¤ë‹ˆí‹°)", "êµ¬ë§¤ íŠ¸ë¦¬ê±°Â·í™•ì‚°"),
            ("ì™¸ë¶€ëª°/ì œíœ´ PA", "ê³µêµ¬ ì™¸ ì¶”ê°€ íŒë§¤ë¶„ í¡ìˆ˜"),
        ]
        note = "í¼í¬ë¨¼ìŠ¤ë³´ë‹¤ â€˜íŒë§¤ì/ì½˜í…ì¸  ë“œë¼ì´ë¸Œâ€™ê°€ ìš°ì„ "
    elif coupang >= max(own, smart, home, groupbuy) and coupang > 0:
        title = "ì¿ íŒ¡(ë§ˆì¼“) ì¤‘ì‹¬í˜•"
        priority = [
            ("ì™¸ë¶€ëª° PA(ì¿ íŒ¡)", "ê°€ì¥ ì§ì ‘ì ì¸ ë§¤ì¶œ ê²¬ì¸ ë ˆë²„"),
            ("ë©”íƒ€", "ë¦¬íƒ€ê²Ÿ/í™•ì¥ ë° ìˆ˜ìš” ìƒì„±(ë³´ì¡°)"),
            ("ë„¤ì´ë²„ SA", "ë³´ì¡° ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
        ]
        note = "ì¿ íŒ¡ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ PA 1ìˆœìœ„, ê·¸ ë‹¤ìŒ ë©”íƒ€ê°€ ìì—°ìŠ¤ëŸ¬ì›€"
    elif smart >= max(own, coupang, home, groupbuy) and smart > 0:
        title = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(ë„¤ì´ë²„) ì¤‘ì‹¬í˜•"
        priority = [
            ("Naver SA", "ê²€ìƒ‰ ê¸°ë°˜ ì „í™˜ í™•ë³´"),
            ("ë„¤ì´ë²„ DA/GFA", "ë„¤ì´ë²„ ìƒíƒœê³„ ë‚´ í™•ì¥"),
            ("ë°”ì´ëŸ´(ë„¤ì´ë²„ ì§€ë©´)", "ìŠ¤ë§ˆíŠ¸ë¸”ë¡/ì½˜í…ì¸  ì—°ê³„"),
        ]
        note = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë„¤ì´ë²„ ë¹„ì¤‘ì„ ë†’ì´ëŠ” ê²Œ ì¼ê´€ë¨"
    elif own >= max(smart, coupang, home, groupbuy) and own > 0:
        title = "ìì‚¬ëª° ì¤‘ì‹¬í˜•"
        priority = [
            ("ë©”íƒ€", "ìì‚¬ëª°ì€ ëœë”©/ë¦¬íƒ€ê²Ÿ ì„¤ê³„ ê°•ì  â†’ íš¨ìœ¨ ê¸°ëŒ€"),
            ("Google(ì„ íƒ)", "ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜(ìƒí’ˆ/ë¸Œëœë“œ ê²€ìƒ‰ ì¤‘ì‹¬)"),
            ("ë„¤ì´ë²„ SA(ì„ íƒ)", "êµ­ë‚´ ê²€ìƒ‰ ìˆ˜ìš” ë³´ì¡°"),
        ]
        note = "ìì‚¬ëª° ë¹„ì¤‘ì´ í´ìˆ˜ë¡ ë©”íƒ€ ë¹„ì¤‘ì„ í‚¤ìš°ëŠ” ë£°ì´ ì˜ ë§ìŒ"
    else:
        title = "í˜¼í•©í˜•(ê· í˜• ìš´ì˜)"
        priority = [
            ("Naver SA", "ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜ìš” íšŒìˆ˜"),
            ("ë©”íƒ€", "ìˆ˜ìš” ìƒì„±/ë¦¬íƒ€ê²Ÿ"),
            ("ë§ˆì¼“ PA", "ë³´ìœ  ì±„ë„ì—ì„œ ë§¤ì¶œ í¡ìˆ˜"),
        ]
        note = "ì±„ë„ì´ ì¹˜ìš°ì¹˜ì§€ ì•Šìœ¼ë©´ 3ì¶• ê· í˜• ìš´ì˜ ê¶Œì¥"

    top3 = sorted(rev_share.items(), key=lambda x: x[1], reverse=True)[:3]
    evidence = [f"{k}: {v*100:.1f}%" for k, v in top3 if v > 0]

    return {"title": title, "priority": priority, "note": note, "evidence": evidence}

# =========================
# Sidebar - Upload
# =========================
st.sidebar.title("ë§ˆì¼€íŒ…/ìœ í†µ ì‹œë®¬ë ˆì´í„°")

uploaded = st.sidebar.file_uploader(
    "Backdata ì—…ë¡œë“œ (xlsx/csv)",
    type=["xlsx", "csv"],
    key="backdata_uploader"
)

if st.sidebar.button("ì—…ë¡œë“œ ì´ˆê¸°í™”", key="reset_uploader"):
    st.session_state.pop("backdata_uploader", None)
    st.cache_data.clear()
    st.rerun()

if uploaded is None:
    st.info("ì¢Œì¸¡ì—ì„œ backdata íŒŒì¼(xlsx/csv)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

try:
    df = load_backdata(uploaded)
except Exception as e:
    st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

cols = detect_columns(df)
col_scn = cols["scenario"]
col_disp = cols["display"]

if col_scn not in df.columns:
    st.error("âŒ 'ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

if col_disp not in df.columns:
    st.warning("âš ï¸ 'ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…' ì»¬ëŸ¼ì´ ì—†ì–´, ì‹œë‚˜ë¦¬ì˜¤ëª…ì„ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤.")
    df[col_disp] = df[col_scn].astype(str)

key_to_disp, disp_to_key, disp_list = scenario_options(df, col_scn, col_disp)

stage_col, drv_col, cat_col, pos_col = cols["stage"], cols["drv"], cols["cat"], cols["pos"]

def uniq_vals(c):
    if c is None or c not in df.columns:
        return []
    return sorted([x for x in df[c].dropna().astype(str).unique().tolist() if str(x).strip() != ""])

st.sidebar.markdown("---")
st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ í•„í„°")
f_search = st.sidebar.text_input("ê²€ìƒ‰(ë…¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ëª…)", value="", key="f_search")
f_stage = st.sidebar.selectbox("ë‹¨ê³„(ST)", ["(ì „ì²´)"] + uniq_vals(stage_col), key="f_stage")
f_cat = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬", ["(ì „ì²´)"] + uniq_vals(cat_col), key="f_cat")
f_pos = st.sidebar.selectbox("ê°€ê²© í¬ì§€ì…˜(POS)", ["(ì „ì²´)"] + uniq_vals(pos_col), key="f_pos")
f_drv = st.sidebar.selectbox("ë“œë¼ì´ë²„(DRV)", ["(ì „ì²´)"] + uniq_vals(drv_col), key="f_drv")

apply_internal = cols.get("apply_internal")
apply_client = cols.get("apply_client")
apply_agency = cols.get("apply_agency")

st.sidebar.markdown("### ì‹œë‚˜ë¦¬ì˜¤ ë…¸ì¶œ í•„í„°(ì˜µì…˜)")
show_internal = st.sidebar.toggle("ë‚´ë¶€ìš© ì ìš©ë§Œ", value=False, key="show_internal")
show_client = st.sidebar.toggle("ë¸Œëœë“œì‚¬ìš© ì ìš©ë§Œ", value=False, key="show_client")
show_agency = st.sidebar.toggle("ëŒ€í–‰ìš© ì ìš©ë§Œ", value=False, key="show_agency")

df_f = df.copy()
if f_stage != "(ì „ì²´)" and stage_col in df_f.columns:
    df_f = df_f[df_f[stage_col].astype(str) == f_stage]
if f_cat != "(ì „ì²´)" and cat_col in df_f.columns:
    df_f = df_f[df_f[cat_col].astype(str) == f_cat]
if f_pos != "(ì „ì²´)" and pos_col in df_f.columns:
    df_f = df_f[df_f[pos_col].astype(str) == f_pos]
if f_drv != "(ì „ì²´)" and drv_col in df_f.columns:
    df_f = df_f[df_f[drv_col].astype(str) == f_drv]

def _apply_flag_filter(df_, flag_col):
    if flag_col and flag_col in df_.columns:
        return df_[df_[flag_col].astype(str).str.strip().isin(["1","True","TRUE","Y","y","O","o"])]
    return df_

if show_internal:
    df_f = _apply_flag_filter(df_f, apply_internal)
if show_client:
    df_f = _apply_flag_filter(df_f, apply_client)
if show_agency:
    df_f = _apply_flag_filter(df_f, apply_agency)

disp_candidates = sorted(list(set(df_f[col_disp].dropna().astype(str).str.strip().tolist())))
if f_search.strip():
    s = f_search.strip()
    disp_candidates = [x for x in disp_candidates if s in x]
if not disp_candidates:
    st.sidebar.warning("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•˜ì„¸ìš”.")
    disp_candidates = disp_list

sel_disp = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ", options=disp_candidates, key="sel_scn")

scenario_key = disp_to_key.get(sel_disp)
if scenario_key is None:
    scenario_key = next((k0 for k0, d0 in key_to_disp.items() if d0 == sel_disp), None)
if scenario_key is None:
    st.error("âŒ ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‚´ë¶€í‚¤ë¡œ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

row_df = df[df[col_scn].astype(str).str.strip() == str(scenario_key).strip()]
if row_df.empty:
    st.error("âŒ ì‹œë‚˜ë¦¬ì˜¤ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()
row = row_df.iloc[0]

rev_cols = cols["rev_cols"]
perf_cols = cols["perf_cols"]
viral_cols = cols["viral_cols"]
brand_cols = cols["brand_cols"]

rev_share = build_rev_shares(row, rev_cols)
media_share = build_media_shares(row, perf_cols, viral_cols, brand_cols)
group_share = media_share["group"]

# =========================
# Main Tabs
# =========================
tab_guide, tab_agency, tab_brand, tab_rec, tab_custom, tab_plan = st.tabs(
    ["ì•ˆë‚´", "ëŒ€í–‰", "ë¸Œëœë“œì‚¬", "ì¶”ì²œì—”ì§„", "ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤", "ë§¤ì¶œ ê³„íš"]
)

# =========================
# Tab: Guide
# =========================
with tab_guide:
    st.markdown("## ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown(
        """
<div class="card">
<h3>ì´ ì‹œë®¬ë ˆì´í„°ëŠ” ë¬´ì—‡ì„ í•˜ë‚˜ìš”?</h3>
<hr class="soft"/>
<ul>
  <li><b>ì‹œë‚˜ë¦¬ì˜¤(backdata)</b>ë¥¼ ì„ íƒí•˜ë©´, í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ <b>ë§¤ì¶œ ì±„ë„ ë¹„ì¤‘</b>ê³¼ <b>ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë¹„ì¤‘</b>ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.</li>
  <li><b>ëŒ€í–‰</b> íƒ­ì—ì„œëŠ” ì…ë ¥ê°’(AOV/CPC/CVR ë“±) ê¸°ë°˜ìœ¼ë¡œ <b>ë§¤ì¶œâ†”ê´‘ê³ ë¹„ë¥¼ ì–‘ë°©í–¥</b>ìœ¼ë¡œ ì‚°ì¶œí•©ë‹ˆë‹¤.</li>
  <li><b>ë¯¸ë””ì–´ ë¯¹ìŠ¤</b>ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ë¹„ì¤‘ìœ¼ë¡œ ìë™ ë¶„ë°°ë˜ë©°, <b>ì˜ˆì‚°/ê±´ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì •</b>í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
  <li><b>ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤</b> íƒ­ì€ ë¹„ì¤‘/ì˜ˆì‚°ì„ ì§ì ‘ ì…ë ¥í•´ ë³„ë„ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</li>
  <li><b>ë§¤ì¶œ ê³„íš</b> íƒ­ì€ ì—¬ëŸ¬ ë¸Œëœë“œì˜ 1~12ì›” ê³„íšì„ í•œ ë²ˆì— ë³´ê³  í¸ì§‘í•©ë‹ˆë‹¤.</li>
</ul>
<hr class="soft"/>
<h3>ê³„ì‚°ì‹(ëŒ€í–‰ íƒ­)</h3>
<ul>
  <li><b>ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ</b>: Clicks = ê´‘ê³ ë¹„/CPC â†’ Orders = ClicksÃ—CVR â†’ Revenue = OrdersÃ—AOV</li>
  <li><b>ë§¤ì¶œ â†’ ê´‘ê³ ë¹„</b>: Orders = ë§¤ì¶œ/AOV â†’ Clicks = Orders/CVR â†’ ê´‘ê³ ë¹„ = ClicksÃ—CPC</li>
  <li><b>ROAS</b> = ë§¤ì¶œ/ê´‘ê³ ë¹„</li>
</ul>
<div class="smallcap">â€» ì…ë ¥ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì´ë©° ì‹¤ì œ ì„±ê³¼ëŠ” ìš´ì˜/ìƒí’ˆ/ì‹œì¦Œ ìš”ì¸ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>
</div>
        """,
        unsafe_allow_html=True
    )

# =========================
# Shared editors (budget overrides)
# =========================
def editable_perf_table(perf_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if perf_df.empty:
        return perf_df
    perf_df = perf_df.copy()

    if submode.startswith("ë‚´ë¶€"):
        if "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)" not in perf_df.columns:
            perf_df["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"] = 0.0
        if "í˜ì´ë°±ë¥ (%)" not in perf_df.columns:
            perf_df["í˜ì´ë°±ë¥ (%)"] = 0.0

        edited = st.data_editor(
            perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "í˜ì´ë°±ë¥ (%)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
            key=f"{key_prefix}_perf_editor_int",
        )
        outp = perf_df.copy()
        outp.update(edited)

        outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outp["ì²­êµ¬ì˜ˆìƒë¹„ìš©"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (1.0 + float(r["ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)"]) / 100.0)), axis=1
        )
        outp["í˜ì´ë°±ì˜ˆìƒì•¡"] = outp.apply(
            lambda r: round_to_100(float(r["ì˜ˆì‚°(ê³„íš)"]) * (float(r["í˜ì´ë°±ë¥ (%)"]) / 100.0)), axis=1
        )

        st.dataframe(
            outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)", "ëŒ€í–‰ìˆ˜ìˆ˜ë£Œìœ¨(%)", "ì²­êµ¬ì˜ˆìƒë¹„ìš©", "í˜ì´ë°±ë¥ (%)", "í˜ì´ë°±ì˜ˆìƒì•¡"]],
            use_container_width=True,
            hide_index=True
        )
        return outp

    edited = st.data_editor(
        perf_df[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["êµ¬ë¶„2", "ë§¤ì²´"],
        key=f"{key_prefix}_perf_editor_ext",
    )
    outp = perf_df.copy()
    outp.update(edited)
    outp["ì˜ˆì‚°(ê³„íš)"] = outp["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    st.dataframe(outp[["êµ¬ë¶„2", "ë§¤ì²´", "ì˜ˆì‚°(ê³„íš)", "ëª©í‘œ ROAS(%)"]], use_container_width=True, hide_index=True)
    return outp

def editable_viral_table(viral_df: pd.DataFrame, submode: str, key_prefix: str) -> pd.DataFrame:
    if viral_df.empty:
        return viral_df

    viral_df = viral_df.copy()
    viral_df["ì˜ˆì‚°(ê³„íš)"] = viral_df["ì˜ˆì‚°(ê³„íš)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
    viral_df["ì§„í–‰ ê±´ìˆ˜"] = viral_df["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))

    if submode.startswith("ë‚´ë¶€"):
        if "ì‹¤ì§‘í–‰ë¹„(ì›)" not in viral_df.columns:
            viral_df["ì‹¤ì§‘í–‰ë¹„(ì›)"] = 0.0

        edited = st.data_editor(
            viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)"]],
            use_container_width=True,
            hide_index=True,
            disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
            key=f"{key_prefix}_viral_editor_int",
        )
        outv = viral_df.copy()
        outv.update(edited)

        outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
        outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
        outv["ì‹¤ì§‘í–‰ë¹„(ì›)"] = outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].apply(lambda x: round_to_100(to_float(x, 0.0)))
        outv["ë§ˆì§„(ì›)"] = outv["ì˜ˆì‚°(ê³„íš)"].astype(float) - outv["ì‹¤ì§‘í–‰ë¹„(ì›)"].astype(float)

        st.dataframe(
            outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)", "ì‹¤ì§‘í–‰ë¹„(ì›)", "ë§ˆì§„(ì›)"]],
            use_container_width=True,
            hide_index=True
        )
        return outv

    edited = st.data_editor(
        viral_df[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]],
        use_container_width=True,
        hide_index=True,
        disabled=["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©"],
        key=f"{key_prefix}_viral_editor_ext",
    )
    outv = viral_df.copy()
    outv.update(edited)
    outv["ì§„í–‰ ê±´ìˆ˜"] = outv["ì§„í–‰ ê±´ìˆ˜"].apply(lambda x: int(to_float(x, 0.0)))
    outv["ì˜ˆì‚°(ê³„íš)"] = outv.apply(lambda r: round_to_100(float(r["ì§„í–‰ ê±´ìˆ˜"]) * float(r["ê±´ë‹¹ë¹„ìš©"])), axis=1)
    st.dataframe(outv[["ë§¤ì²´", "ì§€ë©´/ìº í˜ì¸", "ê±´ë‹¹ë¹„ìš©", "ì§„í–‰ ê±´ìˆ˜", "ì˜ˆì‚°(ê³„íš)"]], use_container_width=True, hide_index=True)
    return outv

# =========================
# Tab: Agency
# =========================
with tab_agency:
    st.markdown("## ëŒ€í–‰ ëª¨ë“œ")
    submode = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(í´ë¼ì´ì–¸íŠ¸ ì œì•ˆìš©)", "ë‚´ë¶€(ìš´ì˜/ì •ì‚°ìš©)"], horizontal=True, key="agency_sub")

    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì…ë ¥ (ì‹œë®¬ë ˆì´ì…˜)")
    use_scn_kpi = st.toggle("ì‹œë‚˜ë¦¬ì˜¤ KPI ìë™ ì‚¬ìš©(ê¶Œì¥)", value=True, key="use_scn_kpi_ag")

    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="calc_mode_ag")
    with cB:
        aov = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50000, step=1000, key="aov_ag")
    with cC:
        cpc_manual = st.number_input("CPC (ì›) [ìˆ˜ë™]", value=300.0, step=10.0, key="cpc_ag")
    with cD:
        cvr_manual = st.number_input("CVR (%) [ìˆ˜ë™]", value=2.0, step=0.1, key="cvr_ag") / 100.0

    scn_cpc, scn_cvr = blended_cpc_cvr(row, perf_cols)
    cpc = scn_cpc if (use_scn_kpi and scn_cpc is not None) else float(cpc_manual)
    cvr = scn_cvr if (use_scn_kpi and scn_cvr is not None) else float(cvr_manual)

    st.caption(
        f"í˜„ì¬ ì ìš© KPI: CPC {fmt_won(cpc)} / CVR {fmt_pct(cvr*100,1)} "
        + (f"(ì‹œë‚˜ë¦¬ì˜¤ KPI ê¸°ë°˜)" if use_scn_kpi and scn_cpc is not None else "(ìˆ˜ë™ ì…ë ¥)")
    )

    c1, c2, c3, c4 = st.columns(4)
    with c1:
        cost_rate = st.number_input("ì›ê°€ìœ¨(%)", value=30.0, step=1.0, key="cr_ag") / 100.0
    with c2:
        logistics = st.number_input("ë¬¼ë¥˜ë¹„(ê±´ë‹¹) (ì›)", value=3000, step=500, key="logi_ag")
    with c3:
        headcount = st.number_input("ìš´ì˜ ì¸ë ¥(ëª…)", value=2, step=1, min_value=0, key="hc_ag")
    with c4:
        cost_per = st.number_input("ì¸ë‹¹ ê³ ì •ë¹„(ì›)", value=3000000, step=100000, key="cper_ag")

    fixed_cost = float(headcount) * float(cost_per)

    if calc_mode.startswith("ê´‘ê³ ë¹„"):
        ad_total = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="ad_total_ag")
        rev_target = None
    else:
        rev_target = st.number_input("ëª©í‘œ ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="rev_target_ag")
        ad_total = None

    sim = simulate_pl(
        calc_mode=calc_mode,
        aov=aov,
        cpc=cpc,
        cvr=cvr,
        cost_rate=cost_rate,
        logistics_per_order=logistics,
        fixed_cost=fixed_cost,
        ad_spend=ad_total,
        revenue=rev_target
    )

    st.divider()
    st.markdown("### ê²°ê³¼ ìš”ì•½")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ë§¤ì¶œ", fmt_won(sim["revenue"]))
    m2.metric("ì˜ˆìƒ ê´‘ê³ ë¹„", fmt_won(sim["ad_spend"]))
    m3.metric("ì˜ì—…ì´ìµ", fmt_won(sim["profit"]))
    m4.metric("ROAS", f"{sim['roas']:.2f}x ({sim['roas']*100:,.0f}%)")

    st.divider()

    cL, cR = st.columns(2)
    with cL:
        fig_rev_tm = treemap_revenue(rev_share, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
        if fig_rev_tm:
            st.plotly_chart(fig_rev_tm, use_container_width=True, key=f"rev_tm_ag_{scenario_key}")
        else:
            st.info("ë§¤ì¶œ ì±„ë„ ë¹„ì¤‘ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    with cR:
        st.plotly_chart(
            donut_chart(
                ["í¼í¬ë¨¼ìŠ¤", "ë°”ì´ëŸ´", "ë¸Œëœë“œ"],
                [group_share.get("í¼í¬ë¨¼ìŠ¤", 0), group_share.get("ë°”ì´ëŸ´", 0), group_share.get("ë¸Œëœë“œ", 0)],
                title="ê´‘ê³ ë¹„ êµ¬ì¡°(100%)",
                height=380
            ),
            use_container_width=True,
            key=f"donut_group_ag_{scenario_key}"
        )

    st.divider()
    st.markdown("## ë¯¸ë””ì–´ ë¯¹ìŠ¤ (ì˜ˆì‚°/ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget = float(sim["ad_spend"]) * float(group_share.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget = float(sim["ad_spend"]) * float(group_share.get("ë°”ì´ëŸ´", 0.0))

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        st.caption("ì§€ë©´ ë‹¨ê°€/ë¹„ìœ¨ ìˆ˜ì • â†’ ê±´ìˆ˜/ì˜ˆì‚°ì— ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
        viral_price = st.data_editor(
            DEFAULT_VIRAL_PRICE.copy(),
            num_rows="dynamic",
            use_container_width=True,
            key=f"viral_price_editor_{scenario_key}"
        )

    perf_df = build_performance_mix_table(media_share["perf"], perf_budget)
    medium_share = viral_medium_shares(media_share["viral"])
    viral_df = build_viral_mix_table(viral_price, medium_share, viral_budget)

    st.markdown("### í¼í¬ë¨¼ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")
    if perf_df.empty:
        st.info("í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        perf_out = perf_df
    else:
        perf_out = editable_perf_table(perf_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.markdown("### ë°”ì´ëŸ´(ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥)")
    if viral_df.empty:
        st.info("ë°”ì´ëŸ´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë¹„ìœ¨ 0).")
        viral_out = viral_df
    else:
        viral_out = editable_viral_table(viral_df, submode=submode, key_prefix=f"ag_{scenario_key}")

    st.divider()
    st.markdown("### í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ í‘œ(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´)")
    mix_df = unify_mix_table(perf_out, viral_out)
    if mix_df.empty:
        st.info("í†µí•© ë¯¸ë””ì–´ ë¯¹ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(mix_df, use_container_width=True, hide_index=True)

    fig_ads_tm = treemap_ads(perf_out, viral_out, title="ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ: í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´ ìƒ‰ êµ¬ë¶„)")
    if fig_ads_tm:
        st.plotly_chart(fig_ads_tm, use_container_width=True, key=f"ads_tm_ag_{scenario_key}")

# =========================
# Tab: Brand
# =========================
with tab_brand:
    st.markdown("## ë¸Œëœë“œì‚¬ ëª¨ë“œ")
    submode_b = st.radio("ë²„ì „ ì„ íƒ", ["ì™¸ë¶€(ë¸Œëœë“œì‚¬ ê³µìœ ìš©)", "ë‚´ë¶€(ë¸Œëœë“œ ìš´ì˜/ê²€ì¦ìš©)"], horizontal=True, key="brand_sub")
    st.markdown(f"<div class='smallcap'>ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤: <span class='badge'>{sel_disp}</span></div>", unsafe_allow_html=True)
    st.divider()

    st.markdown("### ì›”ë³„ ë§¤ì¶œ/ê´‘ê³ ë¹„ ì „ë§")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        months = st.selectbox("ê¸°ê°„(ê°œì›”)", options=[3, 6, 12], index=2, key="b_months")
    with c2:
        base_month_rev = st.number_input("ì›” ê¸°ì¤€ ë§¤ì¶œ(ì›)", value=200000000, step=10000000, key="b_base_rev")
    with c3:
        base_month_ad = st.number_input("ì›” ê¸°ì¤€ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="b_base_ad")
    with c4:
        growth = st.number_input("ì›” ì„±ì¥ë¥ (%)", value=0.0, step=0.5, key="b_growth") / 100.0

    months_idx = list(range(1, int(months) + 1))
    rev_list, ad_list, roas_list = [], [], []
    for i in months_idx:
        factor = (1.0 + growth) ** (i - 1)
        rev_i = base_month_rev * factor
        ad_i = base_month_ad * factor
        rev_list.append(rev_i)
        ad_list.append(ad_i)
        roas_list.append((rev_i / ad_i) if ad_i > 0 else 0.0)

    df_m = pd.DataFrame({"ì›”": [f"M{i}" for i in months_idx], "ì˜ˆìƒë§¤ì¶œ": rev_list, "ì˜ˆìƒê´‘ê³ ë¹„": ad_list, "ROAS": roas_list})

    k1, k2, k3 = st.columns(3)
    k1.metric("ê¸°ê°„ ì´ë§¤ì¶œ", fmt_won(df_m["ì˜ˆìƒë§¤ì¶œ"].sum()))
    k2.metric("ê¸°ê°„ ì´ê´‘ê³ ë¹„", fmt_won(df_m["ì˜ˆìƒê´‘ê³ ë¹„"].sum()))
    k3.metric("í‰ê·  ROAS", f"{df_m['ROAS'].mean():.2f}x ({df_m['ROAS'].mean()*100:,.0f}%)")

    st.plotly_chart(
        compare_chart(df_m, "ì›”", "ì˜ˆìƒë§¤ì¶œ", "ì˜ˆìƒê´‘ê³ ë¹„", "ROAS", title="ì›”ë³„ ë§¤ì¶œ/ê´‘ê³ ë¹„ + ROAS(ë³´ì¡°ì¶•)"),
        use_container_width=True,
        key=f"brand_month_chart_{scenario_key}"
    )

    st.divider()
    st.markdown("### ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
    fig_rev_tm2 = treemap_revenue(rev_share, title="ë§¤ì¶œ ì±„ë„ êµ¬ì„±(íŠ¸ë¦¬ë§µ)")
    if fig_rev_tm2:
        st.plotly_chart(fig_rev_tm2, use_container_width=True, key=f"rev_tm_brand_{scenario_key}")

# =========================
# Tab: Recommendation Engine
# =========================
with tab_rec:
    st.markdown("## ì¶”ì²œ ì—”ì§„")
    st.markdown("<div class='smallcap'>backdataì˜ ë‹¨ê³„/ì¹´í…Œê³ ë¦¬/í¬ì§€ì…˜/ë§¤ì¶œë¹„ì¤‘ ê¸°ë°˜ìœ¼ë¡œ ì „ëµì„ ì¶”ì²œí•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    reco = strategy_recommendation(rev_share)

    st.markdown(
        f"<div class='card'>"
        f"<h3>ì¶”ì²œ ì „ëµ: {reco['title']}</h3>"
        f"<div class='smallcap'>íŒë‹¨ ê·¼ê±°(ë§¤ì¶œì±„ë„ Top): {' Â· '.join(reco['evidence']) if reco['evidence'] else 'ë°ì´í„° ë¶€ì¡±'}</div>"
        f"<hr class='soft'/>"
        + "".join([f"<div>â€¢ <b>{a}</b> â€” {b}</div>" for a,b in reco["priority"]])
        + f"<hr class='soft'/>"
        f"<div class='smallcap'>ë©”ëª¨: {reco['note']}</div>"
        f"</div>",
        unsafe_allow_html=True
    )

# =========================
# Tab: Custom Scenario (NEW)
# =========================
with tab_custom:
    st.markdown("## ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤")
    st.markdown("<div class='smallcap'>ì‹œë‚˜ë¦¬ì˜¤ ìë™ ë¶„ë°°ê°’ ê¸°ë°˜ìœ¼ë¡œ, ë¹„ì¤‘/ì˜ˆì‚°ì„ ì§ì ‘ ìˆ˜ì •í•´ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    base = st.selectbox("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤(ì´ˆê¸°ê°’)", options=disp_list, index=disp_list.index(sel_disp) if sel_disp in disp_list else 0, key="custom_base")
    base_key = disp_to_key.get(base)
    base_row = df[df[col_scn].astype(str).str.strip() == str(base_key).strip()].iloc[0] if base_key is not None else row

    base_media = build_media_shares(base_row, perf_cols, viral_cols, brand_cols)
    base_group = base_media["group"]

    st.markdown("### 1) ê·¸ë£¹ ë¶„ë°°(í¼í¬ë¨¼ìŠ¤/ë°”ì´ëŸ´/ë¸Œëœë“œ)")
    gdf = pd.DataFrame([
        {"ê·¸ë£¹": "í¼í¬ë¨¼ìŠ¤", "ë¹„ì¤‘(%)": base_group.get("í¼í¬ë¨¼ìŠ¤", 0) * 100},
        {"ê·¸ë£¹": "ë°”ì´ëŸ´", "ë¹„ì¤‘(%)": base_group.get("ë°”ì´ëŸ´", 0) * 100},
        {"ê·¸ë£¹": "ë¸Œëœë“œ", "ë¹„ì¤‘(%)": base_group.get("ë¸Œëœë“œ", 0) * 100},
    ])
    gdf_e = st.data_editor(gdf, use_container_width=True, hide_index=True, key="custom_group")
    group_custom = normalize_shares({r["ê·¸ë£¹"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in gdf_e.iterrows()})

    st.markdown("### 2) í¼í¬ë¨¼ìŠ¤ ì±„ë„ ë¹„ì¤‘")
    pdf = pd.DataFrame([{"ë§¤ì²´": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["perf"].items() if v > 0])
    if pdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— í¼í¬ë¨¼ìŠ¤ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        perf_custom = {}
    else:
        pdf_e = st.data_editor(pdf, use_container_width=True, hide_index=True, key="custom_perf_share")
        perf_custom = normalize_shares({r["ë§¤ì²´"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in pdf_e.iterrows()})

    st.markdown("### 3) ë°”ì´ëŸ´ ë¹„ì¤‘")
    vdf = pd.DataFrame([{"ë°”ì´ëŸ´ í•­ëª©": k, "ë¹„ì¤‘(%)": v*100} for k, v in base_media["viral"].items() if v > 0])
    if vdf.empty:
        st.info("ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ì— ë°”ì´ëŸ´ ë¹„ì¤‘ì´ ì—†ìŠµë‹ˆë‹¤.")
        viral_custom = {}
    else:
        vdf_e = st.data_editor(vdf, use_container_width=True, hide_index=True, key="custom_viral_share")
        viral_custom = normalize_shares({r["ë°”ì´ëŸ´ í•­ëª©"]: to_float(r["ë¹„ì¤‘(%)"], 0.0) for _, r in vdf_e.iterrows()})

    with st.expander("ë°”ì´ëŸ´ ë‹¨ê°€í‘œ(í¸ì§‘ ê°€ëŠ¥)", expanded=False):
        viral_price_custom = st.data_editor(DEFAULT_VIRAL_PRICE.copy(), num_rows="dynamic", use_container_width=True, key="custom_viral_price")

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥")
    cA, cB, cC, cD = st.columns(4)
    with cA:
        calc_mode_c = st.radio("ê³„ì‚° ë°©ì‹", ["ê´‘ê³ ë¹„ ì…ë ¥ â†’ ë§¤ì¶œ ì‚°ì¶œ", "ë§¤ì¶œ ì…ë ¥ â†’ í•„ìš” ê´‘ê³ ë¹„ ì‚°ì¶œ"], horizontal=True, key="custom_calc_mode")
    with cB:
        aov_c = st.number_input("ê°ë‹¨ê°€(AOV) (ì›)", value=50000, step=1000, key="custom_aov")
    with cC:
        cpc_c = st.number_input("CPC (ì›)", value=300.0, step=10.0, key="custom_cpc")
    with cD:
        cvr_c = st.number_input("CVR (%)", value=2.0, step=0.1, key="custom_cvr") / 100.0

    if calc_mode_c.startswith("ê´‘ê³ ë¹„"):
        ad_total_c = st.number_input("ì´ ê´‘ê³ ë¹„(ì›)", value=50000000, step=1000000, key="custom_ad_total")
        rev_target_c = None
    else:
        rev_target_c = st.number_input("ëª©í‘œ ë§¤ì¶œ(ì›)", value=300000000, step=10000000, key="custom_rev_target")
        ad_total_c = None

    sim_c = simulate_pl(calc_mode_c, aov_c, cpc_c, cvr_c, 0.0, 0.0, 0.0, ad_total_c, rev_target_c)

    st.markdown("### ì»¤ìŠ¤í…€ ê²°ê³¼")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì˜ˆìƒ ë§¤ì¶œ", fmt_won(sim_c["revenue"]))
    m2.metric("ì˜ˆìƒ ê´‘ê³ ë¹„", fmt_won(sim_c["ad_spend"]))
    m3.metric("ROAS", f"{sim_c['roas']:.2f}x ({sim_c['roas']*100:,.0f}%)")
    m4.metric("ë¹„ê³ ", "ì˜ˆì‚°/ê±´ìˆ˜ ìˆ˜ì • ê°€ëŠ¥")

    st.divider()
    st.markdown("### ì»¤ìŠ¤í…€ ë¯¸ë””ì–´ ë¯¹ìŠ¤(ì˜ˆì‚° ìˆ˜ì • ê°€ëŠ¥)")

    perf_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("í¼í¬ë¨¼ìŠ¤", 1.0))
    viral_budget_c = float(sim_c["ad_spend"]) * float(group_custom.get("ë°”ì´ëŸ´", 0.0))

    perf_df_c = build_performance_mix_table(perf_custom, perf_budget_c) if perf_custom else pd.DataFrame()
    viral_df_c = build_viral_mix_table(viral_price_custom, viral_medium_shares(viral_custom), viral_budget_c) if viral_custom else pd.DataFrame()

    st.markdown("#### í¼í¬ë¨¼ìŠ¤")
    if perf_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ í¼í¬ë¨¼ìŠ¤ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        perf_out_c = perf_df_c
    else:
        perf_out_c = editable_perf_table(perf_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    st.markdown("#### ë°”ì´ëŸ´")
    if viral_df_c.empty:
        st.info("ì»¤ìŠ¤í…€ ë°”ì´ëŸ´ ë¯¹ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        viral_out_c = viral_df_c
    else:
        viral_out_c = editable_viral_table(viral_df_c, submode="ì™¸ë¶€", key_prefix="custom")

    fig_ads_tm_c = treemap_ads(perf_out_c, viral_out_c, title="ì»¤ìŠ¤í…€ ê´‘ê³  ë¯¹ìŠ¤(íŠ¸ë¦¬ë§µ)")
    if fig_ads_tm_c:
        st.plotly_chart(fig_ads_tm_c, use_container_width=True, key="custom_ads_tm")

# =========================
# Tab: Sales Plan (NEW)
# =========================
with tab_plan:
    st.markdown("## ë§¤ì¶œ ê³„íš (ë¸Œëœë“œë³„ 1~12ì›”)")
    st.markdown("<div class='smallcap'>ë¸Œëœë“œëª…/ì „ëµ ì…ë ¥ ë˜ëŠ” í…œí”Œë¦¿ CSV ì—…ë¡œë“œ â†’ ì›”ë³„ ê³„íšì„ í•œ ë²ˆì— ë³´ê³  í¸ì§‘í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    st.divider()

    plan_mode = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥", "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ"], horizontal=True, key="plan_mode")

    if plan_mode == "í…œí”Œë¦¿ CSV ì—…ë¡œë“œ":
        up = st.file_uploader("ë§¤ì¶œ ê³„íš í…œí”Œë¦¿ ì—…ë¡œë“œ(csv)", type=["csv"], key="plan_uploader")
        if up is None:
            st.info("í…œí”Œë¦¿ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ/ê´‘ê³ ë¹„ í”¼ë²— ë·°ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        else:
            plan_raw = pd.read_csv(StringIO(up.getvalue().decode("utf-8-sig", errors="replace")))
            brand_col = safe_col(plan_raw, ["Brand", "ë¸Œëœë“œ", "brand"])
            month_col = safe_col(plan_raw, ["Month", "ì›”", "month"])
            rev_col = safe_col(plan_raw, ["TotalRevenue", "ë§¤ì¶œ", "Revenue", "totalrevenue"])
            bud_col = safe_col(plan_raw, ["Budget", "ê´‘ê³ ë¹„", "AdSpend", "budget"])

            if brand_col is None or month_col is None or rev_col is None:
                st.error("í…œí”Œë¦¿ì—ì„œ Brand/Month/TotalRevenue(ë§¤ì¶œ) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                plan_raw[rev_col] = plan_raw[rev_col].apply(lambda x: to_float(x, 0.0))
                if bud_col and bud_col in plan_raw.columns:
                    plan_raw[bud_col] = plan_raw[bud_col].apply(lambda x: to_float(x, 0.0))

                p_rev = plan_raw.pivot_table(index=brand_col, columns=month_col, values=rev_col, aggfunc="sum").fillna(0.0)
                st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í¸ì§‘ ê°€ëŠ¥)")
                st.data_editor(p_rev.reset_index(), use_container_width=True, key="plan_pivot_rev")

                if bud_col and bud_col in plan_raw.columns:
                    st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ê´‘ê³ ë¹„(í¸ì§‘ ê°€ëŠ¥)")
                    p_bud = plan_raw.pivot_table(index=brand_col, columns=month_col, values=bud_col, aggfunc="sum").fillna(0.0)
                    st.data_editor(p_bud.reset_index(), use_container_width=True, key="plan_pivot_budget")

                totals = p_rev.sum(axis=1).reset_index()
                totals.columns = ["Brand", "TotalRevenue"]
                fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
                fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
                fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
                st.plotly_chart(fig, use_container_width=True, key="plan_bar_total")

    else:
        st.markdown("### ë¸Œëœë“œ ì…ë ¥(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)")
        seed = pd.DataFrame([
            {"Brand": "ë¸Œëœë“œA", "ì „ëµ": "Aggressive", "ì‹œì‘ì›”(YYYY-MM)": "2026-01", "ì›”ë§¤ì¶œ(ì›)": 200000000, "ì›”ê´‘ê³ ë¹„(ì›)": 50000000, "ì›”ì„±ì¥ë¥ (%)": 0.0},
        ])
        plan_in = st.data_editor(seed, num_rows="dynamic", use_container_width=True, key="plan_input")

        def month_add(ym: str, idx: int) -> str:
            y, m = ym.split("-")
            y, m = int(y), int(m)
            m2 = m + (idx - 1)
            y2 = y + (m2 - 1)//12
            m2 = (m2 - 1) % 12 + 1
            return f"{y2:04d}-{m2:02d}"

        rows = []
        for _, r in plan_in.iterrows():
            brand = str(r.get("Brand","")).strip()
            strat = str(r.get("ì „ëµ","")).strip()
            start = str(r.get("ì‹œì‘ì›”(YYYY-MM)","2026-01")).strip()
            base_rev = to_float(r.get("ì›”ë§¤ì¶œ(ì›)",0.0), 0.0)
            base_ad = to_float(r.get("ì›”ê´‘ê³ ë¹„(ì›)",0.0), 0.0)
            gr = to_float(r.get("ì›”ì„±ì¥ë¥ (%)",0.0), 0.0) / 100.0
            if not brand:
                continue
            for i in range(1, 13):
                factor = (1.0 + gr) ** (i - 1)
                rows.append({
                    "Brand": brand,
                    "ì „ëµ": strat,
                    "Month": month_add(start, i),
                    "ë§¤ì¶œ(ì›)": round_to_100(base_rev * factor),
                    "ê´‘ê³ ë¹„(ì›)": round_to_100(base_ad * factor),
                })

        plan_long = pd.DataFrame(rows)
        if plan_long.empty:
            st.info("ë¸Œëœë“œë¥¼ ìµœì†Œ 1ê°œ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.markdown("### ì›”ë³„ ê³„íš(í¸ì§‘ ê°€ëŠ¥)")
            plan_edit = st.data_editor(plan_long, use_container_width=True, key="plan_long_editor")

            st.markdown("### ë¸Œëœë“œë³„ ì›”ë³„ ë§¤ì¶œ(í”¼ë²—)")
            p = plan_edit.pivot_table(index="Brand", columns="Month", values="ë§¤ì¶œ(ì›)", aggfunc="sum").fillna(0.0)
            st.data_editor(p.reset_index(), use_container_width=True, key="plan_pivot_from_manual")

            totals = p.sum(axis=1).reset_index()
            totals.columns = ["Brand", "TotalRevenue"]
            fig = px.bar(totals, x="Brand", y="TotalRevenue", text="TotalRevenue")
            fig.update_traces(texttemplate="%{text:,.0f}", textposition="outside")
            fig.update_layout(height=380, margin=dict(t=10), yaxis_title=None, xaxis_title=None, title="ë¸Œëœë“œë³„ ì—°ê°„ ë§¤ì¶œ í•©ê³„")
            st.plotly_chart(fig, use_container_width=True, key="plan_bar_total_manual")
